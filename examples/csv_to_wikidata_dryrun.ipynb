{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e6eec2",
   "metadata": {},
   "source": [
    "# CSV to Wikidata Transformation (Dry Run)\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load data from a CSV file\n",
    "2. Apply a mapping configuration\n",
    "3. Transform the data to Wikidata JSON format\n",
    "4. Preview the results without submitting to Wikidata\n",
    "\n",
    "This is useful for testing and validating your mappings before actual submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068069e2",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and create sample CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25a75904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from gkc import WikiverseAuth\n",
    "from gkc.item_creator import PropertyMapper, ItemCreator\n",
    "\n",
    "mapping_file_path = \"mappings/fed_tribe_from_missing_ak_tribes.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b64d0",
   "metadata": {},
   "source": [
    "## Step 1: Read and Preview example CSV Data\n",
    "\n",
    "Let's load and view the CSV data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de07cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 131 records\n",
      "\n",
      "Columns: ['fr_label', 'fr_alternate_labels', 'old_name', 'wikipedia_en', 'qid_ak_city', 'qid_anrc', 'member_count_2005', 'nill_index', 'nill_ref']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_label</th>\n",
       "      <th>fr_alternate_labels</th>\n",
       "      <th>old_name</th>\n",
       "      <th>wikipedia_en</th>\n",
       "      <th>qid_ak_city</th>\n",
       "      <th>qid_anrc</th>\n",
       "      <th>member_count_2005</th>\n",
       "      <th>nill_index</th>\n",
       "      <th>nill_ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinik Eskimo Community</td>\n",
       "      <td>Golovin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chinik_Eskimo_Community_(Golovin)</td>\n",
       "      <td>Q79379</td>\n",
       "      <td>Q4891841</td>\n",
       "      <td>110</td>\n",
       "      <td>https://narf.org/nill/tribes/chinik.html</td>\n",
       "      <td>https://narf.org/nill/triballaw/index.html#c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Circle Native Community</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circle_Native_Community</td>\n",
       "      <td>Q974350</td>\n",
       "      <td>Q5303808</td>\n",
       "      <td>185</td>\n",
       "      <td>https://narf.org/nill/tribes/circle_native.html</td>\n",
       "      <td>https://narf.org/nill/triballaw/index.html#c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Curyung Tribal Council</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Native Village of Dillingham</td>\n",
       "      <td>Curyung_Tribal_Council</td>\n",
       "      <td>Q79383</td>\n",
       "      <td>Q13581663</td>\n",
       "      <td>1873</td>\n",
       "      <td>https://narf.org/nill/tribes/curyung.html</td>\n",
       "      <td>https://narf.org/nill/triballaw/index.html#c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Egegik Village</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Egegik_Village</td>\n",
       "      <td>Q80060</td>\n",
       "      <td>Q13581663</td>\n",
       "      <td>254</td>\n",
       "      <td>https://narf.org/nill/tribes/egegik.html</td>\n",
       "      <td>https://narf.org/nill/triballaw/index.html#e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evansville Village</td>\n",
       "      <td>Bettles Field</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Evansville_Village_(aka_Bettles_Field)</td>\n",
       "      <td>Q79943</td>\n",
       "      <td>Q5303808</td>\n",
       "      <td>15</td>\n",
       "      <td>https://narf.org/nill/tribes/evansville.html</td>\n",
       "      <td>https://narf.org/nill/triballaw/index.html#e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fr_label fr_alternate_labels                      old_name  \\\n",
       "0  Chinik Eskimo Community             Golovin                           NaN   \n",
       "1  Circle Native Community                 NaN                           NaN   \n",
       "2   Curyung Tribal Council                 NaN  Native Village of Dillingham   \n",
       "3           Egegik Village                 NaN                           NaN   \n",
       "4       Evansville Village       Bettles Field                           NaN   \n",
       "\n",
       "                             wikipedia_en qid_ak_city   qid_anrc  \\\n",
       "0       Chinik_Eskimo_Community_(Golovin)      Q79379   Q4891841   \n",
       "1                 Circle_Native_Community     Q974350   Q5303808   \n",
       "2                  Curyung_Tribal_Council      Q79383  Q13581663   \n",
       "3                          Egegik_Village      Q80060  Q13581663   \n",
       "4  Evansville_Village_(aka_Bettles_Field)      Q79943   Q5303808   \n",
       "\n",
       "   member_count_2005                                       nill_index  \\\n",
       "0                110         https://narf.org/nill/tribes/chinik.html   \n",
       "1                185  https://narf.org/nill/tribes/circle_native.html   \n",
       "2               1873        https://narf.org/nill/tribes/curyung.html   \n",
       "3                254         https://narf.org/nill/tribes/egegik.html   \n",
       "4                 15     https://narf.org/nill/tribes/evansville.html   \n",
       "\n",
       "                                       nill_ref  \n",
       "0  https://narf.org/nill/triballaw/index.html#c  \n",
       "1  https://narf.org/nill/triballaw/index.html#c  \n",
       "2  https://narf.org/nill/triballaw/index.html#c  \n",
       "3  https://narf.org/nill/triballaw/index.html#e  \n",
       "4  https://narf.org/nill/triballaw/index.html#e  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV with pandas\n",
    "df = pd.read_csv(\"/Users/sky/Downloads/Federally Recognized Tribes - Missing Tribes.csv\")\n",
    "\n",
    "print(f\"Loaded {len(df)} records\\n\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ee220",
   "metadata": {},
   "source": [
    "## Step 2: Load Mapping Configuration\n",
    "\n",
    "Build (if necessary) the mapping configuration that defines how CSV fields map to Wikidata properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7eb024",
   "metadata": {},
   "source": [
    "## Alternative: Generate Mapping from EntitySchema\n",
    "\n",
    "Instead of loading a pre-made mapping file, you can auto-generate one from a ShEx EntitySchema using ClaimsMapBuilder. This ensures accurate property datatypes and rich documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Generate mapping directly and use it\n",
    "from gkc import ClaimsMapBuilder\n",
    "\n",
    "# Uncomment to auto-generate mapping from EntitySchema E502\n",
    "# builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "# mapper = PropertyMapper.from_claims_builder(builder, entity_type=\"Q7840353\")\n",
    "# print(\"✓ Generated and loaded mapping from EntitySchema E502\")\n",
    "\n",
    "# Option B: Generate, save, then customize\n",
    "builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "mapping_config = builder.build_complete_mapping(entity_type=\"Q7840353\")\n",
    "\n",
    "# Save for customization\n",
    "with open(mapping_file_path, \"w\") as f:\n",
    "    json.dump(mapping_config, f, indent=2)\n",
    "print(f\"✓ Saved auto-generated mapping to {mapping_file_path}\")\n",
    "print(\"  Now edit the file to update source_field names to match your CSV\")\n",
    "\n",
    "# Then load the customized version\n",
    "mapper = PropertyMapper.from_file(mapping_file_path)\n",
    "\n",
    "# print(\"Using Option A generates mapping on-the-fly from EntitySchema\")\n",
    "# print(\"Using Option B allows you to customize field names before using\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ac994",
   "metadata": {},
   "source": [
    "## Step 3: Load Mapping Configuration\n",
    "\n",
    "Load the mapping configuration that defines how CSV fields map to Wikidata properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e78f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded mapping configuration from: mappings/fed_tribe_from_missing_ak_tribes.json\n",
      "\n",
      "Mapping includes:\n",
      "  - Labels: 1 fields\n",
      "  - Aliases: 1 fields\n",
      "  - Descriptions: 1 fields\n",
      "  - Claims: 21 properties\n"
     ]
    }
   ],
   "source": [
    "# METHOD 1: Load from pre-made mapping file\n",
    "mapping_file = Path(mapping_file_path)\n",
    "\n",
    "if not mapping_file.exists():\n",
    "    print(f\"⚠️  Mapping file not found: {mapping_file}\")\n",
    "    print(\"   Using current directory...\")\n",
    "    mapping_file = Path(\"tribe_mapping_example.json\")\n",
    "\n",
    "# Load the mapper from file\n",
    "mapper = PropertyMapper.from_file(str(mapping_file))\n",
    "print(f\"✓ Loaded mapping configuration from: {mapping_file}\")\n",
    "\n",
    "# METHOD 2: Generate mapping from EntitySchema (uncomment to use)\n",
    "# from gkc import ClaimsMapBuilder\n",
    "# builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "# mapper = PropertyMapper.from_claims_builder(builder, entity_type=\"Q7840353\")\n",
    "# print(\"✓ Generated mapping from EntitySchema E502\")\n",
    "\n",
    "# Preview mapping structure\n",
    "print(\"\\nMapping includes:\")\n",
    "print(f\"  - Labels: {len(mapper.config['mappings'].get('labels', []))} fields\")\n",
    "print(f\"  - Aliases: {len(mapper.config['mappings'].get('aliases', []))} fields\")\n",
    "print(f\"  - Descriptions: {len(mapper.config['mappings'].get('descriptions', []))} fields\")\n",
    "print(f\"  - Claims: {len(mapper.config['mappings'].get('claims', []))} properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653d1b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inferred from hq location': [{'property': 'P887',\n",
       "   'value': 'Q131921702',\n",
       "   'datatype': 'wikibase-item',\n",
       "   'comment': 'based on heuristic - inferred from headquarters location'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.reference_library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbd04d",
   "metadata": {},
   "source": [
    "## Step 4: Transform Single Record (Detailed View)\n",
    "\n",
    "Let's transform one record and examine the resulting Wikidata JSON structure in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cf5043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source record:\n",
      "============================================================\n",
      "  fr_label: Native Village of Deering\n",
      "  fr_alternate_labels: nan\n",
      "  old_name: nan\n",
      "  wikipedia_en: Native_Village_of_Deering\n",
      "  qid_ak_city: Q79729\n",
      "  qid_anrc: Q6952322\n",
      "  member_count_2005: 186\n",
      "  nill_index: https://narf.org/nill/tribes/native_deering.html\n",
      "  nill_ref: https://narf.org/nill/triballaw/index.html#n\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Transform to Wikidata JSON\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m wikidata_json = \u001b[43mmapper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform_to_wikidata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTransformed Wikidata JSON:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/gkc/gkc/item_creator.py:318\u001b[39m, in \u001b[36mPropertyMapper.transform_to_wikidata\u001b[39m\u001b[34m(self, source_record)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# Handle separator for multiple aliases in one field\u001b[39;00m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mseparator\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m alias_mapping:\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     values = [v.strip() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m(alias_mapping[\u001b[33m\"\u001b[39m\u001b[33mseparator\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m v.strip()]\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    320\u001b[39m     values = [value]\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Get first record as dictionary\n",
    "first_record = df.iloc[30].to_dict()\n",
    "\n",
    "print(\"Source record:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in first_record.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Transform to Wikidata JSON\n",
    "wikidata_json = mapper.transform_to_wikidata(first_record)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Transformed Wikidata JSON:\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(wikidata_json, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb840f",
   "metadata": {},
   "source": [
    "## Step 5: Examine Key Sections\n",
    "\n",
    "Let's look at specific sections of the transformed data to understand the structure better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a1398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "print(\"LABELS:\")\n",
    "print(json.dumps(wikidata_json.get('labels', {}), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Aliases (note the separator handling)\n",
    "print(\"\\nALIASES (split from semicolon-separated string):\")\n",
    "print(json.dumps(wikidata_json.get('aliases', {}), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Descriptions\n",
    "print(\"\\nDESCRIPTIONS:\")\n",
    "print(json.dumps(wikidata_json.get('descriptions', {}), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b70e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claims - show a few examples\n",
    "print(\"CLAIMS (sample properties):\")\n",
    "print(\"\\nP31 (instance of):\")\n",
    "if 'P31' in wikidata_json.get('claims', {}):\n",
    "    print(json.dumps(wikidata_json['claims']['P31'], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\nP2124 (member count with qualifier and reference):\")\n",
    "if 'P2124' in wikidata_json.get('claims', {}):\n",
    "    print(json.dumps(wikidata_json['claims']['P2124'], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60cf98",
   "metadata": {},
   "source": [
    "## Step 6: Dry Run - Transform All Records\n",
    "\n",
    "Now let's process all records using the ItemCreator in dry-run mode. This shows what would be submitted without actually sending data to Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6512673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create auth (not actually needed for dry run, but required by ItemCreator)\n",
    "auth = WikiverseAuth()\n",
    "\n",
    "# Create ItemCreator in DRY RUN mode\n",
    "creator = ItemCreator(auth=auth, mapper=mapper, dry_run=True)\n",
    "\n",
    "print(\"Processing all records in DRY RUN mode...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert dataframe to list of dicts\n",
    "records = df.to_dict('records')\n",
    "\n",
    "# Process each record\n",
    "for i, record in enumerate(records, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Record {i}/{len(records)}: {record['tribe_name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = creator.create_item(record, validate=False)\n",
    "    print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4675e",
   "metadata": {},
   "source": [
    "## Step 7: Batch Processing Summary\n",
    "\n",
    "Use the batch processing feature to get a summary of all transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4807643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batch and get summary\n",
    "results = creator.create_batch(records, validate=False)\n",
    "\n",
    "print(\"\\nBatch Processing Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total records: {len(records)}\")\n",
    "print(f\"Successful: {len(results['success'])}\")\n",
    "print(f\"Failed: {len(results['failed'])}\")\n",
    "\n",
    "if results['success']:\n",
    "    print(\"\\nSuccessfully processed:\")\n",
    "    for item in results['success']:\n",
    "        record = item['record']\n",
    "        print(f\"  ✓ {record['tribe_name']} → {item['qid']}\")\n",
    "\n",
    "if results['failed']:\n",
    "    print(\"\\nFailed records:\")\n",
    "    for item in results['failed']:\n",
    "        record = item['record']\n",
    "        print(f\"  ✗ {record.get('tribe_name', 'Unknown')}: {item['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846eb31",
   "metadata": {},
   "source": [
    "## Step 8: Export Transformed Data\n",
    "\n",
    "Save all transformed Wikidata JSON structures to a file for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb394b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all records and save\n",
    "transformed_records = []\n",
    "\n",
    "for record in records:\n",
    "    wikidata_json = mapper.transform_to_wikidata(record)\n",
    "    transformed_records.append({\n",
    "        \"source_label\": record['tribe_name'],\n",
    "        \"wikidata_json\": wikidata_json\n",
    "    })\n",
    "\n",
    "# Save to JSON file\n",
    "output_path = Path(\"transformed_items.json\")\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(transformed_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✓ Saved {len(transformed_records)} transformed records to: {output_path}\")\n",
    "print(f\"  File size: {output_path.stat().st_size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a65fd5",
   "metadata": {},
   "source": [
    "## Summary Statistics\n",
    "\n",
    "Analyze the transformed data to understand what will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcef851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze transformed data\n",
    "stats = {\n",
    "    'total_records': len(transformed_records),\n",
    "    'properties_used': set(),\n",
    "    'languages': set(),\n",
    "    'total_aliases': 0,\n",
    "    'total_claims': 0\n",
    "}\n",
    "\n",
    "for item in transformed_records:\n",
    "    wikidata_json = item['wikidata_json']\n",
    "    \n",
    "    # Count languages\n",
    "    stats['languages'].update(wikidata_json.get('labels', {}).keys())\n",
    "    \n",
    "    # Count aliases\n",
    "    for lang, aliases in wikidata_json.get('aliases', {}).items():\n",
    "        stats['total_aliases'] += len(aliases)\n",
    "    \n",
    "    # Count properties\n",
    "    claims = wikidata_json.get('claims', {})\n",
    "    stats['properties_used'].update(claims.keys())\n",
    "    stats['total_claims'] += len(claims)\n",
    "\n",
    "print(\"Transformation Statistics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total records transformed: {stats['total_records']}\")\n",
    "print(f\"Languages: {', '.join(sorted(stats['languages']))}\")\n",
    "print(f\"Total aliases created: {stats['total_aliases']}\")\n",
    "print(f\"Total claims (statements): {stats['total_claims']}\")\n",
    "print(f\"\\nUnique properties used: {len(stats['properties_used'])}\")\n",
    "for prop in sorted(stats['properties_used']):\n",
    "    print(f\"  - {prop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412c68d",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Once you're satisfied with the dry run results:\n",
    "\n",
    "1. **Test on test.wikidata.org** - Always test on the test instance first\n",
    "2. **Authenticate** - Set up proper credentials\n",
    "3. **Disable dry-run** - Set `dry_run=False` in ItemCreator\n",
    "4. **Submit** - Actually create the items\n",
    "\n",
    "```python\n",
    "# For actual submission (be careful!):\n",
    "auth = WikiverseAuth(\n",
    "    api_url=\"https://test.wikidata.org/w/api.php\"  # Test instance\n",
    ")\n",
    "auth.login()\n",
    "\n",
    "creator = ItemCreator(auth=auth, mapper=mapper, dry_run=False)\n",
    "results = creator.create_batch(records, validate=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfd6f8",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove temporary files created during this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e987404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up generated files\n",
    "import os\n",
    "\n",
    "files_to_remove = ['tribe_data.csv', 'transformed_items.json']\n",
    "\n",
    "for filename in files_to_remove:\n",
    "    if Path(filename).exists():\n",
    "        os.remove(filename)\n",
    "        print(f\"✓ Removed: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
