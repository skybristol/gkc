{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CSV to Wikidata Transformation (Dry Run)\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load data from a CSV file\n",
    "2. Apply a mapping configuration\n",
    "3. Transform the data to Wikidata JSON format\n",
    "4. Preview the results without submitting to Wikidata\n",
    "\n",
    "This is useful for testing and validating your mappings before actual submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required libraries and create sample CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from gkc import WikiverseAuth\n",
    "from gkc.item_creator import PropertyMapper, ItemCreator\n",
    "\n",
    "mapping_file_path = \"mappings/fed_tribe_from_missing_ak_tribes.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Step 1: Read and Preview example CSV Data\n",
    "\n",
    "Let's load and view the CSV data using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV with pandas\n",
    "df = pd.read_csv(\"/Users/sky/Downloads/missing_tribes.csv\")\n",
    "\n",
    "created_items = [\n",
    "    \"Egegik Village\",\n",
    "    \"Chinik Eskimo Community\"\n",
    "]\n",
    "\n",
    "df = df[~df['fr_label'].isin(created_items)]\n",
    "\n",
    "print(f\"Loaded {len(df)} records\\n\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Step 2: Build Mapping Configuration\n",
    "\n",
    "Build the mapping configuration that defines how CSV fields map to Wikidata properties. This can be used to at least stub out a mapping JSON file if one does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Generate mapping directly and use it\n",
    "from gkc import ClaimsMapBuilder\n",
    "\n",
    "# Uncomment to auto-generate mapping from EntitySchema E502\n",
    "# builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "# mapper = PropertyMapper.from_claims_builder(builder, entity_type=\"Q7840353\")\n",
    "# print(\"✓ Generated and loaded mapping from EntitySchema E502\")\n",
    "\n",
    "# Option B: Generate, save, then customize\n",
    "builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "mapping_config = builder.build_complete_mapping(entity_type=\"Q7840353\")\n",
    "\n",
    "# Save for customization\n",
    "with open(mapping_file_path, \"w\") as f:\n",
    "    json.dump(mapping_config, f, indent=2)\n",
    "print(f\"✓ Saved auto-generated mapping to {mapping_file_path}\")\n",
    "print(\"  Now edit the file to update source_field names to match your CSV\")\n",
    "\n",
    "# Then load the customized version\n",
    "mapper = PropertyMapper.from_file(mapping_file_path)\n",
    "\n",
    "# print(\"Using Option A generates mapping on-the-fly from EntitySchema\")\n",
    "# print(\"Using Option B allows you to customize field names before using\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Step 3: Load Mapping Configuration\n",
    "\n",
    "Load the mapping configuration that defines how CSV fields map to Wikidata properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD 1: Load from pre-made mapping file\n",
    "mapping_file = Path(mapping_file_path)\n",
    "\n",
    "if not mapping_file.exists():\n",
    "    print(f\"⚠️  Mapping file not found: {mapping_file}\")\n",
    "    print(\"   Using current directory...\")\n",
    "    mapping_file = Path(\"tribe_mapping_example.json\")\n",
    "\n",
    "# Load the mapper from file\n",
    "mapper = PropertyMapper.from_file(str(mapping_file))\n",
    "print(f\"✓ Loaded mapping configuration from: {mapping_file}\")\n",
    "\n",
    "# METHOD 2: Generate mapping from EntitySchema (uncomment to use)\n",
    "# from gkc import ClaimsMapBuilder\n",
    "# builder = ClaimsMapBuilder(eid=\"E502\")\n",
    "# mapper = PropertyMapper.from_claims_builder(builder, entity_type=\"Q7840353\")\n",
    "# print(\"✓ Generated mapping from EntitySchema E502\")\n",
    "\n",
    "# Preview mapping structure\n",
    "print(\"\\nMapping includes:\")\n",
    "print(f\"  - Labels: {len(mapper.config['mappings'].get('labels', []))} fields\")\n",
    "print(f\"  - Aliases: {len(mapper.config['mappings'].get('aliases', []))} fields\")\n",
    "print(f\"  - Descriptions: {len(mapper.config['mappings'].get('descriptions', []))} fields\")\n",
    "print(f\"  - Claims: {len(mapper.config['mappings'].get('claims', []))} properties\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Step 4: Transform Single Record (Detailed View)\n",
    "\n",
    "Let's transform one record and examine the resulting Wikidata JSON structure in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first record as dictionary\n",
    "first_record = df[df.wikipedia_en.notnull()].iloc[0].to_dict()\n",
    "\n",
    "print(\"Source record:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in first_record.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Transform to Wikidata JSON\n",
    "wikidata_json = mapper.transform_to_wikidata(first_record)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Transformed Wikidata JSON:\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(wikidata_json, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Step 5: Examine Key Sections\n",
    "\n",
    "Let's look at specific sections of the transformed data to understand the structure better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "print(\"LABELS:\")\n",
    "print(json.dumps(wikidata_json.get('labels', {}), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Aliases (note the separator handling)\n",
    "print(\"\\nALIASES (split from semicolon-separated string):\")\n",
    "print(json.dumps(wikidata_json.get('aliases', {}), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Descriptions\n",
    "print(\"\\nDESCRIPTIONS:\")\n",
    "print(json.dumps(wikidata_json.get('descriptions', {}), indent=2, ensure_ascii=False))\n",
    "\n",
    "# Sitelinks (Wikipedia and other Wikimedia project links)\n",
    "print(\"\\nSITELINKS (links to Wikipedia/Wikimedia projects):\")\n",
    "print(json.dumps(wikidata_json.get('sitelinks', {}), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claims - show a few examples\n",
    "print(\"CLAIMS (sample properties):\")\n",
    "print(\"\\nP31 (instance of):\")\n",
    "if 'P31' in wikidata_json.get('claims', {}):\n",
    "    print(json.dumps(wikidata_json['claims']['P31'], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\nP2124 (member count with qualifier and reference):\")\n",
    "if 'P2124' in wikidata_json.get('claims', {}):\n",
    "    print(json.dumps(wikidata_json['claims']['P2124'], indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Step 6: Dry Run - Transform All Records\n",
    "\n",
    "Now let's process all records using the ItemCreator in dry-run mode. This shows what would be submitted without actually sending data to Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create auth (not actually needed for dry run, but required by ItemCreator)\n",
    "auth = WikiverseAuth()\n",
    "\n",
    "# Create ItemCreator in DRY RUN mode\n",
    "creator = ItemCreator(auth=auth, mapper=mapper, dry_run=True)\n",
    "\n",
    "print(\"Processing all records in DRY RUN mode...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert dataframe to list of dicts\n",
    "records = df.to_dict('records')\n",
    "\n",
    "# Process each record\n",
    "for i, record in enumerate(records, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Record {i}/{len(records)}: {record['fr_label']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = creator.create_item(record, validate=False)\n",
    "    print(f\"\\nResult: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Step 7: Batch Processing Summary\n",
    "\n",
    "Use the batch processing feature to get a summary of all transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process batch and get summary\n",
    "results = creator.create_batch(records, validate=False)\n",
    "\n",
    "print(\"\\nBatch Processing Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total records: {len(records)}\")\n",
    "print(f\"Successful: {len(results['success'])}\")\n",
    "print(f\"Failed: {len(results['failed'])}\")\n",
    "\n",
    "if results['success']:\n",
    "    print(\"\\nSuccessfully processed:\")\n",
    "    for item in results['success']:\n",
    "        record = item['record']\n",
    "        print(f\"  ✓ {record['fr_label']} → {item['qid']}\")\n",
    "\n",
    "if results['failed']:\n",
    "    print(\"\\nFailed records:\")\n",
    "    for item in results['failed']:\n",
    "        record = item['record']\n",
    "        print(f\"  ✗ {record.get('fr_label', 'Unknown')}: {item['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Step 8: Export Transformed Data\n",
    "\n",
    "Save all transformed Wikidata JSON structures to a file for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all records and save\n",
    "transformed_records = []\n",
    "\n",
    "for record in records:\n",
    "    wikidata_json = mapper.transform_to_wikidata(record)\n",
    "    transformed_records.append({\n",
    "        \"source_label\": record['fr_label'],\n",
    "        \"wikidata_json\": wikidata_json\n",
    "    })\n",
    "\n",
    "# Save to JSON file\n",
    "# output_path = Path(\"transformed_items.json\")\n",
    "# with open(output_path, 'w', encoding='utf-8') as f:\n",
    "#     json.dump(transformed_records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"✓ Saved {len(transformed_records)} transformed records to: {output_path}\")\n",
    "# print(f\"  File size: {output_path.stat().st_size:,} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Summary Statistics\n",
    "\n",
    "Analyze the transformed data to understand what will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze transformed data\n",
    "stats = {\n",
    "    'total_records': len(transformed_records),\n",
    "    'properties_used': set(),\n",
    "    'languages': set(),\n",
    "    'total_aliases': 0,\n",
    "    'total_claims': 0\n",
    "}\n",
    "\n",
    "for item in transformed_records:\n",
    "    wikidata_json = item['wikidata_json']\n",
    "    \n",
    "    # Count languages\n",
    "    stats['languages'].update(wikidata_json.get('labels', {}).keys())\n",
    "    \n",
    "    # Count aliases\n",
    "    for lang, aliases in wikidata_json.get('aliases', {}).items():\n",
    "        stats['total_aliases'] += len(aliases)\n",
    "    \n",
    "    # Count properties\n",
    "    claims = wikidata_json.get('claims', {})\n",
    "    stats['properties_used'].update(claims.keys())\n",
    "    stats['total_claims'] += len(claims)\n",
    "\n",
    "print(\"Transformation Statistics\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total records transformed: {stats['total_records']}\")\n",
    "print(f\"Languages: {', '.join(sorted(stats['languages']))}\")\n",
    "print(f\"Total aliases created: {stats['total_aliases']}\")\n",
    "print(f\"Total claims (statements): {stats['total_claims']}\")\n",
    "print(f\"\\nUnique properties used: {len(stats['properties_used'])}\")\n",
    "for prop in sorted(stats['properties_used']):\n",
    "    print(f\"  - {prop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Step 9: Item Creation Test\n",
    "\n",
    "Test a small number of items to ensure everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = WikiverseAuth()\n",
    "\n",
    "if not auth.is_authenticated():\n",
    "    print(\"\\n⚠️  No credentials found.\")\n",
    "    print(\"Set WIKIVERSE_USERNAME and WIKIVERSE_PASSWORD to run this example.\")\n",
    "\n",
    "print(f\"\\nAuthenticating as: {auth.username}\")\n",
    "try:\n",
    "    auth.login()\n",
    "    print(\"✓ Successfully logged in\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Login failed: {e}\")\n",
    "\n",
    "creator = ItemCreator(auth=auth, mapper=mapper, dry_run=False)\n",
    "\n",
    "print(f\"\\nCreating item for: {first_record['fr_label']}\")\n",
    "\n",
    "response = input(\"Are you sure you want to create this item? (yes/no): \")\n",
    "if response.lower() != \"yes\":\n",
    "    print(\"Cancelled.\")\n",
    "else:\n",
    "    try:\n",
    "        qid = creator.create_item(first_record, validate=False)\n",
    "        print(f\"\\n✓ Successfully created item: {qid}\")\n",
    "        print(f\"   View at: https://www.wikidata.org/wiki/{qid}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Failed to create item: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
