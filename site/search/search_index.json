{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Data Distillery","text":"<p>There are no bad data, just data that haven't yet been distilled.</p> <p>The Data Distillery project is an experimental framework for data cleaning, integration, and enhancement workflows geared toward data and information being contributed to the Global Knowledge Commons. That's the term of art I've adopted for the suite of open knowledge assets maintained by all of us in the commons - Wikidata and other parts of the Wikiverse, OpenStreetMap, and a handful of other platforms and helper services like ORCID. I'm writing some new software that I'll post about here shortly.</p>"},{"location":"#global-knowledge-commons-python-package","title":"Global Knowledge Commons Python package","text":"<p>I've started work porting what I used to do in Wikidata and Wikibase instances into a larger framework to support a more robust set of data processing steps and contributions across Wikimedia projects and OpenStreetMap. I've called it gkc and started building architecture on the data distillery theme. Read the docs here.</p>"},{"location":"#data-curator-narratives","title":"Data Curator Narratives","text":"<p>I've started an initial narrative text about the bigger picture work I'm trying to achieve and how I'd like the gkc Python package and perhaps a larger Data Distillery capability based on that to help me do work in the Commons. I'm using these to help ground and guide the development process.</p> <ul> <li>Federally recognized Tribal Governments in the U.S. </li> </ul>"},{"location":"SpiritSafe/","title":"SpiritSafe: The Entity Profile Registry for the Global Knowledge Commons","text":"<p>Purpose: A comprehensive guide to understanding, contributing to, and maintaining the SpiritSafe registry\u2014the centralized repository of GKC Entity Profiles that define how entities are structured, validated, and transformed across the Global Knowledge Commons.</p>"},{"location":"SpiritSafe/#vision-a-better-alternative-to-wikidata-entity-schemas","title":"Vision: A Better Alternative to Wikidata Entity Schemas","text":""},{"location":"SpiritSafe/#the-problem","title":"The Problem","text":"<p>Wikidata's EntitySchema (ShEx) system, while conceptually sound, has struggled to gain adoption and provide the operational clarity needed for profile management. Profiles are created in isolation, versioning is implicit, community contribution processes are unclear, and there's no unified registry that says \"here are all the entity types the community understands and maintains.\"</p>"},{"location":"SpiritSafe/#the-spiritsafe-solution","title":"The SpiritSafe Solution","text":"<p>SpiritSafe reimagines the entity profile as a registry entry\u2014a version-controlled, community-maintained package that brings together:</p> <ul> <li>Profile Definition (YAML)\u2014The canonical structure of an entity type</li> <li>Controlled Vocabularies (SPARQL queries)\u2014Definitive lists of allowed values for entity properties</li> <li>Metadata &amp; Documentation (README, CHANGELOG, version history)\u2014Clarity on purpose, authorship, and evolution</li> <li>Governance (PR review, human curation, CI validation)\u2014Trust and quality assurance</li> </ul> <p>Metaphor: In a traditional distillery, the SpiritSafe is a locked cabinet where the master distiller inspects and approves each batch of spirit before it moves to barrel aging or bottling. Similarly, SpiritSafe is where entity profiles are registered, reviewed, tested, and maintained as a community asset.</p> <p>Key Innovation: By treating profiles as registry entries with explicit versioning, documentation, and governance, we make entity schema management transparent, auditable, and community-driven\u2014solving the adoption and clarity problems that have plagued EntitySchema.</p>"},{"location":"SpiritSafe/#architecture-spiritsafe-in-the-data-distillery","title":"Architecture: SpiritSafe in the Data Distillery","text":""},{"location":"SpiritSafe/#the-data-distillery-metaphor","title":"The Data Distillery Metaphor","text":"<p>The Global Knowledge Commons (GKC) architecture uses whiskey distilling as its organizational metaphor:</p> <ul> <li>SpiritSafe \u2014 Registry of entity profiles (this document)</li> <li>Entity Profiles \u2014 The spirit (core product): YAML definitions of entity structure</li> <li>Cooperage \u2014 Code that shapes and prepares data (validation, coercion, transformation)</li> <li>Bottler \u2014 Final packages and exports (Wikidata JSON, Commons uploads, OSM relations)</li> <li>Shipper \u2014 Delivery to target platforms (Wikidata API, Commons, OSM)</li> </ul>"},{"location":"SpiritSafe/#spiritsafes-role","title":"SpiritSafe's Role","text":"<p>SpiritSafe is the registry layer that:</p> <ol> <li>Centralizes entity profiles that curators and developers need</li> <li>Maintains definition, versioning, and history of each entity type</li> <li>Provides controlled vocabularies (SPARQL-driven choice lists) used by profiles</li> <li>Enables community contribution under clear governance</li> <li>Documents each entity type's purpose, structure, and authorship</li> <li>Serves as the single source of truth for profile definitions in GKC workflows</li> </ol> <p>The gkc Python package fetches profiles and controlled vocabularies from SpiritSafe, validates them, and uses them to generate wizards, validators, and export logic. The <code>gkc.spirit_safe</code> module is the execution layer that loads profiles, hydrates choice lists, manages caches, and provides configuration for profile sources (GitHub or local).</p>"},{"location":"SpiritSafe/#directory-structure-profiles-as-registry-entries","title":"Directory Structure: Profiles as Registry Entries","text":""},{"location":"SpiritSafe/#rationale-for-per-profile-organization","title":"Rationale for Per-Profile Organization","text":"<p>Profiles are organized as self-contained packages rather than flat lists. This approach:</p> <ul> <li>Isolates changes: Modifications to one profile don't affect others</li> <li>Clarifies ownership: Each profile has explicit authorship and responsibility</li> <li>Enables clear versioning: Profile version history is tracked together with the profile</li> <li>Simplifies PR review: Reviewers examine a specific profile package</li> <li>Supports curation: Metadata (README, CHANGELOG) lives with the profile</li> <li>Scales: Adding new profiles doesn't require structural changes</li> </ul>"},{"location":"SpiritSafe/#structure","title":"Structure","text":"<pre><code>SpiritSafe/\n\u251c\u2500\u2500 README.md                           # Registry overview and contribution guide\n\u251c\u2500\u2500 profiles/                           # All registered entity profiles\n\u2502   \u251c\u2500\u2500 TribalGovernmentUS/\n\u2502   \u2502   \u251c\u2500\u2500 profile.yaml               # YAML profile definition\n\u2502   \u2502   \u251c\u2500\u2500 metadata.yaml              # Profile metadata (version, status, authors)\n\u2502   \u2502   \u251c\u2500\u2500 README.md                  # Profile documentation and use cases\n\u2502   \u2502   \u251c\u2500\u2500 CHANGELOG.md               # Version history and change log\n\u2502   \u2502   \u2514\u2500\u2500 queries/                   # SPARQL queries for this profile\n\u2502   \u2502       \u251c\u2500\u2500 tribal-recognition-references.sparql\n\u2502   \u2502       \u2514\u2500\u2500 tribal-government-offices.sparql\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 OfficeHeldByHeadOfState/\n\u2502   \u2502   \u251c\u2500\u2500 profile.yaml\n\u2502   \u2502   \u251c\u2500\u2500 metadata.yaml\n\u2502   \u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2502   \u251c\u2500\u2500 CHANGELOG.md\n\u2502   \u2502   \u2514\u2500\u2500 queries/\n\u2502   \u2502       \u251c\u2500\u2500 government-office-classifications.sparql\n\u2502   \u2502       \u2514\u2500\u2500 head-of-state-government-types.sparql\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 [additional profiles...]\n\u2502\n\u251c\u2500\u2500 queries/                            # Shared/common SPARQL queries\n\u2502   \u251c\u2500\u2500 wikidata-items-by-type.sparql\n\u2502   \u2514\u2500\u2500 [other shared queries...]\n\u2502\n\u251c\u2500\u2500 cache/                              # Cached SPARQL results\n\u2502   \u2514\u2500\u2500 [managed by hydration process]\n\u2502\n\u2514\u2500\u2500 .github/\n    \u251c\u2500\u2500 workflows/\n    \u2502   \u251c\u2500\u2500 validate-profile.yml       # Validate profile on PR\n    \u2502   \u251c\u2500\u2500 hydrate-caches.yml         # Refresh choice lists\n    \u2502   \u2514\u2500\u2500 publish-release.yml        # Tag and release on merge to main\n    \u2514\u2500\u2500 CONTRIBUTION.md                 # Community contribution guidelines\n</code></pre>"},{"location":"SpiritSafe/#directory-descriptions","title":"Directory Descriptions","text":""},{"location":"SpiritSafe/#profiles","title":"<code>profiles/</code>","text":"<p>Registry of all entity profile packages. Each subdirectory represents one entity type and contains:</p> <ul> <li><code>profile.yaml</code> \u2014 The GKC Entity Profile definition (canonical structure)</li> <li><code>metadata.yaml</code> \u2014 Profile metadata (see below)</li> <li><code>README.md</code> \u2014 Human-readable documentation of the entity type, use cases, and authorship</li> <li><code>CHANGELOG.md</code> \u2014 Version history with dates and change descriptions</li> <li><code>queries/</code> \u2014 SPARQL queries that generate controlled vocabularies for this profile's choice lists (optional, only if profile has SPARQL-driven allowed-item lists)</li> </ul>"},{"location":"SpiritSafe/#queries","title":"<code>queries/</code>","text":"<p>Shared SPARQL queries used across multiple profiles or commonly referenced. Individual profile queries live in <code>profiles/[name]/queries/</code>.</p>"},{"location":"SpiritSafe/#cache","title":"<code>cache/</code>","text":"<p>Cached results from SPARQL query hydration. Managed by CI workflow (see below). Structure mirrors the hierarchy for organization:</p> <pre><code>cache/\n\u251c\u2500\u2500 profiles/\n\u2502   \u251c\u2500\u2500 TribalGovernmentUS/\n\u2502   \u2502   \u251c\u2500\u2500 tribal-recognition-references.json\n\u2502   \u2502   \u2514\u2500\u2500 tribal-government-offices.json\n\u2502   \u2514\u2500\u2500 [...]\n\u2514\u2500\u2500 queries/\n    \u251c\u2500\u2500 wikidata-items-by-type.json\n    \u2514\u2500\u2500 [...]\n</code></pre>"},{"location":"SpiritSafe/#github","title":"<code>.github/</code>","text":"<p>GitHub workflows and contribution guidelines for the registry.</p>"},{"location":"SpiritSafe/#profile-metadata-registry-documentation","title":"Profile Metadata: Registry Documentation","text":"<p>Each profile includes a <code>metadata.yaml</code> file that captures essential information for registry management and profile discovery:</p> <pre><code># TribalGovernmentUS/metadata.yaml\n\nname: Federally Recognized Tribe\ndescription: &gt;\n  Canonical form for representing a federally recognized Native American tribe\n  in the United States. Based on Wikidata EntitySchema E502 concepts but extended\n  with additional properties and enhanced validation.\n\nversion: 1.0.0                          # Semantic versioning\nstatus: stable                          # stable | beta | deprecated\npublished_date: 2026-02-15\n\nauthors:\n  - name: Sky Bristol\n    contact: sky@example.org\n    role: primary\n\nmaintainers:\n  - name: Sky Bristol\n    contact: sky@example.org\n\nsource_references:\n  - name: Wikidata EntitySchema E502\n    url: https://www.wikidata.org/wiki/EntitySchema:E502\n  - name: United States Bureau of Indian Affairs\n    url: https://www.bia.gov/\n\nrelated_profiles:\n  - OfficeHeldByHeadOfState  # Profiles related to hierarchies/governance\n  - GovernmentAgency\n\ncommunity_feedback:\n  email: profiles@example.org\n  issue_tracker: https://github.com/skybristol/SpiritSafe/issues\n\n# Profile capabilities summary (from profile.yaml - referenced for discovery)\ndatatypes_used:\n  - item\n  - string\n  - quantity\n  - url\n\nstatements_count: 12\nreferences_required: true\nqualifiers_used:\n  - sourcing_circumstances\n  - applies_to_territorial_jurisdiction\n</code></pre>"},{"location":"SpiritSafe/#metadata-fields","title":"Metadata Fields","text":"Field Required Purpose <code>name</code> Yes Display name of the entity type <code>description</code> Yes What this entity type represents <code>version</code> Yes Semantic version (MAJOR.MINOR.PATCH) <code>status</code> Yes stable, beta, or deprecated <code>published_date</code> Yes ISO 8601 date of current version <code>authors</code> Yes Primary profile designer(s) <code>maintainers</code> Yes Current profile maintainer(s) <code>source_references</code> No References (EntitySchema, Wikidata items, external resources) <code>related_profiles</code> No Other profiles this type relates to <code>community_feedback</code> No Where to report issues or suggest changes <code>datatypes_used</code> No List of datatypes used (for discovery) <code>statements_count</code> No Number of statements (for discovery)"},{"location":"SpiritSafe/#profile-documentation-readme-and-changelog","title":"Profile Documentation: README and CHANGELOG","text":""},{"location":"SpiritSafe/#readmemd","title":"README.md","text":"<p>Each profile includes a <code>README.md</code> that explains:</p> <ol> <li>What is this entity? \u2014 Plain-language explanation (e.g., \"A federally recognized Native American tribe in the United States\")</li> <li>When to use this profile \u2014 Guidance for profile designers on when to apply this entity type</li> <li>Key statements \u2014 List of primary properties that define this entity type</li> <li>Example entity \u2014 A real Wikidata item that exemplifies this type (with QID and link)</li> <li>Known issues or limitations \u2014 If any (e.g., \"Sitelinks currently support English Wikipedia only\")</li> <li>Future enhancements \u2014 Planned additions or improvements</li> <li>Contributing \u2014 How to propose changes to this profile</li> </ol> <p>Example structure: <pre><code># Federally Recognized Tribe\n\n## What is this entity?\n\nA Federally Recognized Tribe is a Native American tribe formally recognized \nby the United States Bureau of Indian Affairs...\n\n## When to use this profile\n\nUse TribalGovernmentUS when creating Wikidata items for:\n- A specific federally recognized tribe\n- NOT for historical tribes pre-dating federal recognition\n- NOT for state-recognized but not federally recognized tribes\n\n## Key Statements\n\n- **Instance of (P31)**: Indicates this is a tribe organization\n- **Government type (P1313)**: What form of government (tribal council, elected chief, etc.)\n- **Country (P17)**: Always United States\n\n## Example Entity\n\nBitterroot Salish Tribe: [Q24279783](https://www.wikidata.org/wiki/Q24279783)\n\n## Known Issues\n\n- Geographic data not yet integrated; coordinate fields are theoretical\n\n## Contributing\n\nTo propose changes to this profile:\n1. Fork SpiritSafe repository\n2. Create a branch: `feature/tribal-government-update`\n3. Edit `profiles/TribalGovernmentUS/profile.yaml` and this README\n4. Submit PR with explanation of change\n5. Await maintainer review\n</code></pre></p>"},{"location":"SpiritSafe/#changelogmd","title":"CHANGELOG.md","text":"<p>Tracks all changes to a profile, enabling clear version history:</p> <pre><code># Changelog: TribalGovernmentUS\n\n## [1.0.0] - 2026-02-15\n\n### Added\n- Initial stable release\n- 12 statements fully defined\n- Support for official website, member count, headquarters location\n- Per-language labels, descriptions, aliases\n- SPARQL-driven allowed-items lists for tribe classification\n\n### Fixed\n- Corrected P1313 (government type) reference constraints\n\n### Deprecated\n- Legacy `preferred_name` field (use label instead)\n\n## [0.9.0] - 2026-01-20\n\n### Added\n- Beta release for community feedback\n- Initial profile structure\n- SPARQL queries for tribal classification\n\n### Changed\n- Restructured qualifiers for sourcing_circumstances\n</code></pre>"},{"location":"SpiritSafe/#branch-strategy-and-pr-process","title":"Branch Strategy and PR Process","text":""},{"location":"SpiritSafe/#branch-naming","title":"Branch Naming","text":"<ul> <li>main: Production-ready profiles, passing all CI checks, approved by maintainers</li> <li>develop (optional): Staging integration branch for coordinated changes</li> <li>feature branches: Created by contributors for new or modified profiles</li> <li>Format: <code>profile/[profile-name]-[description]</code> or <code>feature/[profile-name]-[description]</code></li> <li>Example: <code>profile/tribal-government-update</code>, <code>feature/add-office-schema</code></li> </ul>"},{"location":"SpiritSafe/#contribution-workflow","title":"Contribution Workflow","text":"<ol> <li> <p>Create branch from main    <pre><code>git checkout -b profile/tribal-government-update\n</code></pre></p> </li> <li> <p>Edit profile files</p> </li> <li>Modify <code>profiles/TribalGovernmentUS/profile.yaml</code></li> <li>Update <code>profiles/TribalGovernmentUS/CHANGELOG.md</code></li> <li>Update <code>profiles/TribalGovernmentUS/metadata.yaml</code> (increment version)</li> <li>Update <code>profiles/TribalGovernmentUS/README.md</code> if needed</li> <li> <p>Add/modify SPARQL queries as needed</p> </li> <li> <p>Push and create PR</p> </li> <li>Draft PR if work in progress</li> <li>Final PR when ready for review</li> <li> <p>Description includes: why change, what changed, validation results</p> </li> <li> <p>Automated checks (run on PR)</p> </li> <li>Profile YAML validation</li> <li>SPARQL query syntax check</li> <li>Metadata completeness validation</li> <li> <p>Choice list hydration from SPARQL queries (cache generation)</p> </li> <li> <p>Human review (maintainer)</p> </li> <li>Review profile changes against design principles</li> <li>Validate metadata accuracy</li> <li>Ensure documentation is clear and complete</li> <li> <p>Approve or request changes</p> </li> <li> <p>Merge to main</p> </li> <li>Once approved, PR is merged</li> <li>Version tags created automatically (from metadata.yaml)</li> <li>Release notes generated from CHANGELOG.md</li> </ol>"},{"location":"SpiritSafe/#cicd-pipeline-validation-and-hydration","title":"CI/CD Pipeline: Validation and Hydration","text":"<p>The SpiritSafe repository uses GitHub Actions workflows to ensure profile quality and maintain cached choice lists. Workflows are triggered on PR creation, PR updates, and manual triggers.</p>"},{"location":"SpiritSafe/#workflow-1-validate-profileyml-on-pr","title":"Workflow 1: <code>validate-profile.yml</code> (On PR)","text":"<p>Purpose: Validate all profiles and SPARQL queries in the PR</p> <p>Steps:</p> <ol> <li>Profile YAML Validation</li> <li>Load each profile YAML</li> <li>Validate against GKC profile schema</li> <li>Check for required fields (profile name, description, statements)</li> <li> <p>Report any validation errors</p> </li> <li> <p>SPARQL Query Validation</p> </li> <li> <p>Syntax check: Is each SPARQL query well-formed?</p> </li> <li>Test query execution: Can the query run against Wikidata?</li> <li> <p>Report query execution errors or warnings</p> </li> <li> <p>Metadata Validation</p> </li> <li> <p>Check metadata.yaml completeness</p> </li> <li>Verify semantic versioning (MAJOR.MINOR.PATCH)</li> <li>Validate author/maintainer existence</li> <li> <p>Report missing or malformed metadata</p> </li> <li> <p>Documentation Check</p> </li> <li> <p>README.md exists and has required sections</p> </li> <li>CHANGELOG.md documents the version being published</li> <li>Check for obvious typos or formatting issues</li> </ol> <p>Output: Required checks pass/fail on PR; blocks merge if critical issues found</p>"},{"location":"SpiritSafe/#workflow-2-hydrate-cachesyml-on-pr-manual","title":"Workflow 2: <code>hydrate-caches.yml</code> (On PR + Manual)","text":"<p>Purpose: Generate cached choice lists by executing SPARQL queries</p> <p>Steps:</p> <ol> <li>For each profile with SPARQL queries:</li> <li>Execute each SPARQL query against live Wikidata endpoint</li> <li>Transform results to JSON format expected by GKC</li> <li> <p>Cache results in <code>cache/profiles/[profile-name]/</code></p> </li> <li> <p>For shared queries in <code>queries/</code>:</p> </li> <li>Execute each query</li> <li> <p>Cache results in <code>cache/queries/</code></p> </li> <li> <p>Fallback behavior:</p> </li> <li>If Wikidata endpoint is unavailable, use previously cached results</li> <li>Log warnings about cache staleness</li> </ol> <p>Trigger:  - Manual trigger on-demand (when editor knows Wikidata data has changed) - Scheduled weekly or monthly (configurable) - Run on merge to main (to ensure main always has fresh caches)</p> <p>Output: Updated cache files committed to PR or automatically committed to main after merge</p>"},{"location":"SpiritSafe/#workflow-3-publish-releaseyml-on-main-merge","title":"Workflow 3: <code>publish-release.yml</code> (On main merge)","text":"<p>Purpose: Tag and release profile changes</p> <p>Steps:</p> <ol> <li>Extract version from metadata.yaml</li> <li>Create git tag with version (e.g., <code>v1.0.0</code>)</li> <li>Generate release notes from CHANGELOG.md</li> <li>Create GitHub Release with tag, notes, and attached cache files</li> <li>Optional: Push updated cache to CDN or package registry for distribution</li> </ol> <p>Output: Versioned release of profile package available for download</p>"},{"location":"SpiritSafe/#integration-with-gkc-the-spirit_safe-module","title":"Integration with GKC: The spirit_safe Module","text":"<p>The <code>gkc.spirit_safe</code> module in the GKC Python package is the execution layer that consumes SpiritSafe registry assets. It:</p>"},{"location":"SpiritSafe/#profile-loading","title":"Profile Loading","text":"<pre><code>from gkc.spirit_safe import SpiritSafeSourceConfig, set_spirit_safe_source\nfrom gkc.profiles import ProfileLoader\n\n# Configure source (GitHub or local SpiritSafe)\nset_spirit_safe_source(\n    mode=\"github\",\n    github_repo=\"skybristol/SpiritSafe\",\n    github_ref=\"main\"\n)\n\n# Load profile\nloader = ProfileLoader()\nprofile = loader.load_from_file(\"profiles/TribalGovernmentUS/profile.yaml\")\n</code></pre>"},{"location":"SpiritSafe/#choice-list-hydration","title":"Choice List Hydration","text":"<pre><code>from gkc.spirit_safe import LookupCache\n\n# Initialize cache (uses configured SpiritSafe source)\ncache = LookupCache()\n\n# Get cached choice list results\ntribal_refs = cache.get(\"profiles/TribalGovernmentUS/tribal-recognition-references\")\n\n# If cache miss or refresh needed, execute SPARQL query and update cache\n</code></pre>"},{"location":"SpiritSafe/#configuration","title":"Configuration","text":"<ul> <li>GitHub mode (default): Profiles fetched from https://raw.githubusercontent.com/skybristol/SpiritSafe/main/...</li> <li>Local mode: Profiles loaded from local SpiritSafe clone (for development)</li> </ul>"},{"location":"SpiritSafe/#source-of-truth-status","title":"Source-of-Truth Status","text":"<p>SpiritSafe is now fully externalized and serves as the active source of truth at:</p> <ul> <li>https://github.com/skybristol/SpiritSafe</li> </ul> <p>GKC no longer relies on a <code>.SpiritSafe/</code> directory inside the GKC repository.</p> <p>For local development overrides, clone SpiritSafe and point GKC to that clone path when needed.</p> <pre><code>git clone https://github.com/skybristol/SpiritSafe.git\ncd SpiritSafe\ngit checkout -b your-feature-branch\n</code></pre> <p>Then use local override in GKC runtime/CLI for branch validation and hydration tests.</p>"},{"location":"SpiritSafe/#theoretical-design-notes-for-infrastructure-development","title":"Theoretical Design Notes for Infrastructure Development","text":"<p>The following elements are designed but not yet fully implemented. These notes guide infrastructure development:</p>"},{"location":"SpiritSafe/#1-automated-cache-refresh-pipeline","title":"1. Automated Cache Refresh Pipeline","text":"<p>Goal: Keep choice list caches fresh without manual intervention Approach:</p> <ul> <li>Schedule hydration workflow weekly or monthly</li> <li>Fallback to previous cache if Wikidata endpoint unavailable</li> <li>Log staleness warnings so curators know if data is outdated</li> <li>Optional: Push updated caches to CDN for faster retrieval</li> </ul> <p>Open Questions:</p> <ul> <li>What refresh cadence makes sense? (weekly, monthly, quarterly by profile?)</li> <li>Should each profile have its own refresh schedule or unified?</li> <li>How to handle transient Wikidata outages without generating false positives?</li> </ul>"},{"location":"SpiritSafe/#2-profile-versioning-and-backward-compatibility","title":"2. Profile Versioning and Backward Compatibility","text":"<p>Goal: Support multiple profile versions without breaking existing curated data Approach:</p> <ul> <li>Each profile version gets a git tag (v1.0.0, v1.1.0, etc.)</li> <li>GKC can specify which profile version to use: <code>ProfileLoader.load(\"TribalGovernmentUS@1.0.0\")</code></li> <li>Profile schema migration paths for major version changes</li> <li>Curated data can be validated against original profile version used</li> </ul> <p>Open Questions:</p> <ul> <li>How to store multiple versions in single directory (folder per version, or git history)?</li> <li>When to enforce migration vs. allow legacy data?</li> <li>How to document breaking changes in CHANGELOG for curators?</li> </ul>"},{"location":"SpiritSafe/#3-profile-discoverability-and-registry-index","title":"3. Profile Discoverability and Registry Index","text":"<p>Goal: Curators and developers can discover available profiles Approach:</p> <ul> <li>Generate registry index (JSON) listing all profiles with metadata</li> <li>Web UI or CLI command to search/browse profiles</li> <li>Tag-based discovery (e.g., \"government\", \"tribal\", \"organization\")</li> <li>Community contributions feed to show recently updated profiles</li> </ul> <p>Open Questions:</p> <ul> <li>Should profiles be tagged/categorized?</li> <li>How to balance ease of discovery vs. avoiding profile explosion?</li> <li>How to recommend profiles for a given use case?</li> </ul>"},{"location":"SpiritSafe/#4-profile-lifecycle-management","title":"4. Profile Lifecycle Management","text":"<ul> <li><code>status: deprecated</code> in metadata sends signal to users</li> <li>Automatic archive after X period of no updates</li> <li>Formal retirement process with data migration guidance</li> <li>Audit trail of profile creation \u2192 active \u2192 deprecated \u2192 archived</li> </ul> <p>Open Questions: ofile creation \u2192 active \u2192 deprecated \u2192 archived</p> <p>Open Questions: - What triggers deprecation (maintainer decision, community vote)? - How to handle curated data when profile retires? - How to preserve profile history (GitHub releases)?</p>"},{"location":"SpiritSafe/#community-and-governance","title":"Community and Governance","text":""},{"location":"SpiritSafe/#who-can-contribute","title":"Who Can Contribute?","text":"<p>Community members can propose new profiles or changes to existing profiles via PR. All contributions must:</p> <ul> <li>Follow the profile schema and structure</li> <li>Include complete documentation (README, CHANGELOG, metadata)</li> <li>Pass all CI validation</li> <li>Be reviewed and approved by at least one maintainer</li> </ul>"},{"location":"SpiritSafe/#decision-making","title":"Decision Making","text":"<ul> <li>Profile additions: Maintainer approval + community consensus for significant new types</li> <li>Profile changes: Maintainer approval; breaking changes require community discussion</li> <li>Infrastructure decisions: Maintainers meet quarterly or as needed</li> </ul>"},{"location":"SpiritSafe/#reporting-issues-or-suggestions","title":"Reporting Issues or Suggestions","text":"<ul> <li>Bug reports: GitHub Issues (e.g., \"Profile X documentation is unclear\")</li> <li>Feature suggestions: Discussion forum or email (see metadata.yaml <code>community_feedback</code>)</li> <li>Contributing a new profile: Create PR with complete profile package</li> </ul>"},{"location":"SpiritSafe/#conclusion","title":"Conclusion","text":"<p>SpiritSafe reimagines entity schema management through a community-driven registry model. By treating profiles as curated, versioned, documented packages with transparent governance, we overcome adoption barriers that have hindered Wikidata EntitySchema. The per-profile folder structure keeps contributions manageable, the metadata and documentation make profiles discoverable, and CI/CD automation ensures quality.</p> <p>As the GKC ecosystem matures, SpiritSafe will become the standard registry of entity types for the Global Knowledge Commons\u2014a reference point where users can find, understand, and contribute to canonical entity definitions across platforms.</p>"},{"location":"tribes/","title":"Filling in lots of blanks","text":"<p>The following is a data development narrative for the Global Knowledge Commons and the Data Distillery capability we are building here. It focuses on the work of bringing overall content in the Commons up to date on the federally recognized Tribal Governments in the U.S.</p>"},{"location":"tribes/#background","title":"Background","text":"<p>I finally finished up my work the other day getting the last of the missing Alaska Native Tribes that are recognized by the U.S. federal government into Wikidata. I had to finally make a call that we needed entities representing official tribal governments even in those cases where a village name showed up in Wikidata via processing of U.S. Census data.</p> <p>This means we now have 575 total items in Wikidata classified as federally recognized Native American tribes in the United States with the recent addition of the Lumbee Tribe of North Carolina.</p> <pre><code>SELECT ?tribe ?tribeLabel ?native_label ?url\n?officeHeldByHeadOfGovernmentLabel ?officeHeldByHeadOfStateLabel\n?hqLocationLabel\nWHERE {\n  ?tribe wdt:P31 wd:Q7840353 .\n  OPTIONAL {\n    ?tribe wdt:P1705 ?nativeLabel .\n  }\n  OPTIONAL {\n    ?tribe wdt:P856 ?url .\n  }\n  OPTIONAL {\n    ?tribe wdt:P1313 ?officeHeldByHeadOfGovernment .\n  }\n  OPTIONAL {\n    ?tribe wdt:P1906 ?officeHeldByHeadOfGovernment .\n  }\n  OPTIONAL {\n    ?tribe wdt:P159 ?hqLocation .\n  }\n  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\n</code></pre> <p>Now the challenge is digging into filling in the rest of the blanks in the still developing Entity Schema for U.S. tribes.</p>"},{"location":"tribes/#whats-important","title":"What's important?","text":"<p>I included the query that I did above, because it highlights some of the major attributes I am working to fill in this work that is geared very much toward bolstering and explaining Tribal sovereighnty. Tribes fill a unique niche in U.S. politics, as sovereign nation states within the boundaries of the Unites States. Tribal sovereignty has been upheld time and time again as U.S. courts, all the way to the Supreme Court, recognizes that tribes existed as cohesive governmental/political entities well before the invention of the United States. We don't always win, but when the law is followed, we do.</p> <p>By designing the schema for these tribal governments on a similar footing with other sovereign states, we can hopefully help to fill in some really important gaps in the U.S. education system that constantly has tribal leaders today having to provide basic education to government officialsa and politicians in other governments (Federal, State, local). For tribal citizens, there is often a whole lot going on in tribal politics. This may be especially true in larger tribes with many government services at stake, but even small villages with a couple dozen citizens are sovereign states deserving of an equal footing within the Global Knowledge Commons.</p>"},{"location":"tribes/#current-state","title":"Current state","text":"<p>Right now, if you run the query above (or go look at the results, you'll see a whole lot of missing values on these few basic fields. Starting right at the beginning, very few official web sites for tribal governments have been sussed out and recorded in Wikidata. Once we have those, though, we can usually track down things like whether the tribe refers to their head of government as Principle Chief, Council President, or any number of other titles. We have to create an item for the office, and then we can start building in logically flowing links like the person who holds that office now or past office holders who perhaps should also be recorded.</p> <p>The most comprehensive source maintained anywhere for tribal leaders is the Bureau of Indian Affairs' \"Tribal Leaders Directory\" that has been maintained for many years. However, this information is often horribly out of date for smaller tribes (who sometimes don't give two shits about the BIA), and it is completely lacking in any kind of context like the title of the office itself. The existence of the office(s) held by head of government/state, and represented legitimately in the digital realm, are arguably a hell of a lot more important from a tribal sovereignty standpoint than the current office holder.</p>"},{"location":"tribes/#how-to-go-about-it","title":"How to go about it","text":"<p>This is the kind of case where having a form tuned to aid in developing this concept makes good sense. While I could also build a simple spreadsheet, spend time filling it out, and then run a batch process, it's also kind of nice to just sit down and work on one particular line of thinking and research when I can, get data on board, and make incremental progress.</p> <p>Another similar case will be filling out headquarters locations. That one would be interesting in that we will be populating a claim/qualifiers/references in Wikidata but also getting these locations laid out in Open Street Maps, so it scratches the \"distributing information to multiple parts of the Commons\" itch.</p> <p>In reality, a data curator is likely to encounter and need to work on several different pieces of information at the same time that need to be organized and distributed out across platforms. I might first track down a web site, meaning I need to put an official URL statement on the item representing the tribe/tribal government and state something about how I found it in a reference. From the website, I'll hopefully get a headquarters address that I can go check on a map. That's going to get me a geospatial coordinate that can find its way into both Wikidata and OSM. I'll hopefull track down information about the government, how they are organized, and who's involved.</p> <p>From this exploration, I'm going to be developing lots of facts, some of which will require me to instantiate entire new items. There are lots of ways to accomplish this, but some type of fill-in-the-right-blanks form and have some software do the rest is what we're working to build in the gkc package. I'm also going to have just about everything I need to not only build structured data in Wikidata/OSM, but organize the appropriate bits of that into Wikipedia templates and do some writing on Wikipedia articles.</p>"},{"location":"tribes/#how-the-gkc-package-can-support-this-work","title":"How the gkc package can support this work","text":"<p>I initially worked up a Python notebook exploring the use of Pydantic as a admittedly Python-specific framework for encoding more of the useful details about what relatively complex data, bound for multiple systems and parts of systems should look like. We developed the idea of multi-profile framework, built within the metaphor-derived context of a Spirit Safe that will help validate and coerce data into the shapes we need across platforms.</p> <p>The central figure in the \"Profile Pantheon\" is the GKC Entity Profile. These are the types of things that should really all have published Entity Schemas in the Wikidata ecosystem, and we may well get more of those filled out. However, ShEx falls short on a number of fronts and is not yet (and likely not to become) a full part of making Wikidata do what it does. Both a tribal government in the U.S. and an office held by head of government should be encoded into GKC Entity Profiles.</p> <p>We also are developing the idea of Modulation Profiles, one or more of which go along with an Entity Profile. They spell out what exactly can be modulated (input, created, edited, etc.) for entities. As we can see in this use case, a Modulation Profile may also need to contain elements associated with more than one entity with content distributed across multiple platforms.</p> <p>Mash Bills and Barrel Profiles form the other two ends of the input/output spectrum. Mash Bills describe, also with Pydantic modeling, what comes from a given data source like a spreadsheet or an API. Barrel Profiles specify exactly what the data need to look like that are getting barrelled and shipped to Wikidata, Wikimedia Commons, OSM, Wikipedia templates, etc.</p> <p>In the Python notebook, we sketched out one specific example of a mult-part profile. The entity we used was a U.S. Federal Register notice, prompted by my need to create an item representing the latest 2026 listing in order to use it as a reference for re-classing the Lumbee a federally recognized tribe. We had the basics of an Entity Profile, a Modulation Profile, and a Barrel Profile all in one place. We added some code that used the details in these to generate an input form using ipywidgets. This followed some previous work where we supported a similar workflow using a command line and answering prompts.</p> <p>We're now at the point where we need to formalize this notional architecture to build out the parts of the Spirit Safe that will house, manage, and provision the profiles. We think we'll move that to its own Python package and repository within the Data Distillery ecosystem, but we'll start within the gkc package itself to prove things out.</p>"},{"location":"architecture/","title":"Architecture Overview","text":""},{"location":"architecture/#introduction","title":"Introduction","text":"<p>The Global Knowledge Commons (GKC) is a framework for understanding and working with structured knowledge across multiple open public platforms. The initial design focuses on Wikidata, Wikimedia Commons, Wikipedia templates, and OpenStreetMap.</p> <p>The project uses a data distillery metaphor to describe the pipeline that converts raw, heterogeneous inputs into validated, platform-ready outputs. Mash Bills describe incoming structure, Modulation Profiles guide transformation, GKC Entity Profiles define canonical entity forms, and Barrel Profiles represent downstream platform-specific targets.</p>"},{"location":"architecture/#architecture-documents","title":"Architecture Documents","text":"<p>This architecture section is split so implemented behavior is easier to locate:</p> <ul> <li>Profile Loading Architecture</li> <li>SpiritSafe Infrastructure</li> <li>Validation Architecture</li> </ul>"},{"location":"architecture/#core-concepts","title":"Core Concepts","text":""},{"location":"architecture/#gkc-entity","title":"GKC Entity","text":"<p>A GKC Entity is a semantically coherent representation of a real-world thing rooted in the Wikibase/Wikidata model and extended across platforms in the Global Knowledge Commons.</p> <p>Multiple platforms contribute to and consume a single GKC Entity:</p> <ul> <li>Wikibase/Wikidata foundation: Labels, descriptions, aliases, statements, qualifiers, references, and sitelinks.</li> <li>Linked entities: Item-valued statements naturally connect entities.</li> <li>Multi-entity workflows: One curation action may require adding or updating related entities.</li> <li>Cross-platform integration: Canonical data in Wikidata can drive content in Commons, Wikipedia, and OSM.</li> </ul>"},{"location":"architecture/#gkc-entity-profile","title":"GKC Entity Profile","text":"<p>A GKC Entity Profile is a YAML specification that defines entity structure, datatype constraints, qualifiers, references, and SPARQL-driven allowed-items hydration.</p> <p>Profiles encode:</p> <ul> <li>Statement structure and requiredness.</li> <li>Datatype constraints for values, qualifiers, and references.</li> <li>Allowed-items hydration with fallback behavior.</li> <li>Curator guidance content used by profile-driven interfaces.</li> </ul> <p>For profile details, see Entity Profiles.</p>"},{"location":"architecture/#spiritsafe","title":"SpiritSafe","text":"<p>SpiritSafe is the profile registry and supporting query/cache infrastructure. It stores profile packages (<code>profile.yaml</code>, <code>metadata.yaml</code>, docs, and <code>queries/</code>) and provides a source for GKC runtime loading in local or GitHub-backed modes.</p> <p>For implementation details, see SpiritSafe Infrastructure.</p>"},{"location":"architecture/#theoretical-design-notes","title":"Theoretical Design Notes","text":"<p>The following are directionally important but not yet fully implemented as stable architecture in GKC:</p> <ul> <li>Wizard execution environments beyond current local Python interfaces.</li> <li>Expanded profile composition and branching workflow semantics.</li> <li>Additional cross-platform publishing orchestration beyond current shipping abstractions.</li> </ul> <p>These are retained as design intent for follow-on implementation work by the Wizard Engineer and Validation Agent.</p>"},{"location":"architecture/profile-loading/","title":"Profile Loading Architecture","text":""},{"location":"architecture/profile-loading/#implementation-status","title":"Implementation Status","text":"<p>This page documents implemented and architecturally committed behavior for profile loading in GKC and SpiritSafe-backed sources.</p>"},{"location":"architecture/profile-loading/#resolution-model","title":"Resolution Model","text":"<p>GKC resolves a profile reference through <code>resolve_profile_path()</code> using the canonical registrant layout:</p> <ul> <li><code>ProfileName</code> \u2192 <code>profiles/ProfileName/profile.yaml</code></li> <li><code>ProfileName.yaml</code> \u2192 <code>profiles/ProfileName/profile.yaml</code></li> <li>Explicit paths are preserved as provided.</li> </ul> <p>Compatibility fallback supports legacy flat layout during migration:</p> <ul> <li><code>profiles/Foo/profile.yaml</code> can fall back to <code>profiles/Foo.yaml</code></li> <li><code>profiles/Foo.yaml</code> can fall back to <code>profiles/Foo/profile.yaml</code></li> </ul>"},{"location":"architecture/profile-loading/#source-modes","title":"Source Modes","text":"<p>Profile loading is source-configured through <code>SpiritSafeSourceConfig</code>:</p> <ul> <li><code>mode: github</code> (default)</li> <li><code>mode: local</code></li> </ul> <p>In GitHub mode, SpiritSafe-relative paths resolve to raw GitHub URLs. In local mode, paths resolve against <code>local_root</code>.</p>"},{"location":"architecture/profile-loading/#query-reference-resolution","title":"Query Reference Resolution","text":"<p>Hydration resolves <code>query_ref</code> deterministically with <code>resolve_query_ref()</code>:</p> <ol> <li>Profile-relative first (for registrant layout).</li> <li>Root-relative fallback.</li> </ol> <p>For registrant profiles, <code>queries/foo.sparql</code> is attempted first as:</p> <ul> <li><code>profiles/&lt;Profile&gt;/queries/foo.sparql</code></li> </ul> <p>then as:</p> <ul> <li><code>queries/foo.sparql</code></li> </ul>"},{"location":"architecture/profile-loading/#failure-behavior","title":"Failure Behavior","text":"<ul> <li>Missing profile files raise path resolution errors after fallback attempts.</li> <li>Missing query files raise <code>FileNotFoundError</code> with attempted paths.</li> <li>Hydration can either collect failures or fail fast based on <code>fail_on_query_error</code>.</li> </ul>"},{"location":"architecture/profile-loading/#theoretical-design-notes","title":"Theoretical Design Notes","text":"<ul> <li>Optional pinned-ref contract testing against SpiritSafe testing branches is not yet integrated into default CI behavior.</li> <li>Future profile version selection semantics (for example, explicit version targeting) remain open design work.</li> </ul>"},{"location":"architecture/spiritsafe-infrastructure/","title":"SpiritSafe Infrastructure","text":""},{"location":"architecture/spiritsafe-infrastructure/#implementation-status","title":"Implementation Status","text":"<p>This page describes implemented and committed SpiritSafe infrastructure as consumed by GKC.</p>"},{"location":"architecture/spiritsafe-infrastructure/#registry-package-shape","title":"Registry Package Shape","text":"<p>SpiritSafe profile registrants use package directories:</p> <ul> <li><code>profiles/&lt;ProfileID&gt;/profile.yaml</code></li> <li><code>profiles/&lt;ProfileID&gt;/metadata.yaml</code></li> <li><code>profiles/&lt;ProfileID&gt;/queries/*.sparql</code> (when applicable)</li> </ul> <p>Additional documentation files (<code>README.md</code>, <code>CHANGELOG.md</code>) are supported as registry artifacts.</p>"},{"location":"architecture/spiritsafe-infrastructure/#gkc-registry-abstractions","title":"GKC Registry Abstractions","text":"<p>GKC currently exposes registry-oriented utilities in <code>gkc.spirit_safe</code>:</p> <ul> <li><code>list_profiles()</code></li> <li><code>profile_exists(profile_id)</code></li> <li><code>get_profile_metadata(profile_id)</code></li> <li><code>ProfileMetadata</code> dataclass for structured metadata access</li> </ul> <p>These APIs operate in both configured source modes (<code>github</code> and <code>local</code>).</p>"},{"location":"architecture/spiritsafe-infrastructure/#caching-and-hydration","title":"Caching and Hydration","text":"<p>SPARQL hydration is profile-driven and cache-backed:</p> <ul> <li>Query templates can be inline (<code>query</code>) or referenced (<code>query_ref</code>).</li> <li>Hydration deduplicates rendered query text per endpoint.</li> <li>Cache files are written under source-specific cache directories.</li> </ul>"},{"location":"architecture/spiritsafe-infrastructure/#current-constraints","title":"Current Constraints","text":"<ul> <li>Profile discovery in GitHub mode currently depends on GitHub API directory listing.</li> <li>Metadata validation currently enforces required fields at runtime (<code>name</code>, <code>version</code>, <code>status</code>) without a separate published schema contract.</li> </ul>"},{"location":"architecture/spiritsafe-infrastructure/#theoretical-design-notes","title":"Theoretical Design Notes","text":"<ul> <li>A central SpiritSafe <code>registry.yaml</code> index is proposed but not yet implemented.</li> <li>Richer metadata taxonomy (categories, deprecation flags, featured profiles) remains an open design item.</li> <li>Explicit version/dependency constraints between profiles are not yet implemented.</li> </ul>"},{"location":"architecture/validation-architecture/","title":"Validation Architecture","text":""},{"location":"architecture/validation-architecture/#implementation-status","title":"Implementation Status","text":"<p>This page documents the currently implemented validation model and committed architectural direction.</p>"},{"location":"architecture/validation-architecture/#validation-layers","title":"Validation Layers","text":"<p>Validation in GKC is layered around profile-defined constraints:</p> <ul> <li>Profile definition validation: YAML is parsed into typed profile models.</li> <li>Entity data validation: Item/statement content is checked against profile requirements.</li> <li>Hydration input validation: Query references and templates are resolved before execution.</li> </ul>"},{"location":"architecture/validation-architecture/#profile-driven-rules","title":"Profile-Driven Rules","text":"<p>Entity profiles remain the source of truth for validation behavior, including:</p> <ul> <li>Required statements and cardinality.</li> <li>Datatype matching for statement values.</li> <li>Qualifier and reference rules.</li> <li>Allowed-items constraints and fallback behavior.</li> </ul>"},{"location":"architecture/validation-architecture/#runtime-validation-policy","title":"Runtime Validation Policy","text":"<p>Current policy behavior includes both permissive and strict paths depending on context:</p> <ul> <li>Existing non-conforming data can be tolerated where policy allows.</li> <li>New curation inputs are expected to follow profile-defined constraints.</li> </ul>"},{"location":"architecture/validation-architecture/#serialization-alignment","title":"Serialization Alignment","text":"<p>Validation and profile models are designed to support downstream serialization workflows without inventing ad hoc Wikidata JSON structures.</p>"},{"location":"architecture/validation-architecture/#theoretical-design-notes","title":"Theoretical Design Notes","text":"<ul> <li>Expanded cross-statement semantic validation is still evolving.</li> <li>Additional wizard-step-specific validation orchestration remains future work.</li> <li>A centralized, reusable constraint message library for all interfaces is not yet fully formalized.</li> </ul>"},{"location":"gkc/","title":"GKC Documentation","text":"<p>Welcome to the documentation for GKC (Global Knowledge Commons), a Python package for managing data and information contributions to Wikidata and related Wikimedia projects along with OpenStreetMap. This site covers the background, mapping formats, item creation workflow, sitelinks usage, and API reference.</p>"},{"location":"gkc/#getting-started","title":"Getting Started","text":"<ul> <li>Installation and setup - setting up to operate the software (aka make whiskey)</li> <li>Authentication - set up credentials for Wikimedia apps and OpenStreetMap</li> <li>Background - read about where the project came from and its motivations</li> <li>Architecture - major architectural concepts for the GKC and Data Distillery</li> <li>Profiles - comprehensive guide to building and using YAML profiles</li> </ul>"},{"location":"gkc/#data-distillery-workflow","title":"Data Distillery Workflow","text":"<p>The following sections lay out the extract, transform and load (ETL) workflow the GKC package is designed to support - messy and disconnected data in to refined and linked open data out.</p>"},{"location":"gkc/#profile-development","title":"Profile Development","text":"<ul> <li>SpiritSafe YAML Profiles - Complete reference for defining entity profiles with all datatypes, constraints, and patterns</li> </ul>"},{"location":"gkc/#data-ingestion-mash-tun","title":"Data Ingestion (mash tun)","text":"<ul> <li>Schema building - present a list of properties or existing Wikidata item to get the start to an entity schema</li> <li>Data source annotation - review and enhance annotation on data sources</li> <li>Mystery data sniffer - evaluating source data to produce a best-guess data map</li> </ul>"},{"location":"gkc/#development-notes","title":"Development Notes","text":"<p>The GitHub repo for the project maintains a wealth of background on architectural decisions and code design in issues and pull requests.</p>"},{"location":"gkc/#cicd","title":"CI/CD","text":"<ul> <li>CI/CD</li> <li>Release Process</li> </ul>"},{"location":"gkc/#api-reference","title":"API Reference","text":"<ul> <li>API Reference</li> </ul>"},{"location":"gkc/CI_CD/","title":"CI/CD Configuration","text":"<p>This document describes the continuous integration and deployment setup for the GKC project.</p>"},{"location":"gkc/CI_CD/#overview","title":"Overview","text":"<p>The project uses GitHub Actions for CI/CD with two main workflows: 1. CI Workflow - Runs tests, linting, and type checking on every PR and push to main 2. Publish Workflow - Automatically publishes to PyPI when a GitHub release is created</p>"},{"location":"gkc/CI_CD/#local-pre-merge-testing","title":"Local Pre-Merge Testing","text":""},{"location":"gkc/CI_CD/#quick-check","title":"Quick Check","text":"<p>Before pushing or creating a PR, run the pre-merge check script:</p> <pre><code>./scripts/pre-merge-check.sh\n</code></pre> <p>This script will: - \u2713 Install/sync dependencies - \u2713 Run ruff linting - \u2713 Check code formatting (black) - \u2713 Run type checking (mypy) - \u2713 Execute full test suite - \u2713 Verify package builds</p>"},{"location":"gkc/CI_CD/#manual-testing","title":"Manual Testing","text":"<p>You can also run individual checks:</p> <pre><code># Install dependencies\npoetry install --sync\n\n# Run linting\npoetry run ruff check gkc tests\n\n# Check formatting\npoetry run black --check gkc tests\n\n# Auto-fix formatting\npoetry run black gkc tests\n\n# Run type checking\npoetry run mypy gkc\n\n# Run tests\npoetry run pytest -v\n\n# Run tests with coverage\npoetry run pytest --cov=gkc --cov-report=html\n\n# Build package\npoetry build\n</code></pre>"},{"location":"gkc/CI_CD/#ci-workflow-githubworkflowsciyml","title":"CI Workflow (<code>.github/workflows/ci.yml</code>)","text":""},{"location":"gkc/CI_CD/#triggers","title":"Triggers","text":"<ul> <li>Push to <code>main</code> branch</li> <li>Pull requests targeting <code>main</code> branch</li> </ul>"},{"location":"gkc/CI_CD/#jobs","title":"Jobs","text":""},{"location":"gkc/CI_CD/#test-matrix","title":"Test Matrix","text":"<p>Runs tests on multiple Python versions: - Python 3.9 - Python 3.10 - Python 3.11 - Python 3.12</p> <p>Steps: 1. Checkout code 2. Set up Python 3. Install Poetry 4. Cache dependencies 5. Install dependencies 6. Run linting (ruff) 7. Check formatting (black) 8. Run type checking (mypy) - non-blocking 9. Run tests with coverage 10. Upload coverage to Codecov (optional)</p>"},{"location":"gkc/CI_CD/#lint-job","title":"Lint Job","text":"<p>Runs on Python 3.12 to verify code quality: - Ruff linting - Black formatting check</p>"},{"location":"gkc/CI_CD/#success-criteria","title":"Success Criteria","text":"<p>All tests must pass across all Python versions for the workflow to succeed. This ensures: - Code works on all supported Python versions - Code style is consistent - All tests pass - No import errors</p>"},{"location":"gkc/CI_CD/#publish-workflow-githubworkflowspublishyml","title":"Publish Workflow (<code>.github/workflows/publish.yml</code>)","text":""},{"location":"gkc/CI_CD/#trigger","title":"Trigger","text":"<p>Automatically runs when you create and publish a GitHub release.</p>"},{"location":"gkc/CI_CD/#publishing-method-pypi-trusted-publishing","title":"Publishing Method: PyPI Trusted Publishing","text":"<p>The workflow uses PyPI Trusted Publishing (OIDC), which is the modern, secure way to publish packages. This method: - \u2705 No API tokens needed - \u2705 More secure (temporary credentials) - \u2705 Automatic rotation - \u2705 Recommended by PyPI</p>"},{"location":"gkc/CI_CD/#setup-required","title":"Setup Required","text":"<p>Before your first release, you must configure Trusted Publishing on PyPI:</p> <ol> <li>Create PyPI account (if you don't have one):</li> <li> <p>Go to https://pypi.org/account/register/</p> </li> <li> <p>Configure Trusted Publishing:</p> </li> <li>Go to https://pypi.org/manage/account/publishing/</li> <li>Click \"Add a new pending publisher\"</li> <li>Fill in:<ul> <li>PyPI Project Name: <code>gkc</code></li> <li>Owner: <code>skybristol</code></li> <li>Repository name: <code>gkc</code></li> <li>Workflow name: <code>publish.yml</code></li> <li>Environment name: (leave blank)</li> </ul> </li> <li> <p>Click \"Add\"</p> </li> <li> <p>Important: You must do this before creating your first release. PyPI will reserve the project name for your GitHub repository.</p> </li> </ol>"},{"location":"gkc/CI_CD/#alternative-token-based-publishing","title":"Alternative: Token-Based Publishing","text":"<p>If you prefer using a token (though Trusted Publishing is recommended), modify <code>.github/workflows/publish.yml</code>:</p> <pre><code>- name: Publish package distributions to PyPI\n  uses: pypa/gh-action-pypi-publish@release/v1\n  with:\n    password: ${{ secrets.PYPI_TOKEN }}\n</code></pre> <p>And remove the <code>permissions: id-token: write</code> line.</p>"},{"location":"gkc/CI_CD/#creating-a-release","title":"Creating a Release","text":""},{"location":"gkc/CI_CD/#1-prepare-the-release","title":"1. Prepare the Release","text":"<pre><code># Ensure you're on main with latest changes\ngit checkout main\ngit pull origin main\n\n# Run pre-merge checks\n./scripts/pre-merge-check.sh\n\n# Update version in pyproject.toml\n# Edit: version = \"0.1.1\"  (or whatever the new version is)\n\n# Commit version bump\ngit add pyproject.toml\ngit commit -m \"Bump version to 0.1.1\"\ngit push origin main\n</code></pre>"},{"location":"gkc/CI_CD/#2-create-git-tag","title":"2. Create Git Tag","text":"<pre><code># Create and push tag\ngit tag -a v0.1.1 -m \"Release version 0.1.1\"\ngit push origin v0.1.1\n</code></pre>"},{"location":"gkc/CI_CD/#3-create-github-release","title":"3. Create GitHub Release","text":"<p>Option A: GitHub Web UI 1. Go to https://github.com/skybristol/gkc/releases/new 2. Choose the tag you just created (<code>v0.1.1</code>) 3. Set release title (e.g., \"v0.1.1\") 4. Add release notes describing changes 5. Click \"Publish release\"</p> <p>Option B: GitHub CLI <pre><code>gh release create v0.1.1 \\\n  --title \"v0.1.1\" \\\n  --notes \"Release notes here\"\n</code></pre></p>"},{"location":"gkc/CI_CD/#4-automated-publishing","title":"4. Automated Publishing","text":"<p>Once you publish the release: 1. GitHub Actions automatically triggers the publish workflow 2. Workflow builds the package 3. Package is published to PyPI 4. Within minutes, available via <code>pip install gkc</code></p>"},{"location":"gkc/CI_CD/#5-verify-publication","title":"5. Verify Publication","text":"<p>Check that the package is available: <pre><code># Wait a few minutes after release\npip install --upgrade gkc\n\n# Or check PyPI directly\nopen https://pypi.org/project/gkc/\n</code></pre></p>"},{"location":"gkc/CI_CD/#monitoring-workflows","title":"Monitoring Workflows","text":""},{"location":"gkc/CI_CD/#view-workflow-runs","title":"View Workflow Runs","text":"<ul> <li>All workflows: https://github.com/skybristol/gkc/actions</li> <li>CI runs: https://github.com/skybristol/gkc/actions/workflows/ci.yml</li> <li>Publish runs: https://github.com/skybristol/gkc/actions/workflows/publish.yml</li> </ul>"},{"location":"gkc/CI_CD/#debugging-failed-workflows","title":"Debugging Failed Workflows","text":"<p>If a workflow fails:</p> <ol> <li>Click on the failed run in GitHub Actions</li> <li>Expand the failed step to see error details</li> <li>Common issues:</li> <li>Test failures: Check test output</li> <li>Linting errors: Run <code>poetry run ruff check gkc tests</code></li> <li>Formatting issues: Run <code>poetry run black gkc tests</code></li> <li>Build errors: Run <code>poetry build</code> locally</li> <li> <p>PyPI publish errors: Check Trusted Publishing configuration</p> </li> <li> <p>Fix locally and re-push:    <pre><code># Fix the issue\n./scripts/pre-merge-check.sh  # Verify fix\ngit add .\ngit commit -m \"Fix CI issue\"\ngit push\n</code></pre></p> </li> </ol>"},{"location":"gkc/CI_CD/#version-management","title":"Version Management","text":""},{"location":"gkc/CI_CD/#semantic-versioning","title":"Semantic Versioning","text":"<p>Follow semantic versioning (semver): - MAJOR (1.0.0): Breaking changes - MINOR (0.1.0): New features, backwards compatible - PATCH (0.0.1): Bug fixes, backwards compatible</p>"},{"location":"gkc/CI_CD/#pre-releases","title":"Pre-releases","text":"<p>For testing releases before official publication:</p> <pre><code># Update version to pre-release\n# version = \"0.2.0-alpha.1\"\n\n# Create pre-release tag\ngit tag -a v0.2.0-alpha.1 -m \"Alpha release\"\ngit push origin v0.2.0-alpha.1\n\n# Create GitHub pre-release\ngh release create v0.2.0-alpha.1 \\\n  --title \"v0.2.0-alpha.1\" \\\n  --notes \"Alpha release for testing\" \\\n  --prerelease\n</code></pre> <p>Pre-releases won't be installed by default with <code>pip install gkc</code>, users must specify: <pre><code>pip install gkc==0.2.0-alpha.1\n</code></pre></p>"},{"location":"gkc/CI_CD/#security","title":"Security","text":""},{"location":"gkc/CI_CD/#secrets","title":"Secrets","text":"<p>Current repository secrets: - <code>PYPI_TOKEN</code> - Not needed if using Trusted Publishing, but kept as backup</p>"},{"location":"gkc/CI_CD/#permissions","title":"Permissions","text":"<p>The publish workflow requires: - <code>id-token: write</code> - For Trusted Publishing authentication</p>"},{"location":"gkc/CI_CD/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gkc/CI_CD/#package-already-exists-on-pypi","title":"\"Package already exists on PyPI\"","text":"<p>If you try to publish a version that already exists: 1. Delete the GitHub release 2. Delete the git tag: <code>git tag -d v0.1.0 &amp;&amp; git push origin :refs/tags/v0.1.0</code> 3. Bump version in pyproject.toml 4. Create new tag and release</p>"},{"location":"gkc/CI_CD/#trusted-publisher-not-configured","title":"\"Trusted Publisher not configured\"","text":"<p>Error: <code>403: The user 'xxx' isn't allowed to upload to project 'gkc'</code></p> <p>Solution: Configure Trusted Publishing on PyPI (see \"Setup Required\" above)</p>"},{"location":"gkc/CI_CD/#tests-pass-locally-but-fail-in-ci","title":"\"Tests pass locally but fail in CI\"","text":"<p>Common causes: - Python version differences (CI tests on 3.9-3.12) - Missing dependencies in pyproject.toml - Environment-specific code</p> <p>Debug: <pre><code># Test on specific Python version\npoetry env use 3.9\npoetry install\npoetry run pytest\n</code></pre></p>"},{"location":"gkc/CI_CD/#best-practices","title":"Best Practices","text":"<ol> <li>Always run pre-merge checks before pushing</li> <li>Never commit directly to main - use PRs for review</li> <li>Write meaningful commit messages following conventional commits</li> <li>Update CHANGELOG for each release</li> <li>Test the package after publishing: <code>pip install --upgrade gkc</code></li> <li>Monitor CI results - fix failures immediately</li> <li>Keep dependencies updated - run <code>poetry update</code> regularly</li> </ol>"},{"location":"gkc/CI_CD/#additional-resources","title":"Additional Resources","text":"<ul> <li>GitHub Actions Documentation</li> <li>PyPI Trusted Publishing Guide</li> <li>Poetry Publishing Documentation</li> <li>Semantic Versioning</li> </ul>"},{"location":"gkc/RELEASE/","title":"Release Process","text":"<p>This document describes how to plan, version, and publish releases for GKC.</p>"},{"location":"gkc/RELEASE/#versioning-policy","title":"Versioning Policy","text":"<p>GKC follows semantic versioning.</p> <ul> <li>Patch ($0.1.x$): bug fixes, small improvements, doc-only changes when publishing a release</li> <li>Minor ($0.x.0$): new features, non-breaking API additions</li> <li>Major ($1.0.0$): breaking changes or redesigns</li> </ul> <p>Notes: - Do not bump the version for every commit. Bump only when you are about to publish a release. - Doc-only changes do not require a PyPI release unless you want a new package build.</p>"},{"location":"gkc/RELEASE/#release-checklist","title":"Release Checklist","text":"<p>1) Verify clean working tree - <code>git status</code></p> <p>2) Run local checks - <code>./scripts/pre-merge-check.sh</code></p> <p>3) Decide version bump - Update the version in <code>pyproject.toml</code></p> <p>4) Update release notes - Add a short summary of changes in the GitHub release notes</p> <p>5) Commit the version bump - <code>git add pyproject.toml</code> - <code>git commit -m \"Bump version to X.Y.Z\"</code></p> <p>6) Tag the release - <code>git tag -a vX.Y.Z -m \"Release vX.Y.Z\"</code> - <code>git push origin vX.Y.Z</code></p> <p>7) Create GitHub release - Use the GitHub UI or CLI - Publishing the release triggers PyPI publishing via GitHub Actions</p> <p>8) Verify PyPI - <code>pip install --upgrade gkc</code> - Check https://pypi.org/project/gkc/</p>"},{"location":"gkc/RELEASE/#example","title":"Example","text":"<pre><code># Update version in pyproject.toml\n# version = \"0.1.1\"\n\ngit add pyproject.toml\ngit commit -m \"Bump version to 0.1.1\"\n\n# Tag and push\ngit tag -a v0.1.1 -m \"Release v0.1.1\"\ngit push origin v0.1.1\n\n# Create GitHub release (if you have gh CLI installed)\ngh release create v0.1.1 \\\n  --title \"v0.1.1\" \\\n  --notes \"Short summary of changes\"\n</code></pre>"},{"location":"gkc/RELEASE/#notes-on-documentation-only-changes","title":"Notes on Documentation-Only Changes","text":"<p>If you only update documentation and you do not need a new package build: - Skip the version bump - Skip tagging and release - Let GitHub Pages publish documentation updates</p> <p>If you want a new package release for documentation updates: - Follow the standard checklist and bump the patch version</p>"},{"location":"gkc/RELEASE/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If <code>poetry lock</code> fails, run <code>poetry lock --no-update</code> to sync the lockfile</li> <li>If <code>gh</code> is not installed, create the release in the GitHub web UI</li> <li>If PyPI publish fails, check the GitHub Actions logs and PyPI Trusted Publishing settings</li> </ul>"},{"location":"gkc/authentication/","title":"Authentication Guide","text":"<p>The GKC package provides authentication classes for Global Knowledge Commons services. You can provide credentials directly, via environment variables, or through interactive prompts.</p> <p>For detailed API documentation and examples, see the Authentication API Reference.</p>"},{"location":"gkc/authentication/#wikiverse-wikidata-wikipedia-wikimedia-commons","title":"Wikiverse (Wikidata, Wikipedia, Wikimedia Commons)","text":"<p>The <code>WikiverseAuth</code> class provides unified authentication for all Wikimedia projects using bot passwords. The same credentials work across Wikidata, Wikipedia, and Wikimedia Commons due to Wikimedia's Single User Login (SUL) system.</p>"},{"location":"gkc/authentication/#setting-up-bot-passwords","title":"Setting up Bot Passwords","text":"<ol> <li>Go to Special:BotPasswords on Wikidata</li> <li>Create a new bot password with appropriate permissions</li> <li>Your username will be in the format <code>YourUsername@BotName</code></li> <li>Save the generated password (you won't see it again!)</li> </ol>"},{"location":"gkc/authentication/#basic-usage","title":"Basic Usage","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\n\n# Method 1: Using environment variables (recommended)\nauth = WikiverseAuth()\nauth.login()\n\n# Method 2: Using explicit credentials\nauth = WikiverseAuth(\n    username=\"YourUsername@BotName\",\n    password=\"abc123def456ghi789\"\n)\nauth.login()\n\n# Method 3: Interactive prompt\nauth = WikiverseAuth(interactive=True)\nauth.login()\n\n# Check login status\nif auth.is_logged_in():\n    print(f\"Logged in as: {auth.get_account_name()}\")\n    print(f\"Bot name: {auth.get_bot_name()}\")\n</code></pre>"},{"location":"gkc/authentication/#targeting-different-wikimedia-projects","title":"Targeting Different Wikimedia Projects","text":"<pre><code># Wikidata (default)\nauth = WikiverseAuth(\n    username=\"User@Bot\",\n    password=\"secret\",\n    api_url=\"wikidata\"  # or just omit for default\n)\nauth.login()\n\n# Wikidata Test Instance (for testing and development)\nauth = WikiverseAuth(\n    username=\"User@Bot\",\n    password=\"secret\",\n    api_url=\"wikidata_test\"  # Points to test.wikidata.org\n)\nauth.login()\n\n# English Wikipedia\nauth = WikiverseAuth(\n    username=\"User@Bot\",\n    password=\"secret\",\n    api_url=\"wikipedia\"\n)\nauth.login()\n\n# Wikimedia Commons\nauth = WikiverseAuth(\n    username=\"User@Bot\",\n    password=\"secret\",\n    api_url=\"commons\"\n)\nauth.login()\n\n# Custom MediaWiki instance (e.g., enterprise wiki)\nauth = WikiverseAuth(\n    username=\"User@Bot\",\n    password=\"secret\",\n    api_url=\"https://wiki.mycompany.com/w/api.php\"\n)\nauth.login()\n</code></pre>"},{"location":"gkc/authentication/#making-authenticated-api-requests","title":"Making Authenticated API Requests","text":"<pre><code># After login, use the session for API requests\nauth = WikiverseAuth()\nauth.login()\n\n# Example: Query user information\nresponse = auth.session.get(auth.api_url, params={\n    \"action\": \"query\",\n    \"meta\": \"userinfo\",\n    \"format\": \"json\"\n})\nprint(response.json())\n\n# For editing, get a CSRF token\ntry:\n    csrf_token = auth.get_csrf_token()\n    print(f\"CSRF Token: {csrf_token}\")\nexcept AuthenticationError as e:\n    print(f\"Error: {e}\")\n\n# When done, logout\nauth.logout()\n</code></pre>"},{"location":"gkc/authentication/#helper-methods","title":"Helper Methods","text":"<pre><code>auth = WikiverseAuth(username=\"Alice@MyBot\", password=\"secret\")\n\n# Extract account name\nprint(auth.get_account_name())  # Output: \"Alice\"\n\n# Extract bot name\nprint(auth.get_bot_name())  # Output: \"MyBot\"\n\n# Check authentication state\nprint(auth.is_authenticated())  # Has credentials\nprint(auth.is_logged_in())      # Successfully logged in to API\n</code></pre>"},{"location":"gkc/authentication/#openstreetmap","title":"OpenStreetMap","text":"<pre><code>from gkc import OpenStreetMapAuth\n\n# Method 1: Using explicit credentials\nauth = OpenStreetMapAuth(username=\"your_username\", password=\"your_password\")\n\n# Method 2: Using environment variables (OPENSTREETMAP_USERNAME, OPENSTREETMAP_PASSWORD)\nauth = OpenStreetMapAuth()\n\n# Method 3: Interactive prompt\nauth = OpenStreetMapAuth(interactive=True)\n\n# Check authentication status\nif auth.is_authenticated():\n    print(\"Authenticated successfully!\")\n</code></pre>"},{"location":"gkc/authentication/#environment-variables","title":"Environment Variables","text":"<p>You can set the following environment variables for automatic authentication:</p>"},{"location":"gkc/authentication/#wikimedia-projects","title":"Wikimedia Projects","text":"<ul> <li><code>WIKIVERSE_USERNAME</code> - Bot password username (format: Username@BotName)</li> <li><code>WIKIVERSE_PASSWORD</code> - Bot password</li> <li><code>WIKIVERSE_API_URL</code> - (Optional) MediaWiki API endpoint. Defaults to Wikidata. Can use shortcuts: \"wikidata\", \"wikidata_test\", \"wikipedia\", \"commons\"</li> </ul>"},{"location":"gkc/authentication/#openstreetmap_1","title":"OpenStreetMap","text":"<ul> <li><code>OPENSTREETMAP_USERNAME</code> - OpenStreetMap username</li> <li><code>OPENSTREETMAP_PASSWORD</code> - OpenStreetMap password</li> </ul>"},{"location":"gkc/authentication/#example-configuration","title":"Example Configuration","text":"<pre><code># Wikidata (default)\nexport WIKIVERSE_USERNAME=\"Alice@MyBot\"\nexport WIKIVERSE_PASSWORD=\"abc123def456ghi789\"\n\n# Wikidata Test Instance (for development and testing)\nexport WIKIVERSE_USERNAME=\"Alice@MyBot\"\nexport WIKIVERSE_PASSWORD=\"abc123def456ghi789\"\nexport WIKIVERSE_API_URL=\"wikidata_test\"\n\n# Wikipedia\nexport WIKIVERSE_USERNAME=\"Alice@MyBot\"\nexport WIKIVERSE_PASSWORD=\"abc123def456ghi789\"\nexport WIKIVERSE_API_URL=\"wikipedia\"\n\n# Custom MediaWiki instance\nexport WIKIVERSE_USERNAME=\"Alice@MyBot\"\nexport WIKIVERSE_PASSWORD=\"abc123def456ghi789\"\nexport WIKIVERSE_API_URL=\"https://wiki.mycompany.com/w/api.php\"\n\n# OpenStreetMap\nexport OPENSTREETMAP_USERNAME=\"your_osm_username\"\nexport OPENSTREETMAP_PASSWORD=\"your_osm_password\"\n</code></pre>"},{"location":"gkc/authentication/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Never commit credentials to version control</li> <li>Use environment variables or secure credential storage</li> <li>Limit bot password permissions to only what your application needs</li> <li>Rotate credentials regularly and revoke unused bot passwords</li> <li>Use interactive prompts for development/testing workflows</li> </ol>"},{"location":"gkc/authentication/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gkc/authentication/#login-failures","title":"Login Failures","text":"<p>If login fails, check:</p> <ol> <li>Credentials format: Username should be <code>Username@BotName</code> for Wikimedia projects</li> <li>Bot password permissions: Ensure the bot password has required grants</li> <li>API URL: Verify you're targeting the correct Wikimedia project</li> <li>Network connectivity: Ensure you can reach the API endpoint</li> </ol>"},{"location":"gkc/authentication/#authentication-errors","title":"Authentication Errors","text":"<p>Common errors and solutions:</p> <ul> <li><code>AuthenticationError: Not logged in</code> - Call <code>auth.login()</code> before making authenticated requests</li> <li><code>AuthenticationError: Invalid credentials</code> - Double-check your username and password</li> <li><code>AuthenticationError: No credentials provided</code> - Set environment variables or pass credentials to constructor</li> </ul>"},{"location":"gkc/authentication/#see-also","title":"See Also","text":"<ul> <li>Authentication API Reference - Complete API documentation with detailed examples</li> <li>Wikidata:Bots - Wikidata bot policy</li> <li>Special:BotPasswords - Create bot passwords</li> <li>MediaWiki API - MediaWiki API documentation</li> <li>OpenStreetMap API - OpenStreetMap API documentation</li> </ul>"},{"location":"gkc/background/","title":"Background","text":"<p>This document provides background and motivation on the Global Knowledge Commons (GKC) project and the datadistillery.org site.</p>"},{"location":"gkc/background/#background","title":"Background","text":"<p>A couple years ago, I built a tool called wbmaker when working with a Wikibase instance on the wikibase.cloud project. It provided a minimal abstraction on the WikibaseIntegrator project, which is quite excellent for what it does. However, I'm also working toward a broader slate of open data contributions across multiple platforms.</p> <p>I started the gkc project from the standpoint of Wikidata, with additional modules and functionality for other Wikimedia projects and OpenStreetMap to follow. I came at this from the perspective of entity schemas as the basis for source data processing into Wikidata items - essentially pushing toward schema-driven data development. While there are limitations in the shape expression (ShEx) approach to documenting schemas, it is what Wikidata (sort of) supports and offers a reasonable building block.</p> <p>The Data Distillery concept, of which the GKC package is a core component, was born out of a bit of whimsy long ago on another project - the 4D Digital Crust. This was one of the early projects in the National Science Foundation's EarthCube venture where I was co-PI on a rather ambitious grant to build an integration of data modeling the spatiotemporal dynamics of the planet. Our project team was sitting around a table in Fort Collins dreaming up what we thought we could build. I said something about whiskey and a Data Distillery, one of our guys snapped up a cool domain name, and it's sat around dormant until now.</p> <p>My initial focus in the project is on building an end-to-end workflow from source data about federally recognized tribes in the U.S. into representative Wikidata items and Wikipedia articles. At the outset, there were many missing tribes and a great deal of variation in how Wikidata items were documented and Wikipedia articles structured. The basic sequence of the workflow I started with to build this project includes:</p> <ul> <li>spreadsheet of source information (tribe names and aliases, properties about tribes, etc.) assembled through a variety or manual and code-assisted means</li> <li>entity schema in ShExC (work in progress)</li> <li>conversion of entity schema into a JSON-based mapping of source data to target Wikidata item structure</li> <li>transformation of source data to Wikidata's JSON structure</li> <li>rinse and repeat through the thousands of heterogeneous data sources in need of distilling into working knowledge</li> </ul>"},{"location":"gkc/background/#why-a-new-package","title":"Why a new package","text":"<p>I've worked with both WikibaseIntegrator and pyWikiBot over the years. The WBI project is much more functional, and I've used it to create and modify thousands of items in both Wikidata and other Wikibase instances. For a variety of reasons, I kept ending up in a usage pattern with WBI where I was building one-off scripts that essentially mixed data, configuration, and processing logic all together. I wanted something for Wikidata that was based in entity schemas and clearly separated data mapping/configuration logic from processing.</p> <p>At the end of the day, WBI is a Python wrapper on the Wikimedia APIs (mostly REST). It puts together a JSON packet aligned with what the REST API requires and submits it. What I've come up with here is a different approach toward the same end goal that works better with the data processing mode I work with. It may or may not prove useful for others.</p> <p>I am also working to harmonize data and information about the same things between multiple best-fit technologies in the Commons and want a package that helps me make the connections and get content online in the most accurate and explainable ways I can. For instance, when contributing things like headquarters locations for tribes in the U.S., I want those showing up as both claims in Wikidata and as point features in OpenStreetMap with links between. When working on Wikipedia articles and filling out info boxes, I want to ensure alignment of facts with what's in Wikidata.</p>"},{"location":"gkc/background/#code-writing-with-copilot","title":"Code writing with Copilot","text":"<p>I've been writing Python code for well over a decade as part of my professional career, but I'm a biologist and incidental data scientist and not a software engineer. Copilot and code-forward AI agents are the best thing to come along in my lifetime to help make up for that lacking skillset. I know what needs to be done and mostly how to go about it, but I've never been able to match the speed and efficiency in turning wishes and dreams (aka requirements) into working software that is robust, reliable, maintainable, and truly able to be used and contributed to by others. Now that we have these capabilities, I'm making good use of them here. A quick look through my GitHub account will show a marked distinction in the sophistication of this project.</p> <p>The copilot folder contains pages describing the result of the conversational way I've built the code in VSCode with Microsoft's Copilot and various models/agents (mostly Claude Sonnet). I'm keeping those intact because they are both good documentation of the functionality built into the code and a curated view into the way the code is developing.</p> <p>Before committing, merging, and publishing (to PyPi), I am iteratively working through real-world examples to ensure that the code all does exactly what it is designed to do. I have many projects in the works in the Commons, and so I can fully exercise all the features and functionality I'm building on real data. In most cases, I am incorporating them here into the project as examples. You will also see examples show up in my Indian Country Data project where I mostly have workflows in notebooks.</p> <p>I'm also giving the code itself a thorough review as well as validating the end results. I'm learning a lot by looking carefully through what the code-writing models are doing and how they are approaching system architecture. Hands down, though, there's no way I could possibly generate this kind of high-quality code, tests, and feature documentation in anywhere near the time Copilot is able to get it done from a simple statement about what I want the end result to be and some iterative testing with real data.</p>"},{"location":"gkc/profiles/","title":"GKC Entity Profiles: Construction and Reference","text":"<p>Plain Meaning: A comprehensive guide to building, structuring, and validating YAML profiles that define how GKC Entities are captured, validated, and transformed in the Global Knowledge Commons.</p>"},{"location":"gkc/profiles/#overview","title":"Overview","text":"<p>Entity profiles are declarative, machine-readable definitions of entity structures that bridge raw user input and refined, cross-platform entity models. They encode:</p> <ul> <li>What statements make up an entity (properties and their datatypes)</li> <li>How statements relate to Wikidata properties and external systems</li> <li>What constraints apply to each statement's values</li> <li>How to validate incoming data against those constraints</li> <li>How to reference sources and maintain provenance</li> </ul> <p>Profiles are YAML files that live in the SpiritSafe profile registry (<code>profiles/&lt;ProfileID&gt;/profile.yaml</code>) and are managed in version control in the dedicated SpiritSafe repository. They serve as both human-readable documentation and executable specifications that drive two distinct workflows:</p> <ol> <li>GKC Wizards \u2014 Interactive, multi-step data entry interfaces where curators create and edit entities with guided input, validation, and choice lists</li> <li>Validation &amp; Coercion \u2014 Programmatic validation of existing data (from Wikidata, spreadsheets, APIs) using dynamically-generated Pydantic models</li> </ol> <p>This document focuses primarily on how to build profiles that drive successful wizard experiences while maintaining the validation rigor needed for bulk data processing.</p>"},{"location":"gkc/profiles/#implementation-status","title":"Implementation Status","text":"<p>The following profile capabilities are implemented and stable in current GKC architecture:</p> <ul> <li>YAML profile loading into typed profile models.</li> <li>Statement, qualifier, reference, and datatype validation structures.</li> <li>SPARQL allowed-items extraction and hydration workflows with fallback behavior.</li> <li>Profile path and query reference resolution aligned to SpiritSafe registrant layout.</li> </ul> <p>For architecture-level implementation details, see:</p> <ul> <li>Architecture Overview</li> <li>Profile Loading Architecture</li> <li>SpiritSafe Infrastructure</li> <li>Validation Architecture</li> </ul>"},{"location":"gkc/profiles/#theoretical-design-notes","title":"Theoretical Design Notes","text":"<p>Some sections in this document describe wizard behavior and curator flow targets that are directionally committed but not fully implemented end-to-end in a single production UI stack.</p> <p>Treat those sections as architecture guidance for future Wizard Engineer and Validation Agent implementation work, not as guaranteed current runtime behavior.</p>"},{"location":"gkc/profiles/#profiles-and-gkc-wizards","title":"Profiles and GKC Wizards","text":"<p>GKC Wizards are the primary curator-facing interface for working with entity profiles. A wizard is a multi-step, guided workflow that transforms a YAML profile into an interactive data-entry experience. Every field, validation rule, prompt, and choice list comes directly from the profile\u2014wizards have no hardcoded forms or entity-specific logic.</p>"},{"location":"gkc/profiles/#the-5-step-wizard-structure","title":"The 5-Step Wizard Structure","text":"<p>Every wizard follows a consistent 5-step progression designed with a curator mental model in mind:</p>"},{"location":"gkc/profiles/#step-1-plan-of-action","title":"Step 1: Plan of Action","text":"<p>A summary screen that explains:</p> <ul> <li>What type of entity will be created (drawn from profile <code>name</code> and <code>description</code>)</li> <li>What the wizard will ask for (metadata, required statements, optional statements, cross-platform links)</li> <li>Secondary entities that may need to be created or linked (e.g., government positions, related organizations)</li> <li>How long the process will take and what sources/references the curator should have ready</li> </ul> <p>This step sets expectations and helps curators gather the right information before starting data entry.</p>"},{"location":"gkc/profiles/#step-2-basic-identification","title":"Step 2: Basic Identification","text":"<p>Primary entity metadata:</p> <ul> <li>Labels (one per language, required languages determined by profile)</li> <li>Descriptions (one per language, must be distinctive and disambiguating)</li> <li>Aliases (multiple per language, includes alternative names, historical names)</li> </ul> <p>Each field shows <code>input_prompt</code> and <code>guidance</code> from the profile. Required languages are validated before progression.</p>"},{"location":"gkc/profiles/#step-3-statements","title":"Step 3: Statements","text":"<p>All statements about the entity:</p> <ul> <li>Profile's community-curated statement ordering determines presentation sequence</li> <li>Any statement can be skipped with explicit \"Skip this statement\" option</li> <li>Each statement includes:</li> <li>Value input (widget determined by datatype)</li> <li>Qualifiers (nested under statement)</li> <li>References (behavior.references determines whether shown, auto-derived, or hidden)</li> <li>\"Add another\" button for multi-count statements (<code>max_count &gt; 1</code> or <code>max_count: null</code>)</li> </ul> <p>Validation occurs per-field (on blur) and per-statement (when complete). No validation blocks progression\u2014curators can advance even with incomplete data. Missing statements generate suggestions in the review step.</p> <p>Philosophy: Following Wikidata/Wikipedia principles, curators can create minimal entities quickly and enhance them later. The wizard guides toward completeness but never forces it.</p>"},{"location":"gkc/profiles/#step-4-cross-platform-links","title":"Step 4: Cross-Platform Links","text":"<p>Sitelinks and external platform connections:</p> <ul> <li>Wikipedia articles (per language, with conflict detection)</li> <li>Wikimedia Commons categories or files</li> <li>OpenStreetMap relations (for geographic entities)</li> <li>Other wiki projects as defined in profile <code>sitelinks</code> section</li> </ul> <p>Each sitelink validates format and checks for uniqueness conflicts (one sitelink per language+project across all Wikidata).</p>"},{"location":"gkc/profiles/#step-5-review-validate","title":"Step 5: Review &amp; Validate","text":"<p>Comprehensive summary and validation:</p> <ul> <li>All collected data grouped by section (metadata, statements, sitelinks)</li> <li>What's missing: Community-expected statements that were skipped (helps curators understand completeness)</li> <li>Secondary entities identified during statement entry (if any need creation, wizard offers to branch)</li> <li>Full validation results: errors (data type/format issues), warnings (conformance issues), suggestions (statements worth considering)</li> <li>Quality score and conformance indicators</li> <li>Actions:</li> <li>Edit any section (returns to that step)</li> <li>Export to JSON (save locally without shipping)</li> <li>Ship to Wikidata (write via API, create Commons connections, update OSM if applicable)</li> </ul> <p>Curators can ship even with warnings and suggestions\u2014only true errors (malformed data) block shipping. Skipped statements appear as suggestions: \"Consider adding: official website, member count\" with quick-add options.</p>"},{"location":"gkc/profiles/#how-profile-elements-map-to-wizard-steps","title":"How Profile Elements Map to Wizard Steps","text":"Profile Element Wizard Step Wizard Behavior <code>name</code>, <code>description</code> Step 1 (Plan) Displayed as \"You will create...\" summary <code>labels</code>, <code>descriptions</code>, <code>aliases</code> Step 2 (Identification) Per-language inputs, required languages enforced <code>statements</code> Step 3 (Statements) All statements presented in profile order, all skippable <code>qualifiers</code> Step 3 (nested) Nested under parent statement <code>references</code> Step 3 (nested) Behavior determined by <code>behavior.references</code> (auto-derived, editable, or hidden) <code>sitelinks</code> Step 4 (Links) Per-project inputs, conflict validation All data + validation Step 5 (Review) Summary view with validation report and community completeness suggestions"},{"location":"gkc/profiles/#profiles-used-without-wizards","title":"Profiles Used Without Wizards","text":"<p>Profiles also support non-interactive workflows where no wizard is involved:</p> <ul> <li>Bulk validation: Validate thousands of Wikidata items against a profile, generating conformance reports</li> <li>Data coercion: Normalize and transform data from external sources (spreadsheets, APIs) into Wikidata-conformant structures</li> <li>Programmatic entity creation: Generate entities from code without user interaction (e.g., automated bots)</li> <li>Quality analysis: Scan existing Wikidata content to identify gaps or constraint violations</li> </ul> <p>In these workflows, profiles are loaded into dynamically-generated Pydantic models that provide validation and type coercion. The <code>validation_policy</code> and <code>behavior</code> settings still apply\u2014for example, <code>behavior.references: auto_derive</code> will generate references automatically even in bulk operations.</p> <p>Key distinction: Wizard-driven workflows are curator-centric (interactive, guided, with prompts and choice lists). Validation-driven workflows are programmatic (batch processing, no UI, focused on conformance checking).</p>"},{"location":"gkc/profiles/#profile-anatomy","title":"Profile Anatomy","text":"<p>A SpiritSafe YAML profile has this essential structure:</p> <pre><code>name: Entity Type Name\ndescription: &gt;\n  Multi-line description of what this profile represents\n  and what kinds of entities it covers.\n\n# Optional: Reusable reference patterns (via YAML anchors)\nstandard_reference: &amp;standard_reference\n  min_count: 1\n  # ... reference structure\n\nstatements:\n  - id: statement_identifier\n    label: Human-readable label\n    wikidata_property: P123  # Wikidata property ID\n    type: statement           # Always \"statement\" for now\n    max_count: 1              # null = unlimited\n    validation_policy: allow_existing_nonconforming\n\n    behavior:  # Optional: control processing across all GKC operations\n      value: editable       # or fixed, hidden\n      qualifiers: editable  # or hidden\n      references: editable  # or auto_derive, hidden\n\n    value:\n      type: string  # Datatype\n      constraints:  # Statement-level constraints\n        - type: format\n          pattern: '[A-Z0-9]+'\n\n    qualifiers:  # (optional) properties that modify the main statement\n      - id: qualifier_id\n        label: Qualifier label\n        wikidata_property: P456\n        required: false\n        value:\n          type: item\n\n    references:  # (optional) sources and citations\n      required: true\n      min_count: 1\n      allowed:\n        - id: source_id\n          wikidata_property: P248\n          type: item\n          label: Stated in\n</code></pre>"},{"location":"gkc/profiles/#top-level-keys","title":"Top-level Keys","text":"Key Type Required Purpose <code>name</code> string YES Profile name displayed to users and in logs <code>description</code> string YES Multi-line explanation of profile scope <code>statements</code> array YES List of statement definitions Anchors any NO YAML anchors for reusable patterns (e.g., <code>&amp;standard_reference</code>)"},{"location":"gkc/profiles/#statement-keys","title":"Statement Keys","text":"Key Type Required Purpose <code>id</code> string YES Unique identifier (snake_case) <code>label</code> string YES Human-readable display name <code>input_prompt</code> string NO Curator-facing prompt shown in wizard <code>guidance</code> string NO Extended help text for curators <code>wikidata_property</code> string YES Wikidata property ID (e.g., \"P31\") <code>type</code> string YES Always \"statement\" (for now) <code>max_count</code> int or null NO Max statements allowed (null = unlimited); determines \"Add another\" button visibility <code>validation_policy</code> enum NO How to handle existing data (see Validation Policy) <code>behavior</code> object NO Universal processing rules for value, qualifiers, and references across all GKC operations (see Statement Behavior) <code>entity_profile</code> string NO Filename reference to another GKC Entity Profile for secondary entities (see Secondary Entities); enables wizard chaining <code>value</code> object YES Value definition (datatype + constraints) <code>qualifiers</code> array NO Qualifier definitions (nested in wizard step 3) <code>references</code> object NO Reference definition (includes derivation rules)"},{"location":"gkc/profiles/#validation-policy","title":"Validation Policy","text":"<p>The <code>validation_policy</code> enum controls how strict validation is when working with existing Wikidata data, affecting both interactive wizard workflows and programmatic validation workflows.</p> <p><code>validation_policy</code> determines how strict validation is when working with existing Wikidata data.</p>"},{"location":"gkc/profiles/#allow_existing_nonconforming-default-recommended","title":"<code>allow_existing_nonconforming</code> (Default, Recommended)","text":"<p>What it means: - New data must conform to all profile constraints - Existing data in Wikidata that doesn't conform is allowed to remain - Validation warnings are issued for non-conforming existing data, but they don't block operations</p> <p>When to use: - Almost always\u2014this is the recommended default - When working with mature Wikidata items that may have legacy data - When profile constraints are stricter than historical Wikidata practices - When you want to improve data quality incrementally without breaking existing items</p> <p>Wizard behavior: - When editing existing items, pre-populated fields may show non-conforming data with warning indicators - Curators can choose to fix warnings or leave them as-is - New statements added during the wizard session should conform (warnings shown if not) - Review step shows warnings for existing non-conforming data but always allows shipping - Philosophy: Get the data in, refine it later</p> <p>Example: <pre><code>statements:\n  - id: instance_of\n    wikidata_property: P31\n    required: true\n    validation_policy: allow_existing_nonconforming  # Existing items may have multiple P31 values\n    max_count: 1  # But new items should only have one\n</code></pre></p>"},{"location":"gkc/profiles/#strict","title":"<code>strict</code>","text":"<p>What it means: - All data must conform to profile constraints, whether new or existing - Non-conforming existing data triggers validation errors that block operations - No tolerance for deviations from the profile</p> <p>When to use: - When working with newly-created entity types with no legacy data - When profile constraints match established Wikidata community norms exactly - When conformance is critical (e.g., regulatory compliance, legal requirements) - When you control all existing data and can guarantee conformance</p> <p>Wizard behavior: - When editing existing items, non-conforming data triggers errors - Curators see errors and are strongly encouraged to fix them before shipping - Review step shows prominent error indicators but still allows shipping (with confirmation) - Philosophy: Even in strict mode, contribution is more important than perfection</p> <p>Example: <pre><code>statements:\n  - id: headquarters_location\n    wikidata_property: P159\n    required: false\n    validation_policy: strict  # When present, must have exactly the qualifiers we define\n    max_count: 1\n</code></pre></p>"},{"location":"gkc/profiles/#statement-behavior","title":"Statement Behavior","text":"<p>The <code>behavior</code> object defines universal processing rules for how a statement is handled across all GKC operations\u2014interactive wizards, bulk data imports, validation workflows, and programmatic entity creation. These are profile-level data transformation rules, not just UI presentation hints.</p> <p>Each statement has three components that can be controlled independently: 1. Value (the main statement content) 2. Qualifiers (contextual modifiers on the statement) 3. References (source citations)</p>"},{"location":"gkc/profiles/#behavior-keys","title":"Behavior Keys","text":"<pre><code>behavior:\n  value: editable | fixed | hidden\n  qualifiers: editable | hidden\n  references: editable | auto_derive | hidden\n</code></pre>"},{"location":"gkc/profiles/#behaviorvalue","title":"<code>behavior.value</code>","text":"<p>Controls how the statement value is processed.</p> <p><code>editable</code> (default): - User/process can set any valid value conforming to datatype constraints - In wizards: full input widget shown based on datatype - In bulk operations: value read from input data (CSV, JSON, etc.)</p> <p><code>fixed</code>: - Value must match <code>value.fixed</code> - locked across all operations - In wizards: shown as read-only badge with label (e.g., \"federally recognized Native American tribe in the United States\") - In bulk operations: value auto-populated from profile, not expected in input data - In validation: flags error if existing value doesn't match <code>value.fixed</code></p> <p><code>hidden</code>: - Statement not shown in forms or expected in bulk data - Reserved for future use (computed values, deprecated fields)</p> <p>Example: <pre><code>statements:\n  - id: instance_of\n    label: Instance of\n    wikidata_property: P31\n\n    behavior:\n      value: fixed           # Value locked to Q7840353 in all contexts\n      references: editable    # References manually provided\n\n    value:\n      type: item\n      fixed: Q7840353\n      label: federally recognized Native American tribe in the United States\n</code></pre></p>"},{"location":"gkc/profiles/#behaviorqualifiers","title":"<code>behavior.qualifiers</code>","text":"<p>Controls how qualifiers are processed.</p> <p><code>editable</code> (default): - User/process can add qualifiers as defined in <code>qualifiers</code> array - In wizards: qualifier inputs shown nested under statement - In bulk operations: qualifiers read from input data</p> <p><code>hidden</code>: - Qualifiers not shown in forms or expected in bulk data - Use when qualifiers exist in schema but shouldn't be collected for this entity type</p> <p>Example: <pre><code>statements:\n  - id: official_website\n    wikidata_property: P856\n\n    behavior:\n      qualifiers: editable  # Show language_of_work qualifier\n\n    qualifiers:\n      - id: language_of_work\n        wikidata_property: P407\n        value:\n          type: item\n          fixed: Q1860  # English\n</code></pre></p>"},{"location":"gkc/profiles/#behaviorreferences","title":"<code>behavior.references</code>","text":"<p>Controls how references are processed and where their values come from.</p> <p><code>editable</code> (default): - User/process manually provides all reference details - In wizards: full reference entry controls shown (type selector + value inputs) - In bulk operations: references read from input data - All <code>allowed</code> reference types available for selection</p> <p><code>auto_derive</code>: - References automatically generated using <code>value_source</code> rules - In wizards: reference section hidden or shows \"auto-generated\" indicator - In bulk operations: references created automatically from statement value - Common pattern: official website URL becomes reference URL</p> <p><code>hidden</code>: - No references shown, collected, or required - Use sparingly\u2014most Wikidata statements should have references</p> <p>Example - Auto-derived references: <pre><code>statements:\n  - id: official_website\n    wikidata_property: P856\n\n    behavior:\n      value: editable\n      references: auto_derive  # Generate P854 from P856 automatically\n\n    value:\n      type: url\n\n    references:\n      min_count: 1\n      target:\n        id: reference_url\n        wikidata_property: P854\n        type: url\n        value_source: statement_value  # Derivation rule: P854 = P856\n</code></pre></p> <p>Example - Manual references with choice: <pre><code>statements:\n  - id: member_count\n    wikidata_property: P2124\n\n    behavior:\n      references: editable  # Curator chooses reference type\n\n    value:\n      type: quantity\n\n    references:\n      min_count: 1\n      allowed:\n        - id: stated_in\n          wikidata_property: P248\n          type: item\n        - id: reference_url\n          wikidata_property: P854\n          type: url\n</code></pre></p>"},{"location":"gkc/profiles/#how-behavior-works-across-contexts","title":"How Behavior Works Across Contexts","text":"<p>Interactive Wizard: - <code>behavior.value: fixed</code> \u2192 renders as read-only badge - <code>behavior.references: auto_derive</code> \u2192 hides reference input, shows \"auto-generated\" note - <code>behavior.references: editable</code> \u2192 shows reference type selector and value inputs</p> <p>Bulk CSV Import: <pre><code>qid,official_website\nQ123,https://cherokeenation.com\nQ456,https://navajo-nsn.gov\n</code></pre></p> <p>Profile processor reads <code>behavior.references: auto_derive</code> and automatically: - Creates P856 statement with URL from CSV - Creates P854 reference with same URL (no reference column needed in CSV)</p> <p>Validation Workflow: <pre><code>validator.check_entity(qid=\"Q789\", profile=\"TribalGovernmentUS\")\n</code></pre></p> <p>Validator reads <code>behavior</code>: - Checks <code>behavior.value: fixed</code> on instance_of \u2192 validates P31 = Q7840353 - Checks <code>behavior.references: auto_derive</code> on official_website \u2192 if P856 exists without P854 or P854 \u2260 P856, flags non-conforming - Applies rules consistently regardless of how entity was created</p>"},{"location":"gkc/profiles/#default-behavior","title":"Default Behavior","text":"<p>If <code>behavior</code> is omitted, defaults are:</p> <pre><code>behavior:\n  value: editable         # Unless value.fixed is set, then value: fixed\n  qualifiers: editable    # If qualifiers array defined\n  references: editable    # Unless target.value_source set, then auto_derive\n</code></pre> <p>Profile authors can omit <code>behavior</code> for standard statements and only specify it when special handling is needed.</p>"},{"location":"gkc/profiles/#datatypes-reference","title":"Datatypes Reference","text":"<p>SpiritSafe supports 9 core Wikidata datatypes. Each has specific use cases, constraint options, and validation behaviors.</p>"},{"location":"gkc/profiles/#1-item-item","title":"1. Item (<code>item</code>)","text":"<p>Wikidata type: <code>wikibase-entityid</code> Use cases: entity references, enums with bounded choice lists Form widget: Autocomplete or select dropdown</p> <pre><code>value:\n  type: item\n  fixed: Q5  # (optional) Lock to specific item\n  label: human\n  constraints:\n    - type: allowed_items\n      source: sparql\n      query: SELECT ?item ?itemLabel WHERE { ... }\n</code></pre> <p>Key constraint types: - <code>allowed_items</code> - SPARQL query for choice list - <code>fixed</code> - item value must be exactly this QID</p> <p>Validation: Checks that value is a valid QID and (if specified) exists in choice list.</p>"},{"location":"gkc/profiles/#2-string-string","title":"2. String (<code>string</code>)","text":"<p>Wikidata type: <code>string</code> Use cases: Names, identifiers, free text Form widget: Text input</p> <pre><code>value:\n  type: string\n  constraints:\n    - type: format\n      pattern: '^[A-Z0-9\\-]+$'\n    - type: length\n      min_length: 1\n      max_length: 255\n</code></pre> <p>Key constraint types: - <code>format</code> - regex pattern for validation - <code>length</code> - min/max string length</p> <p>Validation: Matches against regex pattern and length bounds.</p>"},{"location":"gkc/profiles/#3-url-url","title":"3. URL (<code>url</code>)","text":"<p>Wikidata type: <code>string</code> (with datatype=\"url\") Use cases: Website links, reference URLs, external system links Form widget: URL input (with validation)</p> <pre><code>value:\n  type: url\n  constraints:\n    - type: url_scheme\n      allowed_schemes: ['http', 'https']\n    - type: url_validation\n      validate: true  # Check URL returns valid HTTP response\n</code></pre> <p>Key constraint types: - <code>url_scheme</code> - Allowed protocols (http, https, ftp, etc.) - <code>url_validation</code> - HTTP HEAD validation</p> <p>Validation: Parses as valid URL and optionally checks HTTP response.</p>"},{"location":"gkc/profiles/#4-quantity-quantity","title":"4. Quantity (<code>quantity</code>)","text":"<p>Wikidata type: <code>quantity</code> Use cases: Counts, measurements, amounts Form widget: Number input + unit selector</p> <pre><code>value:\n  type: quantity\n  constraints:\n    - type: integer_only\n      description: Must be whole number (no decimals)\n    - type: range\n      min_value: 0\n      max_value: 10000\n    - type: unit\n      default_unit: Q199  # Number (dimensionless)\n      allowed_units:\n        - Q199  # Number\n        - Q11588322  # Second\n</code></pre> <p>Key constraint types: - <code>integer_only</code> - No decimal places - <code>range</code> - Min/max numeric bounds - <code>unit</code> - Unit system specification</p> <p>Validation: Checks numeric type and value bounds. Converts to Wikidata quantity format with unit and precision.</p>"},{"location":"gkc/profiles/#5-time-time","title":"5. Time (<code>time</code>)","text":"<p>Wikidata type: <code>time</code> Use cases: Dates, years, temporal ranges Form widget: Date picker / text input with fuzzy parsing</p> <pre><code>value:\n  type: time\n  constraints:\n    - type: precision\n      allowed_precisions: [9, 10, 11]  # year, month, day\n      auto_derive: true  # Infer precision from input format\n    - type: calendar_model\n      default: Q1985727  # Gregorian calendar\n      allowed_calendars:\n        - Q1985727  # Gregorian\n        - Q12138    # Julian (historical)\n    - type: format\n      patterns:\n        - 'YYYY'           # Year only\n        - 'YYYY-MM'        # Year-month\n        - 'YYYY-MM-DD'     # Full date\n</code></pre> <p>Key constraint types: - <code>precision</code> - Allowed precision levels (year/month/day/hour/etc.) - <code>calendar_model</code> - Calendar system (Gregorian vs. Julian) - <code>auto_derive</code> - Automatically determine precision from input</p> <p>Validation: Parses various date formats, derives precision, normalizes to Wikidata time format <code>+YYYY-MM-DDTHH:MM:SSZ</code>.</p>"},{"location":"gkc/profiles/#6-monolingualtext-monolingualtext","title":"6. Monolingualtext (<code>monolingualtext</code>)","text":"<p>Wikidata type: <code>monolingualtext</code> Use cases: Text in specific languages (names, descriptions, addresses) Form widget: Text input + language selector</p> <pre><code>value:\n  type: monolingualtext\n  constraints:\n    - type: language_required\n      description: Must specify language code\n    - type: valid_language_code\n      description: Must be valid Wikimedia language code\n</code></pre> <p>Key constraint types: - <code>language_required</code> - Language code is mandatory - <code>valid_language_code</code> - Must match Wikimedia language code list</p> <p>Storage: Internally stored as <code>{text: string, language: string}</code> tuple.</p> <p>Validation: Validates language code against Wikimedia language list. Normalizes text and language code.</p>"},{"location":"gkc/profiles/#7-globecoordinate-globecoordinate","title":"7. Globecoordinate (<code>globecoordinate</code>)","text":"<p>Wikidata type: <code>globecoordinate</code> Use cases: Geographic coordinates, locations, buildings Form widget: Map picker or lat/long input boxes</p> <pre><code>value:\n  type: globecoordinate\n  constraints:\n    - type: valid_coordinates\n      description: Latitude -90 to 90, longitude -180 to 180\n    - type: precision\n      min_precision: 0.0001   # ~11m (building-level)\n      max_precision: 0.01     # ~1km (city-level)\n    - type: globe\n      default: Q2  # Earth\n      allowed_globes:\n        - Q2  # Earth\n</code></pre> <p>Key constraint types: - <code>valid_coordinates</code> - Latitude/longitude bounds - <code>precision</code> - Coordinate precision bounds (in degrees) - <code>globe</code> - Which celestial body (Earth, Mars, etc.)</p> <p>Storage: Internally stored as <code>{latitude: float, longitude: float, precision: float, globe: string}</code>.</p> <p>Validation: Checks coordinate bounds and precision range. Converts to Wikidata globe coordinate format.</p>"},{"location":"gkc/profiles/#8-external-id-external-id","title":"8. External-id (<code>external-id</code>)","text":"<p>Wikidata type: <code>external-id</code> (string with special handling) Use cases: IDs from external systems (OSM, DOI, ISBN, etc.) Form widget: Text input (with validation against external system)</p> <pre><code>value:\n  type: external-id\n  constraints:\n    - type: format\n      description: Pattern for valid ID format\n      pattern: '^\\d+$'  # Numeric only\n    - type: formatter_url\n      description: Wikidata property formatter URL\n      url_pattern: 'http://www.openstreetmap.org/relation/$1'\n      validate: true\n      validation_method: http_head  # Check URL validity\n    - type: external_system\n      system: OpenStreetMap\n      url_base: 'http://www.openstreetmap.org/relation/'\n</code></pre> <p>Key constraint types: - <code>format</code> - Regex pattern for ID format - <code>formatter_url</code> - Wikidata P1630 (formatter URL) pattern - <code>external_system</code> - External system metadata</p> <p>Validation: Matches regex pattern. Optionally validates formatted URL with HTTP HEAD request.</p> <p>Note: External IDs are considered declarative statements from data curators and typically don't require references.</p>"},{"location":"gkc/profiles/#9-commons-media-commonsmedia","title":"9. Commons Media (<code>commonsMedia</code>)","text":"<p>Wikidata type: <code>commonsMedia</code> (string filename with special handling) Use cases: Media files on Wikimedia Commons (images, audio, video) Form widget: File selector / file upload stub</p> <pre><code>value:\n  type: commonsMedia\n  constraints:\n    - type: file_exists\n      description: File must exist on Wikimedia Commons\n      validate: true\n      validation_method: commons_api\n    - type: file_type\n      description: Allowed file formats\n      allowed_types:\n        - 'image/svg+xml'\n        - 'image/png'\n        - 'image/jpeg'\n    - type: wikidata_constraint\n      description: Commons file must have specific properties\n      required_property: P6216  # License\n</code></pre> <p>Key constraint types: - <code>file_exists</code> - Check file exists on Commons - <code>file_type</code> - MIME type restrictions - <code>wikidata_constraint</code> - Required properties on Commons file</p> <p>Storage: Stored as filename string (e.g., \"Flag.svg\").</p> <p>Validation: Checks file exists on Commons via API. Validates file format and licensing metadata.</p>"},{"location":"gkc/profiles/#constraints-reference","title":"Constraints Reference","text":"<p>Constraints are the validation rules applied to statement values. They enforce business logic, external system compliance, and data quality.</p>"},{"location":"gkc/profiles/#universal-constraint-properties","title":"Universal Constraint Properties","text":"<p>All constraints share these properties:</p> <pre><code>- type: constraint_type_name     # Identifier (required)\n  description: Human-readable    # Description (required)\n  # + type-specific properties\n</code></pre>"},{"location":"gkc/profiles/#common-constraint-patterns","title":"Common Constraint Patterns","text":""},{"location":"gkc/profiles/#format-constraints-regex-validation","title":"Format Constraints (Regex Validation)","text":"<pre><code>- type: format\n  pattern: '^[A-Z0-9]{3,10}$'  # Alphanumeric, 3-10 chars\n  message: 'Must be 3-10 alphanumeric characters'\n</code></pre>"},{"location":"gkc/profiles/#range-constraints-numeric-bounds","title":"Range Constraints (Numeric Bounds)","text":"<pre><code>- type: range\n  min_value: 0\n  max_value: 100\n  message: 'Must be between 0 and 100'\n</code></pre>"},{"location":"gkc/profiles/#choice-list-constraints-sparql-backed","title":"Choice List Constraints (SPARQL-backed)","text":"<pre><code>- type: allowed_items\n  source: sparql\n  query: |\n    SELECT ?item ?itemLabel\n    WHERE {\n      ?item wdt:P31 wd:Q5 .\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n    }\n  refresh: daily  # or manual, weekly, on_release\n  fallback_items:\n    - id: Q123\n      label: Fallback option\n</code></pre>"},{"location":"gkc/profiles/#url-validation","title":"URL Validation","text":"<pre><code>- type: formatter_url\n  url_pattern: 'http://example.com/item/$1'\n  validate: true\n  validation_method: http_head\n  timeout: 10  # seconds\n</code></pre>"},{"location":"gkc/profiles/#references-sourcing-and-provenance","title":"References: Sourcing and Provenance","text":"<p>References document the origin and authority of statements. Wikidata supports multiple reference patterns:</p>"},{"location":"gkc/profiles/#reference-structure","title":"Reference Structure","text":"<pre><code>references:\n  required: true              # Are references mandatory?\n  min_count: 1                # Minimum number of references\n  validation_policy: allow_existing_nonconforming\n  form_policy: target_only    # or show_all\n\n  # Option 1: Single target (exactly one reference type allowed)\n  target:\n    id: reference_id\n    wikidata_property: P248   # Stated in\n    type: item\n    label: Stated in\n\n  # Option 2: Multiple allowed types\n  allowed:\n    - id: stated_in\n      wikidata_property: P248\n      type: item\n      label: Stated in\n    - id: reference_url\n      wikidata_property: P854\n      type: url\n      label: Reference URL\n</code></pre>"},{"location":"gkc/profiles/#reusable-reference-patterns-with-yaml-anchors","title":"Reusable Reference Patterns with YAML Anchors","text":"<p>Instead of repeating reference structures, define them once and reuse:</p> <pre><code># Define at top of profile\nstandard_reference: &amp;standard_reference\n  min_count: 1\n  validation_policy: allow_existing_nonconforming\n  allowed:\n    - id: stated_in\n      wikidata_property: P248\n      type: item\n      label: Stated in\n    - id: reference_url\n      wikidata_property: P854\n      type: url\n      label: Reference URL\n\n# Use anywhere in statements with editable references behavior\nstatements:\n  - id: member_count\n    wikidata_property: P2124\n    behavior:\n      references: editable  # Curator chooses reference type\n    value:\n      type: quantity\n    references: *standard_reference\n</code></pre> <p>This pattern dramatically reduces duplication and makes profile maintenance easier.</p>"},{"location":"gkc/profiles/#qualifiers-statement-modifiers","title":"Qualifiers: Statement Modifiers","text":"<p>Qualifiers are properties that modify or provide context for a main statement. They appear alongside the statement value in Wikidata's data model.</p>"},{"location":"gkc/profiles/#qualifier-structure","title":"Qualifier Structure","text":"<pre><code>qualifiers:\n  - id: qualifier_id\n    label: Human-readable label\n    wikidata_property: P123\n    required: false        # Is qualifier mandatory?\n    max_count: 1           # null = unlimited\n\n    value:\n      type: string         # Qualifier's datatype\n      constraints: []\n</code></pre>"},{"location":"gkc/profiles/#common-qualifier-examples","title":"Common Qualifier Examples","text":"<p>Point in time (P585) - When a statement is true: <pre><code>- id: point_in_time\n  label: Point in time\n  wikidata_property: P585\n  required: true\n  max_count: 1\n  value:\n    type: time\n</code></pre></p> <p>Language of work or name (P407) - Language for text: <pre><code>- id: language_of_work\n  label: Language of work or name\n  wikidata_property: P407\n  required: false\n  max_count: 1\n  value:\n    type: item\n    allowed_items:\n      source: sparql\n      query: SELECT ?item ?itemLabel WHERE { ... }\n</code></pre></p> <p>Criterion used (P1013) - How location was determined: <pre><code>- id: criterion_used\n  label: Criterion used\n  wikidata_property: P1013\n  required: false\n  value:\n    type: item\n</code></pre></p>"},{"location":"gkc/profiles/#entity-metadata-labels-descriptions-aliases-and-sitelinks","title":"Entity Metadata: Labels, Descriptions, Aliases, and Sitelinks","text":"<p>In addition to statements (claims), Wikidata items have entity-level metadata that provides context and discoverability:</p> <ul> <li>Labels: The primary name in each language (only one per language)</li> <li>Descriptions: Short, distinctive descriptions (only one per language)</li> <li>Aliases: Alternative names, historical names, abbreviations (multiple per language)</li> <li>Sitelinks: Links to Wikipedia, Wikimedia Commons, and other wiki projects</li> </ul> <p>SpiritSafe profiles can optionally declare curator guidance for these metadata elements to ensure consistency and quality across language versions.</p>"},{"location":"gkc/profiles/#metadata-in-wizard-workflows","title":"Metadata in Wizard Workflows","text":"<p>Entity metadata maps to Wizard Step 2 (Basic Identification) for labels/descriptions/aliases and Step 4 (Cross-Platform Links) for sitelinks. The wizard renders these sections based on what's defined in the profile.</p>"},{"location":"gkc/profiles/#labels","title":"Labels","text":"<p>Labels are the primary identifiers for items in human-readable form. Each language gets exactly one label.</p> <pre><code>labels:\n  en:\n    label: Label\n    description: The primary name by which this entity is known.\n    required: true\n    guidance: |\n      Use the name that the tribe uses in referring to itself as the primary label.\n      Check official sources and tribal government websites before setting.\n\n  es:\n    label: Label (Spanish)\n    description: The entity name in Spanish.\n    required: false\n    guidance: |\n      Use official Spanish names where available, preferring tribal self-designations.\n</code></pre> <p>Design notes: - One per language: Wikidata enforces this strictly\u2014a label is immutable within a language - Statement ordering: Place commonly expected languages first in the profile to set curator expectations - Guidance: Include curator instructions on naming conventions and authority sources</p>"},{"location":"gkc/profiles/#descriptions","title":"Descriptions","text":"<p>Descriptions disambiguate items when there are multiple with the same or similar labels. They should be concise and contextual.</p> <pre><code>descriptions:\n  en:\n    label: Description\n    description: A short, distinctive description to disambiguate this entity.\n    guidance: |\n      Format: \"federally recognized Native American tribe based in [region/state]\"\n      Example: \"federally recognized Native American tribe based in Oklahoma\"\n      Keep under 250 characters. Use present tense when possible.\n\n  fr:\n    label: Description (French)\n    description: La description en fran\u00e7ais.\n    required: false\n    guidance: |\n      Translate the English description or write a naturally-phrased French equivalent.\n</code></pre> <p>Design notes: - Disambiguation: Should help distinguish this item from others with same/similar label - Consistency: Use consistent language and phrasing across language versions - Conciseness: Aim for 50\u2013150 characters; under 250 is a strict limit</p>"},{"location":"gkc/profiles/#aliases","title":"Aliases","text":"<p>Aliases capture alternative names: historical names, abbreviations, informal names, names in other languages, transliterations, etc.</p> <pre><code>aliases:\n  en:\n    label: Aliases\n    description: Alternative names by which this entity is known or has been referred to.\n    required: false\n    guidance: |\n      Include official alternative names, historical names, acronyms, and colloquial variants.\n      For tribes: include the U.S. Government official name if different from self-designation.\n      Example aliases:\n        - \"Northern Band of Paiute Indians\"\n        - \"Northern Paiute\"\n        - \"Kucedika\"\n    examples:\n      - \"Northern Band\"\n      - \"Historic name from federal recognition document\"\n      - \"Colloquial short form\"\n</code></pre> <p>Design notes: - No uniqueness constraint: Many items can have the same alias - Multiple per language: Aliases are not limited (unlike labels/descriptions) - Type-specific guidance: Tribes \u2192 government names; places \u2192 historical names; organizations \u2192 acronyms - Bidirectional matching: Aliases improve discoverability in search</p>"},{"location":"gkc/profiles/#sitelinks","title":"Sitelinks","text":"<p>Sitelinks are references to articles in Wikimedia projects (Wikipedia, Wikimedia Commons, etc.) in different languages. They establish the \"interlinking\" between language versions.</p> <pre><code>sitelinks:\n  required: false\n  validation_policy: allow_existing_nonconforming\n  guidance: |\n    Sitelinks connect this Wikidata item to Wikipedia articles and other Wikimedia projects.\n    IMPORTANT: Each language+project combination can only exist on ONE Wikidata item.\n    Check for conflicts before adding any sitelink. The Wikidata API will reject duplicates.\n\n  languages:\n    en:\n      project: wikipedia\n      description: English Wikipedia article\n      required: false\n      guidance: |\n        Article title should match the item label or follow Wikipedia naming conventions.\n        If an article exists, add it here to improve discoverability.\n\n    es:\n      project: wikipedia\n      description: Spanish Wikipedia article\n      required: false\n      guidance: |\n        Add if this entity has significant coverage in Spanish Wikipedia.\n\n    commons:\n      project: commons\n      description: Wikimedia Commons entity (for media files)\n      required: false\n      guidance: |\n        Use only for entities that deserve a category or page on Commons (cultural institutions, \n        notable historical figures, geographic features with associated media collections).\n</code></pre> <p>Design notes: - Uniqueness constraint: Wikidata enforces one sitelink per language+project combination across ALL items - Validation policy: Use <code>allow_existing_nonconforming</code> to prevent blocking item creation when conflicts exist - Project scope: Limit to projects with active communities (Wikipedia, Commons, etc.) - Conflict detection: Curators should verify no conflicting item already links to target article before adding - Wizard rendering: Sitelinks appear in Step 4 (Cross-Platform Links) with conflict validation</p>"},{"location":"gkc/profiles/#secondary-entities-and-profile-references","title":"Secondary Entities and Profile References","text":"<p>Many entity types naturally reference secondary entities\u2014related entities of different types that need their own profiles. For example:</p> <ul> <li>A Federally Recognized Tribe profile might link to:</li> <li>\"Office held by head of state\" (a position/role entity)</li> <li> <p>\"Headquarters location\" (a geographic entity)</p> </li> <li> <p>A University profile might link to:</p> </li> <li>\"Founded by\" (person or organization entities)</li> <li>\"Academic department\" entities</li> <li>\"Campus\" (geographic entities)</li> </ul> <p>When a statement references another entity that should be managed by its own profile, use the <code>entity_profile</code> key at the statement level to link to that profile.</p>"},{"location":"gkc/profiles/#profile-reference-syntax","title":"Profile Reference Syntax","text":"<p>The <code>entity_profile</code> field contains a filename reference (without extension) to another profile registered in the SpiritSafe:</p> <pre><code>statements:\n  - id: office_held_by_head_of_state\n    label: Office held by head of state\n    wikidata_property: P1906\n    type: statement\n    entity_profile: OfficeHeldByHeadOfState  # Filename reference (no .yaml extension)\n\n    value:\n      type: item\n\n    references: *standard_reference\n</code></pre> <p>Key design points: - <code>entity_profile</code> is specified at the statement level, not the value level - Value is always <code>type: item</code> (Wikidata entity reference) - Filename reference uses PascalCase without file extension - SpiritSafe CI enforces uniqueness of profile filenames across the repository</p>"},{"location":"gkc/profiles/#how-profile-references-work-in-wizards","title":"How Profile References Work in Wizards","text":"<p>During Wizard Step 1 (Plan of Action): - Wizard scans all statements for <code>entity_profile</code> keys - Lists secondary entity types that may need creation: \"You may also create or link to: Office Held by Head of State\" - Provides context: \"If the entity doesn't exist in Wikidata, the wizard can help you create it\"</p> <p>During Wizard Step 3 (Statements): - When curator encounters a statement with <code>entity_profile</code>, the wizard always shows:   - Option 1: Select existing item (QID) from Wikidata (standard item selection widget)   - Option 2: \"Create new [entity type]\" button (always visible when <code>entity_profile</code> is present) - If curator chooses \"Create new\":   - Sub-wizard launches using the linked profile (full 5-step workflow with summaries)   - Curator completes the secondary entity creation   - Sub-wizard final summary offers: \"Create another [entity type]\" or \"Return to [primary entity] wizard\"   - Returns to main wizard with new entity's temporary ID populated   - Secondary entity is flagged for creation alongside primary entity</p> <p>During Wizard Step 5 (Review): - Section shows \"Secondary entities to be created\" with:   - List of new entities created during workflow   - Summary of each (label, type, key statements)   - Option to edit or remove before shipping - When shipped, all entities are created in dependency order (secondary entities first, then primary)</p> <p>Note on sub-wizard design: Sub-wizards follow the same 5-step structure as primary wizards, including Plan of Action and Review screens. Post-MVP, sub-wizards may themselves spawn tertiary entity creation (nested wizard chains).</p>"},{"location":"gkc/profiles/#when-to-use-profile-references","title":"When to Use Profile References","text":"<p>Use <code>entity_profile</code> when: - The referenced entity is complex enough to warrant its own profile - Curators may need to create these entities during workflow (not just link to existing) - The entity type has specific validation rules or statement patterns - You want wizard support for creating related entities inline with full workflow support</p> <p>Don't use <code>entity_profile</code> when: - The entity is generic and well-established in Wikidata (e.g., \"country\" or \"language\") - The entity is unlikely to be created by curators (only linked to existing items) - A simple choice list is sufficient (<code>allowed_items</code> with SPARQL query) - The relationship is to a person or other entity managed through different workflows</p>"},{"location":"gkc/profiles/#example-tribal-government-with-position-entities","title":"Example: Tribal Government with Position Entities","text":"<pre><code># TribalGovernmentUS.yaml\nstatements:\n  - id: head_of_government\n    label: Head of government\n    wikidata_property: P6\n    value:\n      type: item\n      # No entity_profile - this links to a person, managed by a different workflow\n    references: *standard_reference\n\n  - id: office_held_by_head_of_state\n    label: Office held by head of state\n    wikidata_property: P1906\n    entity_profile: OfficeHeldByHeadOfState  # Links to secondary entity profile\n    guidance: &gt;\n      This is the office itself (e.g., \"Principal Chief of the Cherokee Nation\"),\n      not the person holding the office.\n    value:\n      type: item\n    references: *standard_reference\n</code></pre> <p>In this pattern: - <code>head_of_government</code> (P6) links to a person (QID) - no special handling needed - <code>office_held_by_head_of_state</code> (P1906) links to an office entity that may need creation - wizard always shows \"Create new\" button</p>"},{"location":"gkc/profiles/#best-practices","title":"Best Practices","text":""},{"location":"gkc/profiles/#1-design-profiles-for-curator-mental-models","title":"1. Design Profiles for Curator Mental Models","text":"<p>Profiles should align with how curators think about entities, not how developers think about code. The wizard steps (Plan \u2192 Identification \u2192 Statements \u2192 Links \u2192 Review) mirror curator workflows\u2014design profiles to support that flow.</p> <p>Wizard-aware design: - Order statements to reflect community expectations\u2014most important statements first in the YAML - All statements are technically optional; communities aim to eventually fill all agreed-upon statements - Use clear <code>input_prompt</code> text that guides curators at data-entry time - Provide <code>guidance</code> for fields that need context (authority sources, formatting conventions, implications of not providing) - Group semantically related statements together in the YAML (they'll appear together in Step 3) - Use <code>entity_profile</code> for secondary entities that curators may need to create inline - Philosophy: Support incremental contribution\u2014minimal viable entities (labels + instance_of) can be enhanced later</p>"},{"location":"gkc/profiles/#2-keep-profiles-focused-and-cohesive","title":"2. Keep Profiles Focused and Cohesive","text":"<p>A profile should represent a single, well-defined entity type. Don't try to combine multiple unrelated entity types into one profile.</p> <p>Good: <pre><code>name: Federally Recognized Tribe\ndescription: Native American tribes in the United States...\n</code></pre></p> <p>Bad: <pre><code>name: Native American Entities\ndescription: Tribes, nations, organizations, and cultural groups...\n</code></pre></p>"},{"location":"gkc/profiles/#2-use-reusable-patterns","title":"2. Use Reusable Patterns","text":"<p>Define common patterns once at the top and reuse them via YAML anchors.</p> <pre><code># Define standard_reference, standard_source_qualifier, etc.\nstandard_reference: &amp;standard_reference\n  # ...\n\n# Then use in every statement that needs it\nstatements:\n  - id: ...; references: *standard_reference\n</code></pre>"},{"location":"gkc/profiles/#3-document-constraints-clearly","title":"3. Document Constraints Clearly","text":"<p>Each constraint should have a clear <code>description</code> that explains both what it does and why:</p> <pre><code>constraints:\n  - type: format\n    pattern: '^\\d+$'\n    description: 'OSM relation IDs are numeric only'  # Good\n  - type: format\n    pattern: '^\\d+$'  # Bad - no explanation\n</code></pre>"},{"location":"gkc/profiles/#4-choose-validation-policy-and-behavior-intentionally","title":"4. Choose Validation Policy and Behavior Intentionally","text":"<p>For validation_policy: - Use <code>allow_existing_nonconforming</code> (default) unless you have a specific reason not to - Use <code>strict</code> only when conformance is critical and you control all existing data</p> <p>For behavior: - Use <code>behavior.references: auto_derive</code> when references are predictable and can be derived from statement value (reduces curator work, applies universally) - Use <code>behavior.references: editable</code> when curators need flexibility in choosing reference types - Use <code>behavior.value: fixed</code> when all entities of this type share the same value (e.g., instance_of classification)</p> <pre><code># Example: locked value with editable references\nbehavior:\n  value: fixed\n  references: editable\n\nvalue:\n  fixed: Q7840353\n  label: federally recognized Native American tribe\n\n# Example: editable value with auto-derived references\nbehavior:\n  references: auto_derive\n\nvalue:\n  type: url\n\nreferences:\n  target:\n    value_source: statement_value  # URL becomes its own reference\n</code></pre>"},{"location":"gkc/profiles/#5-leverage-sparql-for-choice-lists","title":"5. Leverage SPARQL for Choice Lists","text":"<p>Instead of hardcoding choices, query Wikidata dynamically:</p> <pre><code>allowed_items:\n  source: sparql\n  query: |\n    PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n    PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\n\n    SELECT ?item ?itemLabel\n    WHERE {\n      ?item wdt:P31 wd:Q6581097 .  # Administrative territory\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n    }\n</code></pre>"},{"location":"gkc/profiles/#6-use-explicit-prefixes-in-sparql-queries","title":"6. Use Explicit Prefixes in SPARQL Queries","text":"<p>Since profiles may be used with alternate SPARQL endpoints (Qlever, Virtuoso), use explicit prefixes:</p> <pre><code>query: |\n  PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n  PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\n  PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\n\n  SELECT ?item ?itemLabel\n  WHERE {\n    ?item wdt:P31 wd:Q6581097 ;\n          rdfs:label ?itemLabel .\n    FILTER(LANG(?itemLabel) = \"en\")\n  }\n</code></pre> <p>Avoid <code>SERVICE wikibase:label</code> which only works on WDQS.</p>"},{"location":"gkc/profiles/#7-set-reasonable-refresh-policies-for-choice-lists","title":"7. Set Reasonable Refresh Policies for Choice Lists","text":"<pre><code>refresh: manual      # Check manually when updated\nrefresh: daily       # Check once per day\nrefresh: weekly      # Check once per week\nrefresh: on_release  # Check on new Wikidata releases\n</code></pre> <p>Use <code>manual</code> during development, <code>daily</code> or <code>weekly</code> for production.</p>"},{"location":"gkc/profiles/#8-make-references-required-where-domain-appropriate","title":"8. Make References Required Where Domain-Appropriate","text":"<p>External IDs typically don't need references (they're declarations). But facts that can be disputed should have references:</p> <pre><code># No references needed - it's an identifier\n- id: osm_relation_id\n  # ...\n  # No references block\n\n# References required - it's a factual claim\n- id: headquarters_location\n  # ...\n  references: *standard_reference\n</code></pre>"},{"location":"gkc/profiles/#9-test-profiles-with-wizard-workflows","title":"9. Test Profiles With Wizard Workflows","text":"<p>The best way to validate a profile is to walk through the wizard it generates:</p> <ol> <li>Launch wizard with profile: <code>gkc profile form --profile YourProfile --new</code></li> <li>Walk through all 5 steps as a curator would</li> <li>Check:</li> <li>Are <code>input_prompt</code> messages clear and helpful?</li> <li>Does statement ordering reflect community priorities?</li> <li>Can you create a minimal viable entity by skipping most statements?</li> <li>Are choice lists populated and relevant?</li> <li>Does <code>behavior.references: auto_derive</code> work correctly and reduce curator burden?</li> <li>Does <code>behavior.value: fixed</code> display appropriately as read-only?</li> <li>Do secondary entities (<code>entity_profile</code>) appear at the right time with \"Create new\" option?</li> <li>Is <code>guidance</code> text helpful for understanding implications of skipping statements?</li> <li>Test the incremental workflow:</li> <li>Create minimal entity (labels + instance_of only)</li> <li>\"Ship\" it to see if review step allows minimal data</li> <li>Return and enhance with more statements</li> <li>Iterate based on curator experience, not code convenience</li> </ol>"},{"location":"gkc/profiles/#complete-example-federally-recognized-tribe-profile","title":"Complete Example: Federally Recognized Tribe Profile","text":"<p>Here's the complete tribal government profile used throughout this phase:</p> <pre><code>name: Federally Recognized Tribe\ndescription: &gt;\n  Canonical form for representing a federally recognized Native American tribe\n  in the United States, based loosely on EntitySchema E502.\n\n# Entity labels (multilingual)\nlabels:\n  en:\n    label: Label\n    description: The primary name by which this tribe is commonly known in English.\n    required: true\n    guidance: &gt;\n      Use the name that the tribe uses in referring to itself as the primary label where possible.\n      Check official tribal government websites and Wikidata items for existing tribes.\n      Prefer the tribe's self-designation over external government names.\n\n# Entity descriptions (multilingual)\ndescriptions:\n  en:\n    label: Description\n    description: A short, distinctive description to disambiguate this tribe from others.\n    required: true\n    guidance: &gt;\n      Format: \"federally recognized Native American tribe based in [region/state]\"\n      Example: \"federally recognized Native American tribe based in Oklahoma\"\n      Keep concise (under 250 characters) and informative.\n\n# Entity aliases (multilingual alternative names)\naliases:\n  en:\n    label: Aliases\n    description: Alternative names by which this tribe is known or has been referred to.\n    required: false\n    guidance: &gt;\n      Include an alias for the official name of the tribe as referred to by the U.S. Government\n      (e.g., from the Bureau of Indian Affairs list).\n      Include historical names and names in other languages when available.\n    examples:\n      - \"Anishinaabek\"\n      - \"Northern Band\"\n      - \"Official tribal name from federal recognition document\"\n\n# Entity sitelinks (Wikipedia and other wiki language versions)\nsitelinks:\n  required: false\n  validation_policy: allow_existing_nonconforming\n  guidance: &gt;\n    Sitelinks connect this item to Wikipedia articles and other Wikimedia projects in different languages.\n    Each language/project combination can only appear on ONE Wikidata item - check for conflicts\n    before adding sitelinks. Validation at profile level can check format, but uniqueness\n    constraint will only be caught when writing to Wikidata.\n  languages:\n    en:\n      project: wikipedia\n      description: English Wikipedia article\n      required: false\n      guidance: &gt;\n        Article title should match the tribe name or established Wikipedia conventions.\n    fr:\n      project: wikipedia\n      description: French Wikipedia article\n      required: false\n      guidance: &gt;\n        Include if a French Wikipedia article exists for this tribe.\n\n# Reusable reference patterns\nstandard_reference: &amp;standard_reference\n  min_count: 1\n  validation_policy: allow_existing_nonconforming\n  allowed:\n    - id: stated_in\n      wikidata_property: P248\n      type: item\n      label: Stated in\n      description: Reference to source document or database\n    - id: reference_url\n      wikidata_property: P854\n      type: url\n      label: Reference URL\n      description: Direct URL to source\n\nstatements:\n\n  - id: instance_of\n    label: Instance of\n    wikidata_property: P31\n    type: statement\n    max_count: null\n    validation_policy: allow_existing_nonconforming\n\n    behavior:\n      value: fixed        # Value locked to Q7840353\n      references: editable  # References manually provided\n\n    value:\n      type: item\n      fixed: Q7840353\n      label: federally recognized Native American tribe in the United States\n\n    references: *standard_reference\n\n  - id: native_name\n    label: Native name\n    wikidata_property: P1705\n    type: statement\n    required: false\n    max_count: null\n\n    value:\n      type: monolingualtext\n      constraints:\n        - type: language_required\n        - type: valid_language_code\n\n    qualifiers:\n      - id: language_of_work\n        label: Language of work or name\n        wikidata_property: P407\n        required: false\n        value:\n          type: item\n          allowed_items:\n            source: sparql\n            query: |\n              PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n              PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\n              PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\n\n              SELECT ?item ?itemLabel ?languageCode\n              WHERE {\n                ?item wdt:P31/wdt:P279* wd:Q34770 ;\n                      wdt:P424 ?languageCode ;\n                      rdfs:label ?itemLabel .\n                FILTER(LANG(?itemLabel) = \"en\")\n              }\n            refresh: weekly\n\n    references: *standard_reference\n\n  - id: headquarters_location\n    label: Headquarters location\n    wikidata_property: P159\n    type: statement\n    required: false\n    max_count: 1\n\n    value:\n      type: item\n\n    qualifiers:\n      - id: street_address\n        label: Street address\n        wikidata_property: P6375\n        required: false\n        value:\n          type: monolingualtext\n          constraints:\n            - type: language_required\n\n      - id: postal_code\n        label: Postal code\n        wikidata_property: P281\n        required: false\n        value:\n          type: string\n\n      - id: coordinate_location\n        label: Coordinate location\n        wikidata_property: P625\n        required: false\n        value:\n          type: globecoordinate\n          constraints:\n            - type: precision\n              min_precision: 0.0001\n              max_precision: 0.01\n\n    references: *standard_reference\n\n  - id: inception\n    label: Inception\n    wikidata_property: P571\n    type: statement\n    required: false\n    max_count: 1\n\n    value:\n      type: time\n      constraints:\n        - type: precision\n          allowed_precisions: [9, 10, 11]\n          auto_derive: true\n        - type: calendar_model\n          default: Q1985727\n        - type: format\n          patterns: ['YYYY', 'YYYY-MM', 'YYYY-MM-DD']\n\n    references: *standard_reference\n\n  - id: osm_relation_id\n    label: OpenStreetMap relation ID\n    wikidata_property: P402\n    type: statement\n    required: false\n    max_count: 1\n\n    value:\n      type: external-id\n      constraints:\n        - type: format\n          pattern: '^\\d+$'\n        - type: formatter_url\n          url_pattern: 'http://www.openstreetmap.org/relation/$1'\n          validate: true\n          validation_method: http_head\n\n  - id: flag_image\n    label: Flag image\n    wikidata_property: P41\n    type: statement\n    required: false\n    max_count: 1\n\n    value:\n      type: commonsMedia\n      constraints:\n        - type: file_exists\n          validate: true\n          validation_method: commons_api\n        - type: file_type\n          allowed_types: ['image/svg+xml', 'image/png', 'image/jpeg']\n\n    references: *standard_reference\n</code></pre>"},{"location":"gkc/profiles/#step-by-step-building-your-own-profile","title":"Step-by-Step: Building Your Own Profile","text":"<ol> <li> <p>Define the entity type - What kind of thing are you profiling?    <pre><code>name: My Entity Type\ndescription: &gt;\n  Clear description of scope, examples, and use cases.\n</code></pre></p> </li> <li> <p>Identify key properties - Which Wikidata properties are essential?</p> </li> <li>Look at existing Wikidata items of this type</li> <li>Check EntitySchemas for precedent</li> <li> <p>Consult domain-specific schemas</p> </li> <li> <p>Start with required statements - What must always be present?    <pre><code>statements:\n  - id: statement_id\n    label: Statement Label\n    wikidata_property: P123\n    type: statement\n    required: true\n</code></pre></p> </li> <li> <p>Add datatype definitions - What type of value does each statement hold?    <pre><code>value:\n  type: string  # or item, url, quantity, time, etc.\n</code></pre></p> </li> <li> <p>Define constraints - What rules validate the data?    <pre><code>constraints:\n  - type: format\n    pattern: '^[A-Z]+$'\n</code></pre></p> </li> <li> <p>Add references where needed - Which statements need sources?    <pre><code>references:\n  required: true\n  allowed:\n    - id: stated_in\n      wikidata_property: P248\n      type: item\n</code></pre></p> </li> <li> <p>Test with real data - Load a profile and validate against actual items</p> </li> <li>Iterate based on feedback - Refine constraints and statement definitions</li> <li>Document edge cases - Add comments explaining non-obvious choices</li> </ol>"},{"location":"gkc/profiles/#future-enhancements","title":"Future Enhancements","text":"<p>As profiles are used in practice, expect iterative refinements:</p> <ul> <li>Wizard step customization - Profile-level <code>wizard_steps</code> metadata to customize step organization beyond the default 5-step structure</li> <li>Conditional statements - Statements that appear only if certain conditions are met (e.g., \"headquarters location\" only for organizations with <code>instance_of: organization</code>)</li> <li>Qualifier constraints - Validate qualifiers without loading full statement</li> <li>Cross-statement validation - Rules connecting multiple statements  </li> <li>Profile composition - Merging or extending existing profiles</li> <li>Multi-language support - Localized statement labels and prompts</li> <li>Version management - Profile versioning and migration guides</li> <li>Wizard branching logic - More sophisticated secondary entity workflows with dependency tracking</li> </ul>"},{"location":"gkc/profiles/#see-also","title":"See Also","text":"<ul> <li>Architecture Overview - Profile role in GKC pipeline</li> <li>API Reference - Profile loading and validation utilities</li> <li>Validation Utilities - Constraint enforcement</li> <li>SpiritSafe Repository - Canonical profile registrants and query assets</li> </ul>"},{"location":"gkc/setup/","title":"Setup and Orientation","text":"<p>This guide gets you ready to use GKC and points you to the Data Distillery Workflow. It is not a full tutorial yet; consider it a practical checklist plus a map to the next steps.</p>"},{"location":"gkc/setup/#1-what-you-need-before-you-start","title":"1. What You Need Before You Start","text":"<ul> <li>A working Python environment (3.10+ recommended)</li> <li>Access to the data sources you want to ingest (CSV, JSON, API, RDF, etc.)</li> <li>Optional but recommended: credentials for Wikidata, Wikimedia Commons, Wikipedia, and OpenStreetMap</li> </ul> <p>If you do not yet have credentials, you can still explore the workflow locally using dry runs.</p>"},{"location":"gkc/setup/#2-install-the-package","title":"2. Install the Package","text":""},{"location":"gkc/setup/#option-a-install-from-pypi-recommended","title":"Option A: Install from PyPI (Recommended)","text":"<pre><code>pip install gkc\n</code></pre>"},{"location":"gkc/setup/#option-b-install-from-source-development-mode","title":"Option B: Install from Source (Development Mode)","text":"<p>If you want to contribute or work with the latest development version:</p> <pre><code># Clone the repo\ngit clone https://github.com/skybristol/gkc.git\ncd gkc\n\n# Install dependencies (Poetry)\npoetry install\n</code></pre>"},{"location":"gkc/setup/#3-configure-language-settings-optional","title":"3. Configure Language Settings (Optional)","text":"<p>GKC provides nominal support for multilingual data processing. Right now, this only includes filtering Wikidata labels, descriptions, and aliases. By default, the package uses English (<code>\"en\"</code>), but you can configure it to work with other languages.</p>"},{"location":"gkc/setup/#setting-the-language-configuration","title":"Setting the Language Configuration","text":"<pre><code>import gkc\n\n# Use a single language (default: \"en\")\ngkc.set_languages(\"en\")\n\n# Use multiple languages\ngkc.set_languages([\"en\", \"es\", \"fr\"])\n\n# Work with all available languages\ngkc.set_languages(\"all\")\n\n# Check current language setting\ncurrent = gkc.get_languages()\nprint(current)  # Returns: \"en\" or [\"en\", \"es\", \"fr\"] or \"all\"\n</code></pre> <p>When to configure: - Before loading Wikidata items if you need labels in specific languages - When working with multilingual datasets - When you want to filter or display data in languages other than English</p> <p>Plain meaning: Tell GKC which languages you want to work with so it can filter and display labels appropriately.</p>"},{"location":"gkc/setup/#4-configure-credentials-optional-for-now","title":"4. Configure Credentials (Optional for Now)","text":"<p>If you intend to publish data to Wikidata, Wikimedia Commons, or OpenStreetMap, you will need credentials.</p> <ul> <li>Authentication walks through setting up API credentials.</li> <li>You can skip this for now if you are only running local transformations.</li> </ul>"},{"location":"gkc/setup/#5-choose-a-starting-workflow","title":"5. Choose a Starting Workflow","text":"<p>Most users begin with one of these paths:</p>"},{"location":"gkc/setup/#path-a-link-my-data-to-wikidata","title":"Path A: Link my data to Wikidata","text":"<ul> <li>Mash Tun -&gt; Fermentation -&gt; Distillation -&gt; Bottling</li> <li>Good for basic reconciliation and export</li> </ul>"},{"location":"gkc/setup/#path-b-integrate-multiple-sources-first","title":"Path B: Integrate multiple sources first","text":"<ul> <li>Mash Tun (multiple sources) -&gt; Fermentation -&gt; Distillation -&gt; Refinement -&gt; Proofing -&gt; Blending -&gt; Bottling</li> <li>Good for multi-source consolidation</li> </ul>"},{"location":"gkc/setup/#path-c-explore-without-publishing","title":"Path C: Explore without publishing","text":"<ul> <li>Mash Tun -&gt; Fermentation -&gt; Distillation</li> <li>Stop before output; focus on data cleaning and linking</li> </ul>"},{"location":"gkc/setup/#6-what-to-expect-next","title":"6. What to Expect Next","text":"<p>As implementation work progresses, this setup guide will continue to expand with:</p> <ul> <li>A quickstart example with real data</li> <li>Configuration file templates for each stage</li> <li>CLI usage patterns</li> <li>How to run a full pipeline end-to-end</li> </ul> <p>Check back as new releases are published to PyPI.</p>"},{"location":"gkc/setup/#8-need-more-context","title":"8. Need More Context?","text":"<ul> <li>Background explains the project goals and history</li> <li>Authentication covers credentials and access</li> </ul> <p>If you are ready to implement or contribute, check the GitHub issues associated with each stage label.</p>"},{"location":"gkc/shipping/","title":"Shipping: Submission &amp; Receipt","text":""},{"location":"gkc/shipping/#overview","title":"Overview","text":"<p>Shipping is the stage that handles submission of bottled and packaged data to components of the Global Knowledge Commons - Wikidata, OpenStreetMap, Wikimedia Commons, etc. Not all data gets shipped; some of it relies on hand delivery such as filled templates in Wikipedia.</p> Aspect Details Input Bottled data transformed into the proper formats for target systems What Happens Validation against Barrel Profiles, interaction with write APIs, transmission of data, receipt of delivery Output Receipt notices suitable for annotation for source systems and users Best For Final distribution of finished products (until the next distillation) Typical Duration Seconds to hours, depending on receiving capacity and amount being shipped"},{"location":"gkc/shipping/#the-problem-shipping-solves","title":"The Problem Shipping Solves","text":"<p>Delivery to consumers:</p> <ul> <li>Shipping docks are all different High variability in write APIs</li> <li>Final distribution varies Wikimedia and OSM and others all have different write APIs</li> <li>API rate limits must be respected</li> <li>Receipts document point in time state successful placement of content recorded</li> </ul> <p>The cost of skipping Shipping: Data isn't available in the Global Knowledge Commons until this happens</p>"},{"location":"gkc/shipping/#input-contract","title":"Input Contract","text":"<p>Records entering Shipping should:</p> <ol> <li>Be bottled into the appropriate format \u2014 Only records that pass structure/content validation</li> <li>Distinguish new or updates \u2014 QIDs, OSM IDs, etc.</li> <li>Include provenance \u2014 References and source metadata</li> <li>Be validated \u2014 No known schema errors or conflicts</li> </ol>"},{"location":"gkc/shipping/#supporting-systems","title":"Supporting Systems","text":""},{"location":"gkc/shipping/#barrel-provenance","title":"Barrel (Provenance)","text":"<p>Stores: - History of actions suitable for annotation on shipped product</p>"},{"location":"gkc/shipping/#spirit-safe-validation","title":"Spirit Safe (Validation)","text":"<p>Provides: - Final output models to verify the shippable product</p>"},{"location":"gkc/shipping/#relationship-to-other-stages","title":"Relationship to Other Stages","text":"<p>After: Data are available across components of the Commons</p>"},{"location":"gkc/shipping/#common-patterns","title":"Common Patterns","text":""},{"location":"gkc/shipping/#pattern-1-i-need-a-dry-run-first","title":"Pattern 1: \"I need a dry-run first\"","text":"<p>Generate export files and reports without uploading. Use diff or review to confirm before pushing to target systems.</p>"},{"location":"gkc/shipping/#pattern-2-i-need-multiple-outputs","title":"Pattern 2: \"I need multiple outputs\"","text":"<p>Configure Bottling to output in multiple formats at once (Wikidata JSON + Wikipedia infobox + OSM tags).</p>"},{"location":"gkc/shipping/#pattern-3-i-want-to-export-only-high-confidence-records","title":"Pattern 3: \"I want to export only high-confidence records\"","text":"<p>Filter by <code>_proofing_status == \"pass\"</code> or a minimum quality threshold.</p>"},{"location":"gkc/shipping/#reference","title":"Reference","text":"<ul> <li>API Reference: Shipper API</li> <li>Target API Specs: -- MediaWiki Action API; overall framework for interacting with any MediaWiki instance -- MediaWiki Wikibase extension API documentation; includes several actions such as wbeditentity, wbsetclaim, etc. -- OpenStreetMap API -- OpenStreetMap API v0.6 Specifications</li> </ul>"},{"location":"gkc/shipping/#github-issues-development","title":"GitHub Issues &amp; Development","text":"<p>Work on the Shipping stage is tracked under the <code>ship</code> label.</p> <p>Other Workflow Stages: - <code>mash</code> \u2014 Data Ingestion - <code>ferment</code> \u2014 Cleaning &amp; Normalization - <code>distill</code> \u2014 Reconciliation &amp; Linking - <code>refine</code> \u2014 Deduplication &amp; Enrichment - <code>proof</code> \u2014 Quality Assurance - <code>blend</code> \u2014 Multi-Source Merging - <code>bottle</code> \u2014 Bottling &amp; packaging</p>"},{"location":"gkc/utilities/","title":"GKC Utility Modules","text":"<p>GKC provides two main utility modules for working with Wikidata and other knowledge graph systems:</p> <ul> <li>SPARQL Query Utilities: Execute SPARQL queries against Wikidata and other endpoints</li> <li>ShEx Validation Utilities: Validate RDF data against ShEx schemas</li> </ul> <p>These utilities are independent, reusable components that work both as Python libraries and through the CLI.</p>"},{"location":"gkc/utilities/#sparql-query-utilities","title":"SPARQL Query Utilities","text":"<p>The GKC SPARQL module provides utilities for executing SPARQL queries against Wikidata, DBpedia, or any other SPARQL endpoint. It supports multiple input formats (raw queries, Wikidata URLs) and output types (JSON, DataFrames, CSV).</p>"},{"location":"gkc/utilities/#features","title":"Features","text":"<ul> <li>Multiple Input Formats: Raw SPARQL queries or Wikidata Query Service URLs</li> <li>Multiple Output Types: JSON objects, Python dictionaries, pandas DataFrames, CSV</li> <li>Error Handling: Comprehensive error messages and custom exceptions</li> <li>Custom Endpoints: Query any SPARQL endpoint, not just Wikidata</li> <li>Pandas Integration: Optional pandas support for data analysis</li> <li>Clean API: Both class-based and convenience functions</li> </ul>"},{"location":"gkc/utilities/#installation","title":"Installation","text":"<p>The SPARQL module is included in GKC. For optional pandas support:</p> <pre><code>pip install pandas\n</code></pre>"},{"location":"gkc/utilities/#quick-start","title":"Quick Start","text":""},{"location":"gkc/utilities/#basic-query","title":"Basic Query","text":"<pre><code>from gkc import SPARQLQuery\n\nexecutor = SPARQLQuery()\nresults = executor.query(\"\"\"\n    SELECT ?item ?itemLabel WHERE {\n      ?item wdt:P31 wd:Q146 .\n      SERVICE wikibase:label {\n        bd:serviceParam wikibase:language \"en\" .\n      }\n    }\n    LIMIT 5\n\"\"\")\nprint(results)\n</code></pre>"},{"location":"gkc/utilities/#query-from-wikidata-url","title":"Query from Wikidata URL","text":"<p>If you build a query using the Wikidata Query Service (WDQS), the URL can be copied and used directly:</p> <pre><code>url = \"https://query.wikidata.org/#SELECT%20?item%20WHERE%20...\"\nresults = executor.query(url)\n</code></pre>"},{"location":"gkc/utilities/#convert-to-dataframe","title":"Convert to DataFrame","text":"<pre><code>df = executor.to_dataframe(\"\"\"\n    SELECT ?item ?itemLabel WHERE {\n      ?item wdt:P31 wd:Q146 .\n      SERVICE wikibase:label {\n        bd:serviceParam wikibase:language \"en\" .\n      }\n    }\n\"\"\")\nprint(df.head())\n</code></pre>"},{"location":"gkc/utilities/#export-to-csv","title":"Export to CSV","text":"<pre><code>executor.to_csv(query, filepath=\"results.csv\")\n</code></pre>"},{"location":"gkc/utilities/#common-usage-patterns","title":"Common Usage Patterns","text":""},{"location":"gkc/utilities/#one-off-queries","title":"One-off Queries","text":"<pre><code>from gkc import execute_sparql, execute_sparql_to_dataframe\n\n# Simple query\nresults = execute_sparql(\"SELECT ?item WHERE { ?item wdt:P31 wd:Q5 } LIMIT 10\")\n\n# Get DataFrame directly\ndf = execute_sparql_to_dataframe(\"SELECT ?item WHERE { ?item wdt:P31 wd:Q5 } LIMIT 10\")\n</code></pre>"},{"location":"gkc/utilities/#custom-endpoints","title":"Custom Endpoints","text":"<pre><code>executor = SPARQLQuery(\n    endpoint=\"https://dbpedia.org/sparql\",\n    user_agent=\"MyApp/1.0\",\n    timeout=60\n)\nresults = executor.query(\"SELECT ?s ?p ?o WHERE { ... }\")\n</code></pre>"},{"location":"gkc/utilities/#error-handling","title":"Error Handling","text":"<pre><code>from gkc.sparql import SPARQLError\n\ntry:\n    results = executor.query(\"SELECT ?item WHERE { ... }\")\nexcept SPARQLError as e:\n    print(f\"Query failed: {e}\")\n</code></pre>"},{"location":"gkc/utilities/#common-sparql-query-patterns","title":"Common SPARQL Query Patterns","text":""},{"location":"gkc/utilities/#get-items-by-type","title":"Get Items by Type","text":"<pre><code>SELECT ?item ?itemLabel WHERE {\n  ?item wdt:P31 wd:Q5 .  # Instance of human\n  SERVICE wikibase:label {\n    bd:serviceParam wikibase:language \"en\" .\n  }\n}\nLIMIT 10\n</code></pre>"},{"location":"gkc/utilities/#filter-by-property-value","title":"Filter by Property Value","text":"<pre><code>SELECT ?item ?itemLabel ?population WHERE {\n  ?item wdt:P31 wd:Q515 .        # Instance of city\n  ?item wdt:P1082 ?population .   # Has population\n  FILTER(?population &gt; 1000000)\n  SERVICE wikibase:label {\n    bd:serviceParam wikibase:language \"en\" .\n  }\n}\nORDER BY DESC(?population)\nLIMIT 10\n</code></pre>"},{"location":"gkc/utilities/#get-related-items","title":"Get Related Items","text":"<pre><code>SELECT ?person ?personLabel ?country ?countryLabel WHERE {\n  ?person wdt:P27 ?country .      # Country of citizenship\n  ?country wdt:P30 wd:Q15 .       # Country in Africa\n  SERVICE wikibase:label {\n    bd:serviceParam wikibase:language \"en\" .\n  }\n}\nLIMIT 10\n</code></pre>"},{"location":"gkc/utilities/#handling-large-result-sets-with-pagination","title":"Handling Large Result Sets with Pagination","text":"<p>When query results exceed thousands of rows, the SPARQL endpoint will time out or limit results. Use the <code>paginate_query()</code> function to automatically fetch large datasets in manageable chunks:</p>"},{"location":"gkc/utilities/#basic-pagination","title":"Basic Pagination","text":"<pre><code>from gkc.sparql import paginate_query\n\n# Fetch all results in batches of 1000\nquery = \"\"\"\n    SELECT ?item ?itemLabel WHERE {\n      ?item wdt:P31 wd:Q5 .\n      SERVICE wikibase:label {\n        bd:serviceParam wikibase:language \"en\" .\n      }\n    }\n\"\"\"\n\nall_results = paginate_query(query)\nprint(f\"Total results: {len(all_results)}\")\n</code></pre>"},{"location":"gkc/utilities/#pagination-with-control","title":"Pagination with Control","text":"<pre><code># Fetch up to 5000 results, 500 per page\nresults = paginate_query(\n    query,\n    page_size=500,\n    max_results=5000,\n    endpoint=\"https://query.wikidata.org/sparql\"\n)\n\nfor result in results:\n    print(result['item'], result['itemLabel'])\n</code></pre>"},{"location":"gkc/utilities/#manual-limitoffset","title":"Manual LIMIT/OFFSET","text":"<p>If you need to handle pagination directly:</p> <pre><code>from gkc.sparql import add_pagination\n\n# Add LIMIT 100 OFFSET 0 to query\npaginated = add_pagination(query, limit=100, offset=0)\n\n# Add without OFFSET\npaginated = add_pagination(query, limit=1000)\n</code></pre> <p>Key Parameters: - <code>page_size</code> - Results per request (default: 1000, max recommended: 5000) - <code>max_results</code> - Stop after this many results (default: None, fetch all) - <code>endpoint</code> - SPARQL endpoint to query (default: Wikidata)</p> <p>When to Use Pagination: - Queries returning thousands of results - Long-running batch processes - Building choice lists for profiles - Mining data for analysis</p>"},{"location":"gkc/utilities/#lookup-cache-and-choice-lists","title":"Lookup Cache and Choice Lists","text":"<p>For profiles that use SPARQL-backed choice lists (e.g., language codes, allowed property values), use the <code>LookupFetcher</code> to cache results and avoid repeated queries:</p>"},{"location":"gkc/utilities/#setup-and-basic-usage","title":"Setup and Basic Usage","text":"<pre><code>from gkc.spirit_safe import LookupFetcher\n\n# Initialize fetcher (uses configured SpiritSafe cache directory)\nfetcher = LookupFetcher()\n\n# Fetch and cache results\nquery = \"\"\"\n    PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n    PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\n    PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;\n\n    SELECT ?item ?itemLabel\n    WHERE {\n      ?item wdt:P31/wdt:P279* wd:Q34770 ;\n            rdfs:label ?itemLabel .\n      FILTER(LANG(?itemLabel) = \"en\")\n    }\n\"\"\"\n\n# Fetch with automatic caching and pagination\nresults = fetcher.fetch(query, refresh_policy=\"weekly\")\nprint(f\"Found {len(results)} languages\")\n</code></pre>"},{"location":"gkc/utilities/#choice-list-normalization","title":"Choice List Normalization","text":"<p>For form generation, normalize results to a consistent choice list format:</p> <pre><code># Fetch and normalize to {id, label, extra_fields} format\nchoices = fetcher.fetch_choice_list(\n    query,\n    id_var=\"item\",\n    label_var=\"itemLabel\",\n    extra_vars=[\"languageCode\"],\n    refresh_policy=\"weekly\"\n)\n\n# Result: [{\"id\": \"Q123\", \"label\": \"Navajo\", \"languageCode\": \"nav\"}]\nfor choice in choices:\n    print(f\"{choice['label']} ({choice['id']})\")\n</code></pre>"},{"location":"gkc/utilities/#refresh-policies","title":"Refresh Policies","text":"<p>Control how often cached results are validated:</p> <pre><code># manual - Check only when explicitly refreshed\nresults = fetcher.fetch(query, refresh_policy=\"manual\")\n\n# daily - Recheck if cache is older than 1 day\nresults = fetcher.fetch(query, refresh_policy=\"daily\")\n\n# weekly - Recheck if cache is older than 1 week\nresults = fetcher.fetch(query, refresh_policy=\"weekly\")\n\n# Force refresh even if cache is fresh\nresults = fetcher.fetch(query, refresh_policy=\"daily\", force_refresh=True)\n</code></pre>"},{"location":"gkc/utilities/#cache-management","title":"Cache Management","text":"<pre><code>from gkc.spirit_safe import LookupCache\n\ncache = LookupCache()\n\n# Check if specific query is cached and fresh\nis_fresh = cache.is_fresh(query, refresh_policy=\"daily\")\n\n# Manually invalidate a specific query\ncache.invalidate(query)\n\n# Clear all cached queries\ncleared_count = cache.clear_all()\nprint(f\"Cleared {cleared_count} cache files\")\n\n# Custom cache directory\ncustom_cache = LookupCache(cache_dir=\"/path/to/cache\")\n</code></pre>"},{"location":"gkc/utilities/#profile-integration-example","title":"Profile Integration Example","text":"<pre><code># In profiles/YourProfile/profile.yaml (SpiritSafe repo)\nvalue:\n  type: item\n  allowed_items:\n    source: sparql\n    query: |\n      PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n      SELECT ?item ?itemLabel WHERE { ... }\n    refresh: weekly\n    fallback_items:\n      - id: Q123\n        label: Fallback option\n</code></pre> <p>The profile loader currently parses and validates profile YAML only; it does not automatically execute SPARQL lookups. Run lookup hydration explicitly (for example, via a dedicated prefetch step or application startup job) to populate cache files.</p>"},{"location":"gkc/utilities/#see-also","title":"See Also","text":"<ul> <li>API Reference: Detailed API documentation at gkc/api/sparql.md</li> <li>SpiritSafe Profiles: gkc/profiles.md - Choice list configuration</li> <li>Wikidata Query Service: https://query.wikidata.org/</li> <li>SPARQL Tutorial: https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service</li> </ul>"},{"location":"gkc/utilities/#shex-validation-utilities","title":"ShEx Validation Utilities","text":"<p>The GKC ShEx module provides validation of RDF data against ShEx (Shape Expression) schemas. It's designed primarily for validating Wikidata entities against EntitySchemas but also supports local files and custom schemas.</p>"},{"location":"gkc/utilities/#features_1","title":"Features","text":"<ul> <li>Wikidata Integration: Validate entities against published EntitySchemas</li> <li>Local File Support: Validate local RDF files against local ShEx schemas</li> <li>Mixed Mode: Use Wikidata entities with local schemas or vice versa</li> <li>Multiple Input Sources: QIDs, EIDs, files, or text strings</li> <li>Detailed Error Reporting: Clear validation error messages</li> <li>CLI &amp; Library: Available as both Python API and command-line tool</li> </ul>"},{"location":"gkc/utilities/#installation_1","title":"Installation","text":"<p>ShEx validation is included in GKC with the PyShEx library:</p> <pre><code>pip install gkc\n</code></pre>"},{"location":"gkc/utilities/#quick-start_1","title":"Quick Start","text":""},{"location":"gkc/utilities/#validate-wikidata-entity","title":"Validate Wikidata Entity","text":"<pre><code>from gkc import ShexValidator\n\n# Validate Wikidata item against EntitySchema\nvalidator = ShexValidator(qid='Q14708404', eid='E502')\nresult = validator.check()\n\nif result.is_valid():\n    print(\"\u2713 Validation passed!\")\nelse:\n    print(\"\u2717 Validation failed\")\n    print(result.results)\n</code></pre>"},{"location":"gkc/utilities/#validate-local-files","title":"Validate Local Files","text":"<pre><code># Validate local RDF against local schema\nvalidator = ShexValidator(\n    rdf_file='entity.ttl',\n    schema_file='schema.shex'\n)\nresult = validator.check()\nprint(f\"Valid: {result.is_valid()}\")\n</code></pre>"},{"location":"gkc/utilities/#mixed-validation","title":"Mixed Validation","text":"<pre><code># Validate Wikidata entity against local schema\nvalidator = ShexValidator(\n    qid='Q42',\n    schema_file='custom_schema.shex'\n)\nresult = validator.check()\n</code></pre>"},{"location":"gkc/utilities/#common-usage-patterns_1","title":"Common Usage Patterns","text":""},{"location":"gkc/utilities/#fluent-api-pattern","title":"Fluent API Pattern","text":"<pre><code>validator = ShexValidator(qid='Q42', eid='E502')\nvalidator.load_specification()  # Load schema\nvalidator.load_rdf()             # Load RDF data\nvalidator.evaluate()             # Perform validation\n\nif validator.passes_inspection():\n    print(\"Valid!\")\n</code></pre>"},{"location":"gkc/utilities/#using-text-strings","title":"Using Text Strings","text":"<pre><code># Validate RDF text against schema text\nvalidator = ShexValidator(\n    rdf_text=my_rdf_turtle,\n    schema_text=my_shex_schema\n)\nresult = validator.check()\n</code></pre>"},{"location":"gkc/utilities/#error-handling_1","title":"Error Handling","text":"<pre><code>from gkc.shex import ShexValidationError\n\ntry:\n    validator = ShexValidator(qid='Q42', eid='E502')\n    validator.check()\n\n    if not validator.is_valid():\n        print(\"Validation failed:\")\n        for result in validator.results:\n            print(f\"  - {result.reason}\")\n\nexcept ShexValidationError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"gkc/utilities/#cli-usage","title":"CLI Usage","text":"<p>The ShEx validator is also available through the GKC command-line interface:</p>"},{"location":"gkc/utilities/#validate-wikidata-entity_1","title":"Validate Wikidata Entity","text":"<pre><code># Basic validation\ngkc shex validate --qid Q14708404 --eid E502\n</code></pre>"},{"location":"gkc/utilities/#validate-local-files_1","title":"Validate Local Files","text":"<pre><code>gkc shex validate --rdf-file entity.ttl --schema-file schema.shex\n</code></pre>"},{"location":"gkc/utilities/#mixed-sources","title":"Mixed Sources","text":"<pre><code># Wikidata entity with local schema\ngkc shex validate --qid Q14708404 --schema-file custom_schema.shex\n\n# Local RDF with Wikidata EntitySchema\ngkc shex validate --rdf-file entity.ttl --eid E502\n</code></pre>"},{"location":"gkc/utilities/#custom-user-agent","title":"Custom User Agent","text":"<pre><code>gkc shex validate --qid Q42 --eid E502 --user-agent \"MyBot/1.0\"\n</code></pre>"},{"location":"gkc/utilities/#understanding-validation-results","title":"Understanding Validation Results","text":""},{"location":"gkc/utilities/#successful-validation","title":"Successful Validation","text":"<p>When validation succeeds, <code>is_valid()</code> returns <code>True</code>:</p> <pre><code>validator = ShexValidator(qid='Q14708404', eid='E502')\nvalidator.check()\n\nif validator.is_valid():\n    print(\"Entity conforms to schema\")\n</code></pre>"},{"location":"gkc/utilities/#failed-validation","title":"Failed Validation","text":"<p>When validation fails, inspect the <code>results</code> attribute for details:</p> <pre><code>validator = ShexValidator(qid='Q736809', eid='E502')\nvalidator.check()\n\nif not validator.is_valid():\n    for result in validator.results:\n        print(f\"Error: {result.reason}\")\n</code></pre> <p>Common error patterns: - <code>\"not in value set\"</code> - Property value doesn't match allowed values - <code>\"does not match\"</code> - Data type or format mismatch - <code>\"Constraint violation\"</code> - Cardinality or required property missing</p>"},{"location":"gkc/utilities/#when-to-use-shex-validation","title":"When to Use ShEx Validation","text":"<p>Use ShEx validation when you need to:</p> <ul> <li>Verify Wikidata items conform to a specific EntitySchema</li> <li>Validate data quality before uploading to Wikidata</li> <li>Test EntitySchema definitions with sample data</li> <li>Ensure consistency across a set of items</li> <li>Develop and debug EntitySchemas</li> </ul> <p>Example: Pre-upload Quality Check</p> <pre><code># Before uploading to Wikidata\nvalidator = ShexValidator(\n    rdf_text=generated_turtle_data,\n    eid='E502'  # Target EntitySchema\n)\n\nif validator.check().is_valid():\n    # Safe to upload\n    upload_to_wikidata(data)\nelse:\n    # Fix validation errors first\n    log_errors(validator.results)\n</code></pre>"},{"location":"gkc/utilities/#see-also_1","title":"See Also","text":"<ul> <li>API Reference: Detailed API documentation at gkc/api/shex.md</li> <li>CLI Reference: Command-line usage at gkc/cli/shex.md</li> <li>EntitySchemas on Wikidata: https://www.wikidata.org/wiki/Wikidata:WikiProject_Schemas</li> <li>ShEx Specification: http://shex.io/</li> </ul>"},{"location":"gkc/utilities/#additional-resources","title":"Additional Resources","text":"<ul> <li>Wikidata Query Service: https://query.wikidata.org/</li> <li>Wikidata EntitySchemas: https://www.wikidata.org/wiki/Wikidata:EntitySchema</li> <li>GKC GitHub Repository: https://github.com/skybristol/gkc</li> </ul>"},{"location":"gkc/api/","title":"API Reference","text":""},{"location":"gkc/api/#overview","title":"Overview","text":"<p>The GKC library is organized into modules corresponding to stages of the data distillery workflow. Each module provides Python functions and classes for loading, transforming, validating, and delivering data to knowledge systems like Wikidata.</p> <p>This reference documents the library API - functions and classes you import and use in Python code. For command-line usage, see the CLI Reference.</p>"},{"location":"gkc/api/#module-organization","title":"Module Organization","text":"<p>GKC modules are grouped by their role in the distillery pipeline:</p> Stage Module Purpose Mash mash Load data from Wikidata and other sources mash_formatters Convert templates to output formats Barrel Schema cooperage Fetch schemas and metadata from target systems Validation / Registry spirit_safe SpiritSafe source config, registry discovery, query hydration, and caching Transform bottler Transform data into Wikidata format Deliver shipper Submit data to Wikidata Utilities auth Authentication for Wikidata and OSM sitelinks Manage Wikipedia sitelinks sparql Query Wikidata with SPARQL Profiles profiles YAML profile loading and validation"},{"location":"gkc/api/#quick-reference-by-task","title":"Quick Reference by Task","text":""},{"location":"gkc/api/#load-a-wikidata-item","title":"Load a Wikidata Item","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n</code></pre> <p>\ud83d\udcd6 Mash Module Documentation</p>"},{"location":"gkc/api/#format-as-quickstatements","title":"Format as QuickStatements","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\nformatter = QSV1Formatter()\nqs_text = formatter.format(template, for_new_item=True)\n</code></pre> <p>\ud83d\udcd6 Mash Formatters Documentation</p>"},{"location":"gkc/api/#discover-and-load-spiritsafe-profiles","title":"Discover and Load SpiritSafe Profiles","text":"<pre><code>import gkc\n\n# default mode is GitHub: skybristol/SpiritSafe@main\nprofiles = gkc.list_profiles()\nmetadata = gkc.get_profile_metadata(\"TribalGovernmentUS\")\nprint(metadata.version)\n</code></pre> <p>\ud83d\udcd6 SpiritSafe Module Documentation</p>"},{"location":"gkc/api/#query-wikidata-with-sparql","title":"Query Wikidata with SPARQL","text":"<pre><code>from gkc.sparql import SPARQLQuery\n\nexecutor = SPARQLQuery()\nresults = executor.query(\"\"\"\n    SELECT ?item ?itemLabel WHERE {\n      ?item wdt:P31 wd:Q5 .\n      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n    }\n    LIMIT 10\n\"\"\")\n</code></pre> <p>\ud83d\udcd6 SPARQL Module Documentation</p>"},{"location":"gkc/api/#authenticate-with-wikidata","title":"Authenticate with Wikidata","text":"<pre><code>from gkc.auth import WikiverseAuth\n\nauth = WikiverseAuth()\nauth.login(username=\"YourUsername\", password=\"YourPassword\")\n</code></pre> <p>\ud83d\udcd6 Authentication Documentation (coming soon)</p>"},{"location":"gkc/api/#core-modules","title":"Core Modules","text":""},{"location":"gkc/api/#mash","title":"Mash","text":"<p>Load data from Wikidata and other sources as templates for processing.</p> <p>Key classes: - <code>WikidataLoader</code> - Load Wikidata items - <code>WikidataTemplate</code> - Manipulate loaded data</p> <p>Key functions: - <code>strip_entity_identifiers()</code> - Prepare for new item creation - <code>fetch_property_labels()</code> - Get property labels</p>"},{"location":"gkc/api/#mash-formatters","title":"Mash Formatters","text":"<p>Convert templates to different output formats.</p> <p>Key classes: - <code>QSV1Formatter</code> - Format as QuickStatements V1</p>"},{"location":"gkc/api/#cooperage","title":"Cooperage","text":"<p>Fetch schemas and metadata from target systems (Barrel Schemas).</p> <p>Key functions: - <code>fetch_schema_specification()</code> - Get EntitySchema ShEx - <code>fetch_entity_schema_json()</code> - Get EntitySchema metadata - <code>fetch_entity_rdf()</code> - Get entity RDF data - <code>validate_entity_reference()</code> - Check if entity exists</p> <p>Documentation coming soon</p>"},{"location":"gkc/api/#spirit-safe","title":"Spirit Safe","text":"<p>Configure SpiritSafe source mode, discover profile registrants, resolve profile/query references, and hydrate/cache SPARQL-driven allowed-items lists.</p> <p>Key classes/functions:</p> <ul> <li><code>SpiritSafeSourceConfig</code></li> <li><code>set_spirit_safe_source()</code>, <code>get_spirit_safe_source()</code></li> <li><code>list_profiles()</code>, <code>profile_exists()</code>, <code>get_profile_metadata()</code></li> <li><code>resolve_profile_path()</code>, <code>resolve_query_ref()</code></li> <li><code>hydrate_profile_lookups()</code>, <code>LookupCache</code>, <code>LookupFetcher</code></li> </ul>"},{"location":"gkc/api/#bottler","title":"Bottler","text":"<p>Transform data into Wikidata item structure.</p> <p>Key classes: - <code>DataTypeTransformer</code> - Transform values to Wikidata format - <code>Bottler</code> - Create Wikidata items from recipes</p> <p>Documentation coming soon</p>"},{"location":"gkc/api/#shipper","title":"Shipper","text":"<p>Submit data to Wikidata via the API.</p> <p>Key classes: - <code>WikidataShipper</code> - Submit QuickStatements or JSON to Wikidata - <code>CommonsShipper</code> - Wikimedia Commons submission (planned) - <code>OpenStreetMapShipper</code> - OSM submission (planned)</p>"},{"location":"gkc/api/#utility-modules","title":"Utility Modules","text":""},{"location":"gkc/api/#authentication","title":"Authentication","text":"<p>Manage credentials for Wikidata, Wikipedia, Wikimedia Commons, and OpenStreetMap.</p> <p>Key classes: - <code>WikiverseAuth</code> - Wikidata/Wikipedia authentication - <code>OpenStreetMapAuth</code> - OSM authentication</p> <p>Documentation coming soon</p>"},{"location":"gkc/api/#sitelinks","title":"Sitelinks","text":"<p>Manage and validate Wikipedia sitelinks for Wikidata items.</p> <p>Key functions: - <code>validate_sitelink()</code> - Check if Wikipedia page exists - <code>get_sitelink_url()</code> - Build Wikipedia URL from title</p> <p>Documentation coming soon</p>"},{"location":"gkc/api/#sparql","title":"SPARQL","text":"<p>Query Wikidata and other SPARQL endpoints.</p> <p>Key classes: - <code>SPARQLQuery</code> - Execute queries and handle results</p> <p>Key functions: - <code>execute_sparql()</code> - Run raw SPARQL queries</p>"},{"location":"gkc/api/#profiles","title":"Profiles","text":"<p>YAML-first profiles for validation and form schema generation.</p> <p>Key classes: - <code>ProfileLoader</code> - Load YAML profiles - <code>ProfileValidator</code> - Validate Wikidata items - <code>FormSchemaGenerator</code> - Build form schemas</p>"},{"location":"gkc/api/#package-configuration","title":"Package Configuration","text":""},{"location":"gkc/api/#language-settings","title":"Language Settings","text":"<pre><code>import gkc\n\n# Set single language\ngkc.set_languages(\"en\")\n\n# Set multiple languages\ngkc.set_languages([\"en\", \"es\", \"fr\"])\n\n# Get current setting\nlanguages = gkc.get_languages()\n</code></pre> <p>Many modules use the package-level language configuration for filtering labels, descriptions, and other multilingual content.</p>"},{"location":"gkc/api/#see-also","title":"See Also","text":"<ul> <li>CLI Reference - Command-line interface</li> </ul>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/","title":"API Documentation Pattern Template","text":"<p>This template documents the standard pattern for creating API documentation for GKC modules. Use this as a guide when creating documentation for remaining modules.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#purpose","title":"Purpose","text":"<p>Each module should have its own API documentation page that follows this consistent structure, making it easy for users to discover functionality and understand how to use it.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#file-structure","title":"File Structure","text":"<pre><code>docs/gkc/api/\n  \u251c\u2500\u2500 index.md                 # Overview and quick reference\n  \u251c\u2500\u2500 module_name.md           # Per-module documentation\n  \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#module-documentation-pattern","title":"Module Documentation Pattern","text":"<p>Each module documentation file (<code>docs/gkc/api/module_name.md</code>) should follow this structure:</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#1-header-and-overview-required","title":"1. Header and Overview (Required)","text":"<p><pre><code># Module Name API\n\n## Overview\n\n[1-2 sentence description of what the module does]\n\n[Optional: 1-2 sentences about its role in the distillery workflow]\n\n**Current implementations:** [What's supported now]  \n**Future implementations:** [What's planned, if applicable]\n\n## Quick Start\n\n```python\n[Minimal 3-5 line example showing the most common use case]\n</code></pre> <pre><code>### 2. Core Classes/Functions (Required)\n\nUse mkdocstrings to auto-generate detailed API documentation:\n\n```markdown\n## Classes\n\n### ClassName\n\n::: gkc.module_name.ClassName\n    options:\n      show_root_heading: false\n      heading_level: 4\n\n## Functions\n\n### function_name()\n\n::: gkc.module_name.function_name\n    options:\n      show_root_heading: false\n      heading_level: 4\n</code></pre></p> <p>Note: The <code>::: gkc.module_name.ClassName</code> syntax tells mkdocstrings to extract and render the docstring from that class/function.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#3-examples-section-required","title":"3. Examples Section (Required)","text":"<p>Include 3-5 real-world examples showing common tasks:</p> <pre><code>## Examples\n\n### [Task-oriented example title]\n\n```python\n[Complete, runnable example using realistic QIDs, data, etc.]\n</code></pre>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#another-example","title":"[Another example]","text":"<p><pre><code>[Another complete example]\n</code></pre> <pre><code>**Guidelines for examples:**\n- Use real Wikidata QIDs (Q42, Q5, etc.) not placeholders\n- Show complete, copy-paste-ready code\n- Include comments explaining non-obvious steps\n- Show error handling where appropriate\n- Progress from simple to complex\n\n### 4. Error Handling (Optional but Recommended)\n\nDocument common error conditions and how to handle them:\n\n```markdown\n## Error Handling\n\n### [Error scenario]\n\n```python\n[Example showing how the error occurs and how to handle it]\n</code></pre> <pre><code>### 5. See Also Section (Required)\n\nCross-link to related documentation:\n\n```markdown\n## See Also\n\n- [Related API Module](other_module.md) - Brief description\n- [Related CLI](../cli/command.md) - Command-line interface\n- [Conceptual Guide](../concept.md) - Background information\n</code></pre></p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#complete-example","title":"Complete Example","text":"<p>See docs/gkc/api/mash.md and docs/gkc/api/mash_formatters.md for complete examples following this pattern.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#documentation-guidelines","title":"Documentation Guidelines","text":""},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#docstrings-in-code","title":"Docstrings in Code","text":"<p>Every public function/class must have a docstring following this format:</p> <pre><code>def function_name(param1: str, param2: int = 10) -&gt; dict:\n    \"\"\"One-line summary of what the function does.\n\n    Longer description if needed (2-3 sentences maximum).\n\n    Args:\n        param1: Description of param1.\n        param2: Description of param2 (default: 10).\n\n    Returns:\n        Description of return value.\n\n    Raises:\n        ExceptionType: When this error occurs.\n\n    Example:\n        &gt;&gt;&gt; result = function_name(\"Q42\")\n        &gt;&gt;&gt; print(result)\n        {'qid': 'Q42', 'label': 'Douglas Adams'}\n\n    Plain meaning: [Simple explanation in everyday language]\n    \"\"\"\n</code></pre> <p>Note: The \"Plain meaning\" section is a GKC convention to provide a non-technical explanation.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#writing-style","title":"Writing Style","text":"<ul> <li>Be concise: Keep explanations short and clear</li> <li>Be explicit: Don't assume the user knows internal details</li> <li>Use examples: Show, don't just tell</li> <li>Prefer tasks over features: \"Load a Wikidata item\" not \"WikidataLoader class\"</li> <li>Use real data: Q42, E502, etc., not foo/bar</li> <li>Link generously: Cross-reference related docs</li> </ul>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#what-to-include","title":"What to Include","text":"<p>Always include: - Overview and quick start - Auto-generated class/function docs - 3-5 real-world examples - See also links</p> <p>Include when relevant: - Error handling examples - Configuration options - Performance considerations - Limitations or caveats</p> <p>Never include: - Implementation details users don't need - Duplicate information from docstrings - Placeholder/toy examples (foo, bar, etc.)</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#updating-the-navigation","title":"Updating the Navigation","text":"<p>After creating a new module documentation file, add it to <code>mkdocs.yml</code>:</p> <pre><code>nav:\n  - GKC Documentation:\n    - API Reference:\n      - Overview: gkc/api/index.md\n      - Module Name: gkc/api/module_name.md\n      - ...\n</code></pre>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#checklist-for-new-module-documentation","title":"Checklist for New Module Documentation","text":"<ul> <li>[ ] Create <code>docs/gkc/api/module_name.md</code></li> <li>[ ] Add header with module name</li> <li>[ ] Write overview section (1-2 sentences)</li> <li>[ ] Add quick start example (3-5 lines)</li> <li>[ ] Use mkdocstrings to include class/function docs</li> <li>[ ] Write 3-5 real-world examples</li> <li>[ ] Add error handling section (if applicable)</li> <li>[ ] Add \"See also\" links</li> <li>[ ] Update <code>mkdocs.yml</code> navigation</li> <li>[ ] Update <code>docs/gkc/api/index.md</code> quick reference table</li> <li>[ ] Test that documentation builds correctly</li> <li>[ ] Verify all code examples are runnable</li> </ul>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#testing-documentation","title":"Testing Documentation","text":"<p>Build and preview locally:</p> <pre><code>mkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000/</code> to preview the site.</p>"},{"location":"gkc/api/API_DOCUMENTATION_PATTERN/#modules-still-needing-documentation","title":"Modules Still Needing Documentation","text":"<p>Based on the codebase, these modules need API documentation:</p> <ol> <li>recipe.md - Recipe builder and entity catalog</li> <li>cooperage.md - Barrel schema management</li> <li>spirit_safe.md - Validation</li> <li>bottler.md - Data transformation</li> <li>shipper.md - Wikidata submission</li> <li>auth.md - Authentication</li> <li>sitelinks.md - Wikipedia sitelinks</li> </ol> <p>Priority: Start with the most commonly used modules (recipe, auth) before less frequently used ones.</p>"},{"location":"gkc/api/auth/","title":"Authentication API","text":""},{"location":"gkc/api/auth/#overview","title":"Overview","text":"<p>The Authentication module provides unified credential management for Global Knowledge Commons services. Currently it supports Wikimedia projects (Wikidata, Wikipedia, Wikimedia Commons) using bot password authentication, with planned support for OpenStreetMap and other external services.</p> <p>Current implementations: Wikimedia projects (Wikidata production, test instance, Wikipedia, Commons); OpenStreetMap auth framework Future implementations: OpenStreetMap API authentication, additional service integrations</p>"},{"location":"gkc/api/auth/#quick-start","title":"Quick Start","text":"<pre><code>from gkc import WikiverseAuth\n\n# Authenticate to Wikidata using bot password\nauth = WikiverseAuth(\n    username=\"MyUsername@MyBot\",\n    password=\"abc123def456ghi789\"\n)\nauth.login()\nprint(f\"Logged in as: {auth.get_account_name()}\")\n</code></pre>"},{"location":"gkc/api/auth/#classes","title":"Classes","text":""},{"location":"gkc/api/auth/#authenticationerror","title":"AuthenticationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when authentication fails.</p> Source code in <code>gkc/auth.py</code> <pre><code>class AuthenticationError(Exception):\n    \"\"\"Raised when authentication fails.\"\"\"\n\n    pass\n</code></pre>"},{"location":"gkc/api/auth/#authbase","title":"AuthBase","text":"<p>Base class for authentication.</p> Source code in <code>gkc/auth.py</code> <pre><code>class AuthBase:\n    \"\"\"Base class for authentication.\"\"\"\n\n    def __init__(self, username: Optional[str] = None, password: Optional[str] = None):\n        \"\"\"\n        Initialize authentication.\n\n        Args:\n            username: Username for authentication. If not provided, will try to\n                     read from environment variable.\n            password: Password for authentication. If not provided, will try to\n                     read from environment variable.\n        \"\"\"\n        self.username = username\n        self.password = password\n\n    def is_authenticated(self) -&gt; bool:\n        \"\"\"Check if credentials are available.\"\"\"\n        return bool(self.username and self.password)\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.AuthBase.__init__","title":"<code>__init__(username=None, password=None)</code>","text":"<p>Initialize authentication.</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>Optional[str]</code> <p>Username for authentication. If not provided, will try to      read from environment variable.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>Password for authentication. If not provided, will try to      read from environment variable.</p> <code>None</code> Source code in <code>gkc/auth.py</code> <pre><code>def __init__(self, username: Optional[str] = None, password: Optional[str] = None):\n    \"\"\"\n    Initialize authentication.\n\n    Args:\n        username: Username for authentication. If not provided, will try to\n                 read from environment variable.\n        password: Password for authentication. If not provided, will try to\n                 read from environment variable.\n    \"\"\"\n    self.username = username\n    self.password = password\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.AuthBase.is_authenticated","title":"<code>is_authenticated()</code>","text":"<p>Check if credentials are available.</p> Source code in <code>gkc/auth.py</code> <pre><code>def is_authenticated(self) -&gt; bool:\n    \"\"\"Check if credentials are available.\"\"\"\n    return bool(self.username and self.password)\n</code></pre>"},{"location":"gkc/api/auth/#wikiverseauth","title":"WikiverseAuth","text":"<p>               Bases: <code>AuthBase</code></p> <p>Authentication for Wikimedia projects (Wikidata, Wikipedia, Wikimedia Commons).</p> <p>Designed for bot accounts using bot passwords. The same credentials work across all Wikimedia projects due to Single User Login (SUL).</p> <p>Supports both default Wikimedia instances and custom MediaWiki installations.</p> <p>Credentials can be provided in three ways (in order of precedence): 1. Direct parameters 2. Environment variables (WIKIVERSE_USERNAME, WIKIVERSE_PASSWORD, WIKIVERSE_API_URL) 3. Interactive prompt</p> Example Source code in <code>gkc/auth.py</code> <pre><code>class WikiverseAuth(AuthBase):\n    \"\"\"\n    Authentication for Wikimedia projects (Wikidata, Wikipedia, Wikimedia Commons).\n\n    Designed for bot accounts using bot passwords. The same credentials work\n    across all Wikimedia projects due to Single User Login (SUL).\n\n    Supports both default Wikimedia instances and custom MediaWiki installations.\n\n    Credentials can be provided in three ways (in order of precedence):\n    1. Direct parameters\n    2. Environment variables (WIKIVERSE_USERNAME, WIKIVERSE_PASSWORD, WIKIVERSE_API_URL)\n    3. Interactive prompt\n\n    Example:\n        &gt;&gt;&gt; # Authenticate to Wikidata (default)\n        &gt;&gt;&gt; auth = WikiverseAuth()\n        &gt;&gt;&gt; auth.login()\n\n        &gt;&gt;&gt; # Direct parameters (bot password format)\n        &gt;&gt;&gt; auth = WikiverseAuth(\n        ...     username=\"MyUsername@MyBot\",\n        ...     password=\"abc123def456ghi789\",\n        ...     api_url=\"https://www.wikidata.org/w/api.php\"\n        ... )\n        &gt;&gt;&gt; auth.login()\n\n        &gt;&gt;&gt; # Custom MediaWiki instance\n        &gt;&gt;&gt; auth = WikiverseAuth(\n        ...     username=\"MyUsername@MyBot\",\n        ...     password=\"abc123def456ghi789\",\n        ...     api_url=\"https://my-wiki.example.com/w/api.php\"\n        ... )\n        &gt;&gt;&gt; auth.login()\n\n        &gt;&gt;&gt; # IMPORTANT: Use auth.session for API requests to maintain authentication\n        &gt;&gt;&gt; token = auth.get_csrf_token()\n        &gt;&gt;&gt; response = auth.session.post(auth.api_url, data={\n        ...     \"action\": \"edit\",\n        ...     \"title\": \"Test\",\n        ...     \"text\": \"content\",\n        ...     \"token\": token,\n        ...     \"format\": \"json\"\n        ... })\n    \"\"\"\n\n    def __init__(\n        self,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        api_url: Optional[str] = None,\n        interactive: bool = False,\n    ):\n        \"\"\"\n        Initialize Wikiverse authentication for bot accounts.\n\n        Args:\n            username: Bot password username in format \"Username@BotName\".\n                If not provided, reads from WIKIVERSE_USERNAME\n                environment variable.\n            password: Bot password. If not provided, reads from\n                WIKIVERSE_PASSWORD environment variable.\n            api_url: MediaWiki API endpoint URL. If not provided, reads from\n                    WIKIVERSE_API_URL environment variable, or defaults to Wikidata.\n                    Can also use shortcuts: \"wikidata\", \"wikipedia\", \"commons\"\n            interactive: If True and credentials are not found, prompt user for input.\n        \"\"\"\n        # Try provided parameters first\n        username = username or os.environ.get(\"WIKIVERSE_USERNAME\")\n        password = password or os.environ.get(\"WIKIVERSE_PASSWORD\")\n        api_url = api_url or os.environ.get(\"WIKIVERSE_API_URL\")\n\n        # If credentials still not available and interactive mode is requested\n        if interactive and not (username and password):\n            print(\"Bot password credentials not found in environment.\")\n            username = input(\n                \"Enter Wikiverse username (format: Username@BotName): \"\n            ).strip()\n            password = getpass.getpass(\"Enter Wikiverse password: \").strip()\n            if not api_url:\n                api_url_input = input(\n                    \"Enter API URL (or 'wikidata', 'wikipedia', 'commons') \"\n                    \"[default: wikidata]: \"\n                ).strip()\n                api_url = api_url_input if api_url_input else \"wikidata\"\n\n        super().__init__(username, password)\n\n        # Resolve API URL shortcuts to full URLs\n        if api_url and api_url.lower() in DEFAULT_WIKIMEDIA_APIS:\n            self.api_url = DEFAULT_WIKIMEDIA_APIS[api_url.lower()]\n        elif api_url:\n            self.api_url = api_url\n        else:\n            # Default to Wikidata\n            self.api_url = DEFAULT_WIKIMEDIA_APIS[\"wikidata\"]\n\n        # Initialize session for authenticated requests\n        self.session = requests.Session()\n        self.session.headers.update(\n            {\"User-Agent\": \"GKC-Python-Client/0.1 (https://github.com/skybristol/gkc)\"}\n        )\n        self._logged_in = False\n\n    def login(self) -&gt; bool:\n        \"\"\"\n        Perform login to MediaWiki API using bot password credentials.\n\n        Returns:\n            True if login successful, False otherwise.\n\n        Raises:\n            AuthenticationError: If login fails with detailed error message.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n            &gt;&gt;&gt; if auth.login():\n            ...     print(\"Successfully logged in!\")\n        \"\"\"\n        if not self.is_authenticated():\n            raise AuthenticationError(\n                \"Cannot login: credentials not provided. \"\n                \"Please provide username and password.\"\n            )\n\n        try:\n            # Step 1: Get login token\n            token_params = {\n                \"action\": \"query\",\n                \"meta\": \"tokens\",\n                \"type\": \"login\",\n                \"format\": \"json\",\n            }\n            token_response = self.session.get(self.api_url, params=token_params)\n            token_response.raise_for_status()\n            token_data = token_response.json()\n\n            if \"query\" not in token_data or \"tokens\" not in token_data[\"query\"]:\n                raise AuthenticationError(\n                    f\"Failed to get login token from {self.api_url}. \"\n                    f\"Response: {token_data}\"\n                )\n\n            login_token = token_data[\"query\"][\"tokens\"][\"logintoken\"]\n\n            # Step 2: Perform login with credentials and token\n            login_params = {\n                \"action\": \"login\",\n                \"lgname\": self.username,\n                \"lgpassword\": self.password,\n                \"lgtoken\": login_token,\n                \"format\": \"json\",\n            }\n            login_response = self.session.post(self.api_url, data=login_params)\n            login_response.raise_for_status()\n            login_data = login_response.json()\n\n            # Check login result\n            if \"login\" not in login_data:\n                raise AuthenticationError(\n                    f\"Unexpected login response from {self.api_url}. \"\n                    f\"Response: {login_data}\"\n                )\n\n            result = login_data[\"login\"][\"result\"]\n\n            if result == \"Success\":\n                self._logged_in = True\n                # Verify we have session cookies\n                if not self.session.cookies:\n                    raise AuthenticationError(\n                        \"Login reported success but no session cookies were set. \"\n                        \"This may indicate a network or API configuration issue.\"\n                    )\n                return True\n            else:\n                # Provide detailed error message\n                reason = login_data[\"login\"].get(\"reason\", \"Unknown reason\")\n                raise AuthenticationError(\n                    f\"Login failed with result '{result}'. Reason: {reason}. \"\n                    f\"Check your bot password credentials and permissions.\"\n                )\n\n        except requests.RequestException as e:\n            raise AuthenticationError(\n                f\"Network error during login to {self.api_url}: {str(e)}\"\n            )\n\n    def is_logged_in(self) -&gt; bool:\n        \"\"\"\n        Check if currently logged in to MediaWiki API.\n\n        Returns:\n            True if logged in, False otherwise.\n        \"\"\"\n        return self._logged_in\n\n    def logout(self) -&gt; None:\n        \"\"\"\n        Logout from MediaWiki API and clear session.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n            &gt;&gt;&gt; auth.login()\n            &gt;&gt;&gt; # ... do some work ...\n            &gt;&gt;&gt; auth.logout()\n        \"\"\"\n        if self._logged_in:\n            try:\n                # Get CSRF token for logout\n                token_params = {\n                    \"action\": \"query\",\n                    \"meta\": \"tokens\",\n                    \"type\": \"csrf\",\n                    \"format\": \"json\",\n                }\n                token_response = self.session.get(self.api_url, params=token_params)\n                token_data = token_response.json()\n                csrf_token = token_data[\"query\"][\"tokens\"][\"csrftoken\"]\n\n                # Perform logout\n                logout_params = {\n                    \"action\": \"logout\",\n                    \"token\": csrf_token,\n                    \"format\": \"json\",\n                }\n                self.session.post(self.api_url, data=logout_params)\n            except Exception:\n                # Ignore logout errors, just clear session\n                pass\n            finally:\n                self._logged_in = False\n                self.session.cookies.clear()\n\n    def get_csrf_token(self) -&gt; str:\n        \"\"\"\n        Get a CSRF token for making edits.\n\n        IMPORTANT: The token must be used with auth.session for requests.\n        The token alone is not sufficient - you need the authenticated session cookies.\n\n        Returns:\n            CSRF token string.\n\n        Raises:\n            AuthenticationError: If not logged in or token retrieval fails.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n            &gt;&gt;&gt; auth.login()\n            &gt;&gt;&gt; token = auth.get_csrf_token()\n            &gt;&gt;&gt; # Use token with auth.session (not a new requests call)\n            &gt;&gt;&gt; response = auth.session.post(auth.api_url, data={\n            ...     \"action\": \"edit\",\n            ...     \"title\": \"Page\",\n            ...     \"text\": \"content\",\n            ...     \"token\": token,\n            ...     \"format\": \"json\"\n            ... })\n        \"\"\"\n        if not self.is_logged_in():\n            raise AuthenticationError(\n                \"Not logged in. Call login() first before getting CSRF token.\"\n            )\n\n        try:\n            token_params = {\n                \"action\": \"query\",\n                \"meta\": \"tokens\",\n                \"type\": \"csrf\",\n                \"format\": \"json\",\n            }\n            # Use POST to ensure cookies are properly handled\n            response = self.session.post(self.api_url, data=token_params)\n            response.raise_for_status()\n            data = response.json()\n\n            if \"query\" in data and \"tokens\" in data[\"query\"]:\n                csrf_token: str = data[\"query\"][\"tokens\"][\"csrftoken\"]\n                return csrf_token\n            else:\n                raise AuthenticationError(f\"Failed to get CSRF token. Response: {data}\")\n\n        except requests.RequestException as e:\n            raise AuthenticationError(f\"Network error getting CSRF token: {str(e)}\")\n\n    def __repr__(self) -&gt; str:\n        status = (\n            \"logged in\"\n            if self._logged_in\n            else (\"authenticated\" if self.is_authenticated() else \"not authenticated\")\n        )\n        return (\n            f\"WikiverseAuth(username={self.username!r}, \"\n            f\"api_url={self.api_url!r}, {status})\"\n        )\n\n    def get_bot_name(self) -&gt; Optional[str]:\n        \"\"\"\n        Extract bot name from username.\n\n        Returns:\n            Bot name if username is in bot password format, None otherwise.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"Alice@MyBot\")\n            &gt;&gt;&gt; auth.get_bot_name()\n            'MyBot'\n        \"\"\"\n        if self.username and \"@\" in self.username:\n            return self.username.split(\"@\", 1)[1]\n        return None\n\n    def get_account_name(self) -&gt; Optional[str]:\n        \"\"\"\n        Extract account name from username.\n\n        Returns:\n            Account name if username is in bot password format, None otherwise.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"Alice@MyBot\")\n            &gt;&gt;&gt; auth.get_account_name()\n            'Alice'\n        \"\"\"\n        if self.username and \"@\" in self.username:\n            return self.username.split(\"@\", 1)[0]\n        return None\n\n    def test_authentication(self) -&gt; dict:\n        \"\"\"\n        Test authentication and return diagnostic information.\n\n        Returns:\n            Dictionary with authentication status, session details, and token info.\n\n        Example:\n            &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n            &gt;&gt;&gt; auth.login()\n            &gt;&gt;&gt; info = auth.test_authentication()\n            &gt;&gt;&gt; print(info)\n        \"\"\"\n        info = {\n            \"credentials_provided\": self.is_authenticated(),\n            \"logged_in\": self.is_logged_in(),\n            \"api_url\": self.api_url,\n            \"username\": self.username,\n            \"bot_name\": self.get_bot_name(),\n            \"session_cookies\": list(self.session.cookies.keys()),\n            \"csrf_token_retrieved\": False,\n            \"csrf_token_preview\": None,\n            \"error\": None,\n        }\n\n        if self.is_logged_in():\n            try:\n                token = self.get_csrf_token()\n                info[\"csrf_token_retrieved\"] = True\n                preview = token[:20] + \"...\" if len(token) &gt; 20 else token\n                info[\"csrf_token_preview\"] = preview\n            except Exception as e:\n                info[\"error\"] = str(e)\n\n        return info\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth--authenticate-to-wikidata-default","title":"Authenticate to Wikidata (default)","text":"<p>auth = WikiverseAuth() auth.login()</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth--direct-parameters-bot-password-format","title":"Direct parameters (bot password format)","text":"<p>auth = WikiverseAuth( ...     username=\"MyUsername@MyBot\", ...     password=\"abc123def456ghi789\", ...     api_url=\"https://www.wikidata.org/w/api.php\" ... ) auth.login()</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth--custom-mediawiki-instance","title":"Custom MediaWiki instance","text":"<p>auth = WikiverseAuth( ...     username=\"MyUsername@MyBot\", ...     password=\"abc123def456ghi789\", ...     api_url=\"https://my-wiki.example.com/w/api.php\" ... ) auth.login()</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth--important-use-authsession-for-api-requests-to-maintain-authentication","title":"IMPORTANT: Use auth.session for API requests to maintain authentication","text":"<p>token = auth.get_csrf_token() response = auth.session.post(auth.api_url, data={ ...     \"action\": \"edit\", ...     \"title\": \"Test\", ...     \"text\": \"content\", ...     \"token\": token, ...     \"format\": \"json\" ... })</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.__init__","title":"<code>__init__(username=None, password=None, api_url=None, interactive=False)</code>","text":"<p>Initialize Wikiverse authentication for bot accounts.</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>Optional[str]</code> <p>Bot password username in format \"Username@BotName\". If not provided, reads from WIKIVERSE_USERNAME environment variable.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>Bot password. If not provided, reads from WIKIVERSE_PASSWORD environment variable.</p> <code>None</code> <code>api_url</code> <code>Optional[str]</code> <p>MediaWiki API endpoint URL. If not provided, reads from     WIKIVERSE_API_URL environment variable, or defaults to Wikidata.     Can also use shortcuts: \"wikidata\", \"wikipedia\", \"commons\"</p> <code>None</code> <code>interactive</code> <code>bool</code> <p>If True and credentials are not found, prompt user for input.</p> <code>False</code> Source code in <code>gkc/auth.py</code> <pre><code>def __init__(\n    self,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    api_url: Optional[str] = None,\n    interactive: bool = False,\n):\n    \"\"\"\n    Initialize Wikiverse authentication for bot accounts.\n\n    Args:\n        username: Bot password username in format \"Username@BotName\".\n            If not provided, reads from WIKIVERSE_USERNAME\n            environment variable.\n        password: Bot password. If not provided, reads from\n            WIKIVERSE_PASSWORD environment variable.\n        api_url: MediaWiki API endpoint URL. If not provided, reads from\n                WIKIVERSE_API_URL environment variable, or defaults to Wikidata.\n                Can also use shortcuts: \"wikidata\", \"wikipedia\", \"commons\"\n        interactive: If True and credentials are not found, prompt user for input.\n    \"\"\"\n    # Try provided parameters first\n    username = username or os.environ.get(\"WIKIVERSE_USERNAME\")\n    password = password or os.environ.get(\"WIKIVERSE_PASSWORD\")\n    api_url = api_url or os.environ.get(\"WIKIVERSE_API_URL\")\n\n    # If credentials still not available and interactive mode is requested\n    if interactive and not (username and password):\n        print(\"Bot password credentials not found in environment.\")\n        username = input(\n            \"Enter Wikiverse username (format: Username@BotName): \"\n        ).strip()\n        password = getpass.getpass(\"Enter Wikiverse password: \").strip()\n        if not api_url:\n            api_url_input = input(\n                \"Enter API URL (or 'wikidata', 'wikipedia', 'commons') \"\n                \"[default: wikidata]: \"\n            ).strip()\n            api_url = api_url_input if api_url_input else \"wikidata\"\n\n    super().__init__(username, password)\n\n    # Resolve API URL shortcuts to full URLs\n    if api_url and api_url.lower() in DEFAULT_WIKIMEDIA_APIS:\n        self.api_url = DEFAULT_WIKIMEDIA_APIS[api_url.lower()]\n    elif api_url:\n        self.api_url = api_url\n    else:\n        # Default to Wikidata\n        self.api_url = DEFAULT_WIKIMEDIA_APIS[\"wikidata\"]\n\n    # Initialize session for authenticated requests\n    self.session = requests.Session()\n    self.session.headers.update(\n        {\"User-Agent\": \"GKC-Python-Client/0.1 (https://github.com/skybristol/gkc)\"}\n    )\n    self._logged_in = False\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.get_account_name","title":"<code>get_account_name()</code>","text":"<p>Extract account name from username.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Account name if username is in bot password format, None otherwise.</p> Example <p>auth = WikiverseAuth(username=\"Alice@MyBot\") auth.get_account_name() 'Alice'</p> Source code in <code>gkc/auth.py</code> <pre><code>def get_account_name(self) -&gt; Optional[str]:\n    \"\"\"\n    Extract account name from username.\n\n    Returns:\n        Account name if username is in bot password format, None otherwise.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"Alice@MyBot\")\n        &gt;&gt;&gt; auth.get_account_name()\n        'Alice'\n    \"\"\"\n    if self.username and \"@\" in self.username:\n        return self.username.split(\"@\", 1)[0]\n    return None\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.get_bot_name","title":"<code>get_bot_name()</code>","text":"<p>Extract bot name from username.</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>Bot name if username is in bot password format, None otherwise.</p> Example <p>auth = WikiverseAuth(username=\"Alice@MyBot\") auth.get_bot_name() 'MyBot'</p> Source code in <code>gkc/auth.py</code> <pre><code>def get_bot_name(self) -&gt; Optional[str]:\n    \"\"\"\n    Extract bot name from username.\n\n    Returns:\n        Bot name if username is in bot password format, None otherwise.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"Alice@MyBot\")\n        &gt;&gt;&gt; auth.get_bot_name()\n        'MyBot'\n    \"\"\"\n    if self.username and \"@\" in self.username:\n        return self.username.split(\"@\", 1)[1]\n    return None\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.get_csrf_token","title":"<code>get_csrf_token()</code>","text":"<p>Get a CSRF token for making edits.</p> <p>IMPORTANT: The token must be used with auth.session for requests. The token alone is not sufficient - you need the authenticated session cookies.</p> <p>Returns:</p> Type Description <code>str</code> <p>CSRF token string.</p> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If not logged in or token retrieval fails.</p> Example <p>auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\") auth.login() token = auth.get_csrf_token()</p> Source code in <code>gkc/auth.py</code> <pre><code>def get_csrf_token(self) -&gt; str:\n    \"\"\"\n    Get a CSRF token for making edits.\n\n    IMPORTANT: The token must be used with auth.session for requests.\n    The token alone is not sufficient - you need the authenticated session cookies.\n\n    Returns:\n        CSRF token string.\n\n    Raises:\n        AuthenticationError: If not logged in or token retrieval fails.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n        &gt;&gt;&gt; auth.login()\n        &gt;&gt;&gt; token = auth.get_csrf_token()\n        &gt;&gt;&gt; # Use token with auth.session (not a new requests call)\n        &gt;&gt;&gt; response = auth.session.post(auth.api_url, data={\n        ...     \"action\": \"edit\",\n        ...     \"title\": \"Page\",\n        ...     \"text\": \"content\",\n        ...     \"token\": token,\n        ...     \"format\": \"json\"\n        ... })\n    \"\"\"\n    if not self.is_logged_in():\n        raise AuthenticationError(\n            \"Not logged in. Call login() first before getting CSRF token.\"\n        )\n\n    try:\n        token_params = {\n            \"action\": \"query\",\n            \"meta\": \"tokens\",\n            \"type\": \"csrf\",\n            \"format\": \"json\",\n        }\n        # Use POST to ensure cookies are properly handled\n        response = self.session.post(self.api_url, data=token_params)\n        response.raise_for_status()\n        data = response.json()\n\n        if \"query\" in data and \"tokens\" in data[\"query\"]:\n            csrf_token: str = data[\"query\"][\"tokens\"][\"csrftoken\"]\n            return csrf_token\n        else:\n            raise AuthenticationError(f\"Failed to get CSRF token. Response: {data}\")\n\n    except requests.RequestException as e:\n        raise AuthenticationError(f\"Network error getting CSRF token: {str(e)}\")\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.get_csrf_token--use-token-with-authsession-not-a-new-requests-call","title":"Use token with auth.session (not a new requests call)","text":"<p>response = auth.session.post(auth.api_url, data={ ...     \"action\": \"edit\", ...     \"title\": \"Page\", ...     \"text\": \"content\", ...     \"token\": token, ...     \"format\": \"json\" ... })</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.is_logged_in","title":"<code>is_logged_in()</code>","text":"<p>Check if currently logged in to MediaWiki API.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if logged in, False otherwise.</p> Source code in <code>gkc/auth.py</code> <pre><code>def is_logged_in(self) -&gt; bool:\n    \"\"\"\n    Check if currently logged in to MediaWiki API.\n\n    Returns:\n        True if logged in, False otherwise.\n    \"\"\"\n    return self._logged_in\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.login","title":"<code>login()</code>","text":"<p>Perform login to MediaWiki API using bot password credentials.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if login successful, False otherwise.</p> <p>Raises:</p> Type Description <code>AuthenticationError</code> <p>If login fails with detailed error message.</p> Example <p>auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\") if auth.login(): ...     print(\"Successfully logged in!\")</p> Source code in <code>gkc/auth.py</code> <pre><code>def login(self) -&gt; bool:\n    \"\"\"\n    Perform login to MediaWiki API using bot password credentials.\n\n    Returns:\n        True if login successful, False otherwise.\n\n    Raises:\n        AuthenticationError: If login fails with detailed error message.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n        &gt;&gt;&gt; if auth.login():\n        ...     print(\"Successfully logged in!\")\n    \"\"\"\n    if not self.is_authenticated():\n        raise AuthenticationError(\n            \"Cannot login: credentials not provided. \"\n            \"Please provide username and password.\"\n        )\n\n    try:\n        # Step 1: Get login token\n        token_params = {\n            \"action\": \"query\",\n            \"meta\": \"tokens\",\n            \"type\": \"login\",\n            \"format\": \"json\",\n        }\n        token_response = self.session.get(self.api_url, params=token_params)\n        token_response.raise_for_status()\n        token_data = token_response.json()\n\n        if \"query\" not in token_data or \"tokens\" not in token_data[\"query\"]:\n            raise AuthenticationError(\n                f\"Failed to get login token from {self.api_url}. \"\n                f\"Response: {token_data}\"\n            )\n\n        login_token = token_data[\"query\"][\"tokens\"][\"logintoken\"]\n\n        # Step 2: Perform login with credentials and token\n        login_params = {\n            \"action\": \"login\",\n            \"lgname\": self.username,\n            \"lgpassword\": self.password,\n            \"lgtoken\": login_token,\n            \"format\": \"json\",\n        }\n        login_response = self.session.post(self.api_url, data=login_params)\n        login_response.raise_for_status()\n        login_data = login_response.json()\n\n        # Check login result\n        if \"login\" not in login_data:\n            raise AuthenticationError(\n                f\"Unexpected login response from {self.api_url}. \"\n                f\"Response: {login_data}\"\n            )\n\n        result = login_data[\"login\"][\"result\"]\n\n        if result == \"Success\":\n            self._logged_in = True\n            # Verify we have session cookies\n            if not self.session.cookies:\n                raise AuthenticationError(\n                    \"Login reported success but no session cookies were set. \"\n                    \"This may indicate a network or API configuration issue.\"\n                )\n            return True\n        else:\n            # Provide detailed error message\n            reason = login_data[\"login\"].get(\"reason\", \"Unknown reason\")\n            raise AuthenticationError(\n                f\"Login failed with result '{result}'. Reason: {reason}. \"\n                f\"Check your bot password credentials and permissions.\"\n            )\n\n    except requests.RequestException as e:\n        raise AuthenticationError(\n            f\"Network error during login to {self.api_url}: {str(e)}\"\n        )\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.logout","title":"<code>logout()</code>","text":"<p>Logout from MediaWiki API and clear session.</p> Example <p>auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\") auth.login()</p> Source code in <code>gkc/auth.py</code> <pre><code>def logout(self) -&gt; None:\n    \"\"\"\n    Logout from MediaWiki API and clear session.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n        &gt;&gt;&gt; auth.login()\n        &gt;&gt;&gt; # ... do some work ...\n        &gt;&gt;&gt; auth.logout()\n    \"\"\"\n    if self._logged_in:\n        try:\n            # Get CSRF token for logout\n            token_params = {\n                \"action\": \"query\",\n                \"meta\": \"tokens\",\n                \"type\": \"csrf\",\n                \"format\": \"json\",\n            }\n            token_response = self.session.get(self.api_url, params=token_params)\n            token_data = token_response.json()\n            csrf_token = token_data[\"query\"][\"tokens\"][\"csrftoken\"]\n\n            # Perform logout\n            logout_params = {\n                \"action\": \"logout\",\n                \"token\": csrf_token,\n                \"format\": \"json\",\n            }\n            self.session.post(self.api_url, data=logout_params)\n        except Exception:\n            # Ignore logout errors, just clear session\n            pass\n        finally:\n            self._logged_in = False\n            self.session.cookies.clear()\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.logout--do-some-work","title":"... do some work ...","text":"<p>auth.logout()</p>"},{"location":"gkc/api/auth/#gkc.auth.WikiverseAuth.test_authentication","title":"<code>test_authentication()</code>","text":"<p>Test authentication and return diagnostic information.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary with authentication status, session details, and token info.</p> Example <p>auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\") auth.login() info = auth.test_authentication() print(info)</p> Source code in <code>gkc/auth.py</code> <pre><code>def test_authentication(self) -&gt; dict:\n    \"\"\"\n    Test authentication and return diagnostic information.\n\n    Returns:\n        Dictionary with authentication status, session details, and token info.\n\n    Example:\n        &gt;&gt;&gt; auth = WikiverseAuth(username=\"User@Bot\", password=\"secret\")\n        &gt;&gt;&gt; auth.login()\n        &gt;&gt;&gt; info = auth.test_authentication()\n        &gt;&gt;&gt; print(info)\n    \"\"\"\n    info = {\n        \"credentials_provided\": self.is_authenticated(),\n        \"logged_in\": self.is_logged_in(),\n        \"api_url\": self.api_url,\n        \"username\": self.username,\n        \"bot_name\": self.get_bot_name(),\n        \"session_cookies\": list(self.session.cookies.keys()),\n        \"csrf_token_retrieved\": False,\n        \"csrf_token_preview\": None,\n        \"error\": None,\n    }\n\n    if self.is_logged_in():\n        try:\n            token = self.get_csrf_token()\n            info[\"csrf_token_retrieved\"] = True\n            preview = token[:20] + \"...\" if len(token) &gt; 20 else token\n            info[\"csrf_token_preview\"] = preview\n        except Exception as e:\n            info[\"error\"] = str(e)\n\n    return info\n</code></pre>"},{"location":"gkc/api/auth/#openstreetmapauth","title":"OpenStreetMapAuth","text":"<p>               Bases: <code>AuthBase</code></p> <p>Authentication for OpenStreetMap.</p> <p>Credentials can be provided in three ways (in order of precedence): 1. Direct parameters 2. Environment variables (OPENSTREETMAP_USERNAME, OPENSTREETMAP_PASSWORD) 3. Interactive prompt</p> Example Source code in <code>gkc/auth.py</code> <pre><code>class OpenStreetMapAuth(AuthBase):\n    \"\"\"\n    Authentication for OpenStreetMap.\n\n    Credentials can be provided in three ways (in order of precedence):\n    1. Direct parameters\n    2. Environment variables (OPENSTREETMAP_USERNAME, OPENSTREETMAP_PASSWORD)\n    3. Interactive prompt\n\n    Example:\n        &gt;&gt;&gt; # Using environment variables\n        &gt;&gt;&gt; auth = OpenStreetMapAuth()\n\n        &gt;&gt;&gt; # Direct parameters\n        &gt;&gt;&gt; auth = OpenStreetMapAuth(username=\"myuser\", password=\"mypass\")\n\n        &gt;&gt;&gt; # Interactive prompt\n        &gt;&gt;&gt; auth = OpenStreetMapAuth(interactive=True)\n        Enter OpenStreetMap username: myuser\n        Enter OpenStreetMap password: ****\n    \"\"\"\n\n    def __init__(\n        self,\n        username: Optional[str] = None,\n        password: Optional[str] = None,\n        interactive: bool = False,\n    ):\n        \"\"\"\n        Initialize OpenStreetMap authentication.\n\n        Args:\n            username: OpenStreetMap username. If not provided, reads from\n                     OPENSTREETMAP_USERNAME environment variable.\n            password: OpenStreetMap password. If not provided, reads from\n                     OPENSTREETMAP_PASSWORD environment variable.\n            interactive: If True and credentials are not found, prompt user for input.\n        \"\"\"\n        # Try provided parameters first\n        username = username or os.environ.get(\"OPENSTREETMAP_USERNAME\")\n        password = password or os.environ.get(\"OPENSTREETMAP_PASSWORD\")\n\n        # If credentials still not available and interactive mode is requested\n        if interactive and not (username and password):\n            print(\"OpenStreetMap credentials not found in environment.\")\n            username = input(\"Enter OpenStreetMap username: \").strip()\n            password = getpass.getpass(\"Enter OpenStreetMap password: \").strip()\n\n        super().__init__(username, password)\n\n    def __repr__(self) -&gt; str:\n        status = \"authenticated\" if self.is_authenticated() else \"not authenticated\"\n        return f\"OpenStreetMapAuth(username={self.username!r}, {status})\"\n</code></pre>"},{"location":"gkc/api/auth/#gkc.auth.OpenStreetMapAuth--using-environment-variables","title":"Using environment variables","text":"<p>auth = OpenStreetMapAuth()</p>"},{"location":"gkc/api/auth/#gkc.auth.OpenStreetMapAuth--direct-parameters","title":"Direct parameters","text":"<p>auth = OpenStreetMapAuth(username=\"myuser\", password=\"mypass\")</p>"},{"location":"gkc/api/auth/#gkc.auth.OpenStreetMapAuth--interactive-prompt","title":"Interactive prompt","text":"<p>auth = OpenStreetMapAuth(interactive=True) Enter OpenStreetMap username: myuser Enter OpenStreetMap password: ****</p>"},{"location":"gkc/api/auth/#gkc.auth.OpenStreetMapAuth.__init__","title":"<code>__init__(username=None, password=None, interactive=False)</code>","text":"<p>Initialize OpenStreetMap authentication.</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>Optional[str]</code> <p>OpenStreetMap username. If not provided, reads from      OPENSTREETMAP_USERNAME environment variable.</p> <code>None</code> <code>password</code> <code>Optional[str]</code> <p>OpenStreetMap password. If not provided, reads from      OPENSTREETMAP_PASSWORD environment variable.</p> <code>None</code> <code>interactive</code> <code>bool</code> <p>If True and credentials are not found, prompt user for input.</p> <code>False</code> Source code in <code>gkc/auth.py</code> <pre><code>def __init__(\n    self,\n    username: Optional[str] = None,\n    password: Optional[str] = None,\n    interactive: bool = False,\n):\n    \"\"\"\n    Initialize OpenStreetMap authentication.\n\n    Args:\n        username: OpenStreetMap username. If not provided, reads from\n                 OPENSTREETMAP_USERNAME environment variable.\n        password: OpenStreetMap password. If not provided, reads from\n                 OPENSTREETMAP_PASSWORD environment variable.\n        interactive: If True and credentials are not found, prompt user for input.\n    \"\"\"\n    # Try provided parameters first\n    username = username or os.environ.get(\"OPENSTREETMAP_USERNAME\")\n    password = password or os.environ.get(\"OPENSTREETMAP_PASSWORD\")\n\n    # If credentials still not available and interactive mode is requested\n    if interactive and not (username and password):\n        print(\"OpenStreetMap credentials not found in environment.\")\n        username = input(\"Enter OpenStreetMap username: \").strip()\n        password = getpass.getpass(\"Enter OpenStreetMap password: \").strip()\n\n    super().__init__(username, password)\n</code></pre>"},{"location":"gkc/api/auth/#examples","title":"Examples","text":""},{"location":"gkc/api/auth/#authenticate-to-wikidata-using-environment-variables","title":"Authenticate to Wikidata using environment variables","text":"<p>This is the recommended approach for production workflows and CI/CD environments:</p> <pre><code>from gkc import WikiverseAuth\n\n# Set environment variables first:\n# export WIKIVERSE_USERNAME=\"MyUsername@MyBot\"\n# export WIKIVERSE_PASSWORD=\"abc123def456ghi789\"\n\nauth = WikiverseAuth()\nauth.login()\nprint(f\"Successfully logged in to: {auth.api_url}\")\n</code></pre>"},{"location":"gkc/api/auth/#authenticate-to-testwikidataorg-for-testing","title":"Authenticate to test.wikidata.org for testing","text":"<p>Use the new <code>wikidata_test</code> endpoint for development and testing:</p> <pre><code>from gkc import WikiverseAuth\n\nauth = WikiverseAuth(\n    username=\"TestBot@BotAccount\",\n    password=\"test_password_123\",\n    api_url=\"wikidata_test\"  # Points to test.wikidata.org/w/api.php\n)\n\nif auth.login():\n    token = auth.get_csrf_token()\n    # Use token for test edits\n    print(f\"Got CSRF token for test edits\")\n</code></pre>"},{"location":"gkc/api/auth/#switch-between-wikimedia-projects","title":"Switch between Wikimedia projects","text":"<p>The same bot password credentials work across all Wikimedia projects thanks to Single User Login (SUL):</p> <pre><code>from gkc import WikiverseAuth\n\n# Create auth once with default Wikidata endpoint\nauth = WikiverseAuth(\n    username=\"MyUsername@MyBot\",\n    password=\"abc123def456ghi789\"\n)\nauth.login()\n\n# Later, query Wikipedia instead\nauth.api_url = \"https://en.wikipedia.org/w/api.php\"\n# The session is already authenticated for all Wikimedia projects\n\n# Or use shortcuts for common projects\nfrom gkc.auth import DEFAULT_WIKIMEDIA_APIS\nauth.api_url = DEFAULT_WIKIMEDIA_APIS[\"commons\"]  # Wikimedia Commons\n</code></pre>"},{"location":"gkc/api/auth/#use-authentication-session-for-api-requests","title":"Use authentication session for API requests","text":"<p>The authenticated session can be used directly for making API calls:</p> <pre><code>from gkc import WikiverseAuth\n\nauth = WikiverseAuth(\n    username=\"MyUsername@MyBot\",\n    password=\"abc123def456ghi789\",\n    api_url=\"wikidata\"\n)\nauth.login()\n\n# Use the authenticated session for queries\nresponse = auth.session.get(auth.api_url, params={\n    \"action\": \"query\",\n    \"meta\": \"userinfo\",\n    \"format\": \"json\"\n})\n\nuserinfo = response.json()\nprint(f\"Logged in as: {userinfo['query']['userinfo']['name']}\")\n</code></pre>"},{"location":"gkc/api/auth/#extract-account-and-bot-names","title":"Extract account and bot names","text":"<p>Parse bot password format to extract components:</p> <pre><code>from gkc import WikiverseAuth\n\nauth = WikiverseAuth(username=\"Alice@MyBot\")\n\n# Before login - still able to parse username\naccount_name = auth.get_account_name()  # \"Alice\"\nbot_name = auth.get_bot_name()          # \"MyBot\"\n\nprint(f\"Account: {account_name}, Bot: {bot_name}\")\n\n# Credentials can be provided via environment or password prompt\nauth.login()\ntoken = auth.get_csrf_token()\n</code></pre>"},{"location":"gkc/api/auth/#error-handling","title":"Error Handling","text":""},{"location":"gkc/api/auth/#missing-credentials","title":"Missing credentials","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\n\nauth = WikiverseAuth()  # No credentials provided\ntry:\n    auth.login()\nexcept AuthenticationError as e:\n    print(f\"Login failed: {e}\")\n    # Output: Login failed: Cannot login: credentials not provided...\n</code></pre>"},{"location":"gkc/api/auth/#invalid-bot-password-credentials","title":"Invalid bot password credentials","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\n\nauth = WikiverseAuth(\n    username=\"Alice@BadBot\",\n    password=\"wrong_password\"\n)\n\ntry:\n    auth.login()\nexcept AuthenticationError as e:\n    print(f\"Authentication error: {e}\")\n    # Output will describe the specific failure reason\n</code></pre>"},{"location":"gkc/api/auth/#network-errors","title":"Network errors","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\n\n# Invalid API URL\nauth = WikiverseAuth(\n    username=\"Alice@MyBot\",\n    password=\"secret\",\n    api_url=\"https://invalid-wiki-site.example.com/w/api.php\"\n)\n\ntry:\n    auth.login()\nexcept AuthenticationError as e:\n    print(f\"Network error: {e}\")\n    # Output: Network error during login to https://invalid-wiki-site.example.com/w/api.php: ...\n</code></pre>"},{"location":"gkc/api/auth/#missing-csrf-token-not-logged-in","title":"Missing CSRF token (not logged in)","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\n\nauth = WikiverseAuth(username=\"Alice@MyBot\", password=\"secret\")\n# Forgot to login first!\n\ntry:\n    token = auth.get_csrf_token()\nexcept AuthenticationError as e:\n    print(f\"Error: {e}\")\n    # Output: Error: Not logged in. Call login() first before getting CSRF token.\n</code></pre>"},{"location":"gkc/api/auth/#available-endpoints","title":"Available Endpoints","text":"<p>The auth module includes shortcuts for common Wikimedia instances:</p> Shortcut Full URL <code>wikidata</code> <code>https://www.wikidata.org/w/api.php</code> <code>wikidata_test</code> <code>https://test.wikidata.org/w/api.php</code> <code>wikipedia</code> <code>https://en.wikipedia.org/w/api.php</code> <code>commons</code> <code>https://commons.wikimedia.org/w/api.php</code> <p>Custom MediaWiki instances can be used by providing the full API URL.</p>"},{"location":"gkc/api/auth/#see-also","title":"See Also","text":"<ul> <li>Authentication Guide - Conceptual overview and setup instructions</li> <li>SPARQL API - Query Wikidata and other SPARQL endpoints</li> </ul>"},{"location":"gkc/api/mash/","title":"Mash Module API","text":""},{"location":"gkc/api/mash/#overview","title":"Overview","text":"<p>Load data from Wikidata, Wikipedia, and other sources as templates for processing. The Mash stage is the entry point to the data distillery workflow, preparing source data for validation, transformation, and submission.</p> <p>Current implementations:</p> <ul> <li>Wikidata items (QID)</li> <li>Wikidata properties (PID)</li> <li>Wikidata EntitySchemas (EID)</li> <li>Wikipedia templates</li> </ul> <p>Future implementations: OSM, Wikimedia Commons, CSV files, JSON APIs, dataframes</p>"},{"location":"gkc/api/mash/#quick-start","title":"Quick Start","text":"<pre><code>from gkc.mash import WikidataLoader, WikipediaLoader\n\n# Load Wikidata entities\nloader = WikidataLoader()\n\n# Load a single item\nitem = loader.load_item(\"Q42\")\n\n# Load multiple items in batch\nitems = loader.load_items([\"Q42\", \"Q5\", \"Q30\"])\n\n# Load a property\nprop = loader.load_property(\"P31\")\n\n# Load an EntitySchema\nschema = loader.load_entity_schema(\"E502\")\n\n# Load Wikipedia templates\nwp_loader = WikipediaLoader()\ntemplate = wp_loader.load_template(\"Infobox settlement\")\n\n# Filter and transform\nitem.filter_languages([\"en\", \"es\"])\nsummary = item.summary()\nprint(summary)\n</code></pre>"},{"location":"gkc/api/mash/#core-classes","title":"Core Classes","text":""},{"location":"gkc/api/mash/#wikidataloader","title":"WikidataLoader","text":"<p>Load a Wikidata item as a template for bulk modification.</p> <p>This is the Wikidata-specific implementation of a data loader. Future loaders for CSV, JSON APIs, etc. should follow a similar pattern.</p> <p>Plain meaning: Fetch and parse a Wikidata item into a usable template.</p> Source code in <code>gkc/mash.py</code> <pre><code>class WikidataLoader:\n    \"\"\"Load a Wikidata item as a template for bulk modification.\n\n    This is the Wikidata-specific implementation of a data loader.\n    Future loaders for CSV, JSON APIs, etc. should follow a similar pattern.\n\n    Plain meaning: Fetch and parse a Wikidata item into a usable template.\n    \"\"\"\n\n    def __init__(self, user_agent: Optional[str] = None):\n        \"\"\"Initialize the loader.\n\n        Args:\n            user_agent: Custom user agent for Wikidata requests.\n                       If not provided, a default GKC user agent is used.\n        \"\"\"\n\n        if user_agent is None:\n            user_agent = \"GKC/1.0 (https://github.com/skybristol/gkc; data integration)\"\n\n        self.user_agent = user_agent\n\n    def load_item(self, qid: str) -&gt; WikidataTemplate:\n        \"\"\"Load a Wikidata item and return it as a template.\n\n        Args:\n            qid: The Wikidata item ID (e.g., 'Q42').\n\n        Returns:\n            WikidataTemplate with the item's structure.\n\n        Raises:\n            RuntimeError: If the item cannot be fetched or parsed.\n\n        Plain meaning: Retrieve the item and return it ready for use.\n\n        Example:\n            &gt;&gt;&gt; loader = WikidataLoader()\n            &gt;&gt;&gt; template = loader.load_item(\"Q42\")\n            &gt;&gt;&gt; print(template.summary())\n        \"\"\"\n\n        entity_data = self.load_entity_data(qid)\n\n        # Convert to MashTemplate\n        template = self._build_template(qid, entity_data)\n\n        return template\n\n    def load(self, qid: str) -&gt; WikidataTemplate:\n        \"\"\"Load a Wikidata item and return it as a template.\n\n        .. deprecated:: 1.0\n            Use :meth:`load_item` instead. This method is maintained for\n            backwards compatibility and will be removed in a future version.\n\n        Args:\n            qid: The Wikidata item ID (e.g., 'Q42').\n\n        Returns:\n            WikidataTemplate with the item's structure.\n\n        Plain meaning: Retrieve the item and return it ready for use.\n        \"\"\"\n        return self.load_item(qid)\n\n    def load_items(self, qids: list[str]) -&gt; dict[str, WikidataTemplate]:\n        \"\"\"Load multiple Wikidata items in batch and return them as templates.\n\n        Uses the wbgetentities API to efficiently fetch multiple items in batches\n        of 50. Handles partial failures gracefully.\n\n        Args:\n            qids: List of Wikidata item IDs (e.g., ['Q42', 'Q5']).\n\n        Returns:\n            Dict mapping QIDs to WikidataTemplates. Only successfully loaded\n            items are included in the result.\n\n        Raises:\n            RuntimeError: If the API request fails completely.\n\n        Plain meaning: Load multiple items efficiently in batch.\n\n        Example:\n            &gt;&gt;&gt; loader = WikidataLoader()\n            &gt;&gt;&gt; templates = loader.load_items([\"Q42\", \"Q5\", \"Q30\"])\n            &gt;&gt;&gt; print(len(templates))\n            3\n        \"\"\"\n        if not qids:\n            return {}\n\n        result: dict[str, WikidataTemplate] = {}\n\n        # Process in batches of 50 (wbgetentities limit)\n        batch_size = 50\n        for i in range(0, len(qids), batch_size):\n            batch = qids[i : i + batch_size]\n            batch_results = self._fetch_entities_batch(batch)\n\n            # Build templates for each successfully fetched entity\n            for qid, entity_data in batch_results.items():\n                try:\n                    template = self._build_template(qid, entity_data)\n                    result[qid] = template\n                except Exception:\n                    # Skip items that fail to parse\n                    continue\n\n        return result\n\n    def load_property(self, pid: str) -&gt; WikidataPropertyTemplate:\n        \"\"\"Load a Wikidata property and return it as a template.\n\n        Args:\n            pid: The Wikidata property ID (e.g., 'P31').\n\n        Returns:\n            WikidataPropertyTemplate with the property's metadata.\n\n        Raises:\n            RuntimeError: If the property cannot be fetched or parsed.\n\n        Plain meaning: Retrieve a property definition and return it ready for use.\n\n        Example:\n            &gt;&gt;&gt; loader = WikidataLoader()\n            &gt;&gt;&gt; prop = loader.load_property(\"P31\")\n            &gt;&gt;&gt; print(prop.summary())\n        \"\"\"\n        entity_data = self.load_entity_data(pid)\n        return self._build_property_template(pid, entity_data)\n\n    def load_entity_schema(self, eid: str) -&gt; WikidataEntitySchemaTemplate:\n        \"\"\"Load a Wikidata EntitySchema and return it as a template.\n\n        Args:\n            eid: The Wikidata EntitySchema ID (e.g., 'E502').\n\n        Returns:\n            WikidataEntitySchemaTemplate with the schema content.\n\n        Raises:\n            RuntimeError: If the EntitySchema cannot be fetched or parsed.\n\n        Plain meaning: Retrieve an EntitySchema and return it ready for use.\n\n        Example:\n            &gt;&gt;&gt; loader = WikidataLoader()\n            &gt;&gt;&gt; schema = loader.load_entity_schema(\"E502\")\n            &gt;&gt;&gt; print(schema.summary())\n        \"\"\"\n        from gkc.cooperage import fetch_entity_schema_json\n\n        entity_data = fetch_entity_schema_json(eid, user_agent=self.user_agent)\n        return self._build_entity_schema_template(eid, entity_data)\n\n    def _fetch_entities_batch(self, entity_ids: list[str]) -&gt; dict[str, dict[str, Any]]:\n        \"\"\"Fetch multiple entities using wbgetentities API.\n\n        Args:\n            entity_ids: List of entity IDs (max 50).\n\n        Returns:\n            Dict mapping entity IDs to their entity data.\n\n        Raises:\n            RuntimeError: If the API request fails.\n\n        Plain meaning: Fetch a batch of entities from Wikidata.\n        \"\"\"\n        url = \"https://www.wikidata.org/w/api.php\"\n        params = {\n            \"action\": \"wbgetentities\",\n            \"ids\": \"|\".join(entity_ids),\n            \"format\": \"json\",\n        }\n\n        headers = {}\n        if self.user_agent:\n            headers[\"User-Agent\"] = self.user_agent\n\n        try:\n            response = requests.get(url, params=params, headers=headers, timeout=30)\n            response.raise_for_status()\n            data = response.json()\n\n            # Extract entities from response\n            entities = data.get(\"entities\", {})\n\n            # Filter out entities with \"missing\" key (not found)\n            return {\n                eid: entity_data\n                for eid, entity_data in entities.items()\n                if \"missing\" not in entity_data\n            }\n\n        except requests.RequestException as exc:\n            raise RuntimeError(f\"Failed to fetch entities batch: {exc}\") from exc\n\n    def load_entity_data(self, qid: str) -&gt; dict[str, Any]:\n        \"\"\"Load raw Wikidata entity data.\n\n        Plain meaning: Return the entity JSON as provided by Wikidata.\n        \"\"\"\n\n        # Fetch the item via Special:EntityData endpoint which returns JSON\n        # This is equivalent to wbgetentities but simpler for single-item fetches\n        json_text = self._fetch_entity_json(qid)\n\n        # Parse the JSON response from Wikidata\n        return self._parse_wikidata_json(json_text, qid)\n\n    def _fetch_entity_json(self, qid: str) -&gt; str:\n        \"\"\"Fetch a single Wikidata entity as JSON.\n\n        Args:\n            qid: The Wikidata item ID (e.g., 'Q42').\n\n        Returns:\n            JSON string with entity data.\n\n        Raises:\n            RuntimeError: If the fetch fails or entity doesn't exist.\n\n        Plain meaning: Download the item from Wikidata as JSON.\n        \"\"\"\n\n        url = f\"https://www.wikidata.org/wiki/Special:EntityData/{qid}.json\"\n\n        headers = {}\n        if self.user_agent:\n            headers[\"User-Agent\"] = self.user_agent\n\n        try:\n            response = requests.get(url, headers=headers, timeout=30)\n\n            # Handle 404 or 400 errors which indicate item doesn't exist\n            if response.status_code == 404:\n                raise RuntimeError(f\"no-such-entity: {qid} not found on Wikidata\")\n            if response.status_code == 400:\n                raise RuntimeError(f\"no-such-entity: {qid} is invalid\")\n\n            response.raise_for_status()\n            return response.text\n        except requests.RequestException as exc:\n            raise RuntimeError(f\"Failed to load item {qid}: {exc}\") from exc\n\n    def _parse_wikidata_json(self, json_text: str, qid: str) -&gt; dict[str, Any]:\n        \"\"\"Parse Wikidata JSON response from Special:EntityData endpoint.\n\n        Args:\n            json_text: Raw JSON response text.\n            qid: The QID being parsed (used for error messages).\n\n        Returns:\n            Dictionary with entity data.\n\n        Raises:\n            ValueError: If JSON parsing fails or format is unexpected.\n\n        Plain meaning: Extract entity data from the API response.\n        \"\"\"\n\n        try:\n            response = json.loads(json_text)\n        except json.JSONDecodeError as exc:\n            raise ValueError(f\"Failed to parse JSON response for {qid}: {exc}\") from exc\n\n        if not isinstance(response, dict):\n            raise ValueError(f\"Expected JSON object for {qid}, got {type(response)}\")\n\n        # Special:EntityData wraps data in an \"entities\" key\n        entities = response.get(\"entities\", {})\n        entity_data: dict[str, Any] = entities.get(qid, {})\n\n        # Check for API error\n        if \"error\" in entity_data:\n            error_code = entity_data[\"error\"].get(\"code\", \"unknown\")\n            error_info = entity_data[\"error\"].get(\"info\", \"No error details\")\n            raise ValueError(\n                f\"Wikidata API error for {qid} ({error_code}): {error_info}\"\n            )\n\n        if not entity_data:\n            raise ValueError(f\"Entity {qid} not found in response\")\n\n        return entity_data\n\n    def _build_template(\n        self, qid: str, entity_data: dict[str, Any]\n    ) -&gt; WikidataTemplate:\n        \"\"\"Convert entity data to a WikidataTemplate.\n\n        Plain meaning: Transform API data into our simplified format.\n        \"\"\"\n\n        # Extract labels, descriptions, aliases\n        labels = entity_data.get(\"labels\", {})\n        descriptions = entity_data.get(\"descriptions\", {})\n        aliases = entity_data.get(\"aliases\", {})\n\n        # Simplify to language -&gt; value mappings\n        labels_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in labels.items()\n            if isinstance(item, dict)\n        }\n        descriptions_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in descriptions.items()\n            if isinstance(item, dict)\n        }\n        aliases_dict = {\n            lang: [alias.get(\"value\", \"\") for alias in alias_list]\n            for lang, alias_list in aliases.items()\n            if isinstance(alias_list, list)\n        }\n\n        # Extract claims\n        claims = self._extract_claims(entity_data.get(\"claims\", {}))\n\n        return WikidataTemplate(\n            qid=qid,\n            labels=labels_dict,\n            descriptions=descriptions_dict,\n            aliases=aliases_dict,\n            claims=claims,\n            entity_data=copy.deepcopy(entity_data),\n        )\n\n    @staticmethod\n    def _extract_claims(claims_data: dict[str, Any]) -&gt; list[ClaimSummary]:\n        \"\"\"Extract claims from entity data.\n\n        Plain meaning: Parse statement data into simplified claim objects.\n        \"\"\"\n\n        claims: list[ClaimSummary] = []\n\n        for prop_id, statements in claims_data.items():\n            if not isinstance(statements, list):\n                continue\n\n            for statement in statements:\n                claim = WikidataLoader._statement_to_claim(prop_id, statement)\n                if claim:\n                    claims.append(claim)\n\n        return claims\n\n    def _build_property_template(\n        self, pid: str, entity_data: dict[str, Any]\n    ) -&gt; WikidataPropertyTemplate:\n        \"\"\"Convert entity data to a WikidataPropertyTemplate.\n\n        Plain meaning: Transform API data into our simplified property format.\n        \"\"\"\n        # Extract labels, descriptions, aliases\n        labels = entity_data.get(\"labels\", {})\n        descriptions = entity_data.get(\"descriptions\", {})\n        aliases = entity_data.get(\"aliases\", {})\n\n        # Simplify to language -&gt; value mappings\n        labels_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in labels.items()\n            if isinstance(item, dict)\n        }\n        descriptions_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in descriptions.items()\n            if isinstance(item, dict)\n        }\n        aliases_dict = {\n            lang: [alias.get(\"value\", \"\") for alias in alias_list]\n            for lang, alias_list in aliases.items()\n            if isinstance(alias_list, list)\n        }\n\n        # Extract property-specific metadata\n        datatype = entity_data.get(\"datatype\")\n\n        # Formatter URL is in claims P1630\n        formatter_url = None\n        claims = entity_data.get(\"claims\", {})\n        p1630_statements = claims.get(\"P1630\", [])\n        if p1630_statements and isinstance(p1630_statements, list):\n            first_statement = p1630_statements[0]\n            mainsnak = first_statement.get(\"mainsnak\", {})\n            datavalue = mainsnak.get(\"datavalue\", {})\n            if datavalue.get(\"type\") == \"string\":\n                formatter_url = datavalue.get(\"value\")\n\n        return WikidataPropertyTemplate(\n            pid=pid,\n            labels=labels_dict,\n            descriptions=descriptions_dict,\n            aliases=aliases_dict,\n            datatype=datatype,\n            formatter_url=formatter_url,\n            entity_data=copy.deepcopy(entity_data),\n        )\n\n    def _build_entity_schema_template(\n        self, eid: str, entity_data: dict[str, Any]\n    ) -&gt; WikidataEntitySchemaTemplate:\n        \"\"\"Convert entity data to a WikidataEntitySchemaTemplate.\n\n        Plain meaning: Transform API data into our simplified EntitySchema format.\n        \"\"\"\n        # Extract labels and descriptions\n        labels = entity_data.get(\"labels\", {})\n        descriptions = entity_data.get(\"descriptions\", {})\n\n        # Simplify to language -&gt; value mappings\n        labels_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in labels.items()\n            if isinstance(item, dict)\n        }\n        descriptions_dict = {\n            lang: item.get(\"value\", \"\")\n            for lang, item in descriptions.items()\n            if isinstance(item, dict)\n        }\n\n        # Extract schema text\n        schema_text = entity_data.get(\"schemaText\", \"\")\n\n        return WikidataEntitySchemaTemplate(\n            eid=eid,\n            labels=labels_dict,\n            descriptions=descriptions_dict,\n            schema_text=schema_text,\n            entity_data=copy.deepcopy(entity_data),\n        )\n\n    @staticmethod\n    def _statement_to_claim(\n        prop_id: str, statement: dict[str, Any]\n    ) -&gt; Optional[ClaimSummary]:\n        \"\"\"Convert a single statement to a ClaimSummary.\n\n        Plain meaning: Simplify a statement object for display.\n        \"\"\"\n\n        # Extract main value\n        mainsnak = statement.get(\"mainsnak\", {})\n        value, value_metadata = WikidataLoader._snak_to_value(mainsnak)\n        if value is None:\n            return None\n\n        # Extract qualifiers with their values\n        qualifiers = statement.get(\"qualifiers\", {})\n        qualifiers_list = []\n        for prop, snaks in qualifiers.items():\n            if snaks:\n                # Extract value from the first snak of each qualifier property\n                snak = snaks[0]\n                qual_value, qual_metadata = WikidataLoader._snak_to_value(snak)\n                if qual_value:\n                    qualifier_dict = {\"property\": prop, \"value\": qual_value}\n                    if qual_metadata:\n                        qualifier_dict[\"metadata\"] = qual_metadata\n                    qualifiers_list.append(qualifier_dict)\n\n        # Extract references\n        references = statement.get(\"references\", [])\n        references_list = [{\"count\": len(ref.get(\"snaks\", {}))} for ref in references]\n\n        rank = statement.get(\"rank\", \"normal\")\n\n        return ClaimSummary(\n            property_id=prop_id,\n            value=value,\n            qualifiers=qualifiers_list,\n            references=references_list,\n            rank=rank,\n            value_metadata=value_metadata,\n        )\n\n    @staticmethod\n    def _snak_to_value(\n        snak: dict[str, Any],\n    ) -&gt; tuple[Optional[str], Optional[dict[str, Any]]]:\n        \"\"\"Extract a human-readable value from a snak with metadata.\n\n        Returns:\n            Tuple of (value_string, metadata_dict) where metadata contains\n            things like precision for dates, units for quantities, etc.\n\n        Plain meaning: Get a simple string representation of the value plus metadata.\n        \"\"\"\n\n        snaktype = snak.get(\"snaktype\", \"value\")\n\n        if snaktype == \"novalue\":\n            return \"[no value]\", None\n        if snaktype == \"somevalue\":\n            return \"[unknown value]\", None\n\n        datavalue = snak.get(\"datavalue\")\n        if not datavalue:\n            return None, None\n\n        dv_type = datavalue.get(\"type\", \"\")\n        dv_value = datavalue.get(\"value\")\n\n        if dv_type == \"wikibase-entityid\":\n            if isinstance(dv_value, dict):\n                return dv_value.get(\"id\", \"[entity]\"), None\n            return str(dv_value), None\n\n        if dv_type == \"quantity\":\n            if isinstance(dv_value, dict):\n                amount = dv_value.get(\"amount\", \"[quantity]\")\n                unit = dv_value.get(\"unit\")\n                metadata = {\"unit\": unit} if unit else None\n                return amount, metadata\n            return str(dv_value), None\n\n        if dv_type == \"time\":\n            if isinstance(dv_value, dict):\n                time_str = dv_value.get(\"time\", \"[time]\")\n                precision = dv_value.get(\"precision\")\n                metadata = {\"precision\": precision} if precision is not None else None\n                return time_str, metadata\n            return str(dv_value), None\n\n        if dv_type == \"monolingualtext\":\n            if isinstance(dv_value, dict):\n                return dv_value.get(\"text\", \"[text]\"), None\n            return str(dv_value), None\n\n        if dv_type == \"string\":\n            return str(dv_value), None\n\n        if dv_type == \"globecoordinate\":\n            if isinstance(dv_value, dict):\n                lat = dv_value.get(\"latitude\", \"?\")\n                lon = dv_value.get(\"longitude\", \"?\")\n                precision_val = dv_value.get(\"precision\")\n                metadata = (\n                    {\"precision\": precision_val} if precision_val is not None else None\n                )\n                return f\"({lat}, {lon})\", metadata\n            return str(dv_value), None\n\n        return (str(dv_value), None) if dv_value else (None, None)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.__init__","title":"<code>__init__(user_agent=None)</code>","text":"<p>Initialize the loader.</p> <p>Parameters:</p> Name Type Description Default <code>user_agent</code> <code>Optional[str]</code> <p>Custom user agent for Wikidata requests.        If not provided, a default GKC user agent is used.</p> <code>None</code> Source code in <code>gkc/mash.py</code> <pre><code>def __init__(self, user_agent: Optional[str] = None):\n    \"\"\"Initialize the loader.\n\n    Args:\n        user_agent: Custom user agent for Wikidata requests.\n                   If not provided, a default GKC user agent is used.\n    \"\"\"\n\n    if user_agent is None:\n        user_agent = \"GKC/1.0 (https://github.com/skybristol/gkc; data integration)\"\n\n    self.user_agent = user_agent\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load","title":"<code>load(qid)</code>","text":"<p>Load a Wikidata item and return it as a template.</p> <p>.. deprecated:: 1.0     Use :meth:<code>load_item</code> instead. This method is maintained for     backwards compatibility and will be removed in a future version.</p> <p>Parameters:</p> Name Type Description Default <code>qid</code> <code>str</code> <p>The Wikidata item ID (e.g., 'Q42').</p> required <p>Returns:</p> Type Description <code>WikidataTemplate</code> <p>WikidataTemplate with the item's structure.</p> <p>Plain meaning: Retrieve the item and return it ready for use.</p> Source code in <code>gkc/mash.py</code> <pre><code>def load(self, qid: str) -&gt; WikidataTemplate:\n    \"\"\"Load a Wikidata item and return it as a template.\n\n    .. deprecated:: 1.0\n        Use :meth:`load_item` instead. This method is maintained for\n        backwards compatibility and will be removed in a future version.\n\n    Args:\n        qid: The Wikidata item ID (e.g., 'Q42').\n\n    Returns:\n        WikidataTemplate with the item's structure.\n\n    Plain meaning: Retrieve the item and return it ready for use.\n    \"\"\"\n    return self.load_item(qid)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load_entity_data","title":"<code>load_entity_data(qid)</code>","text":"<p>Load raw Wikidata entity data.</p> <p>Plain meaning: Return the entity JSON as provided by Wikidata.</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_entity_data(self, qid: str) -&gt; dict[str, Any]:\n    \"\"\"Load raw Wikidata entity data.\n\n    Plain meaning: Return the entity JSON as provided by Wikidata.\n    \"\"\"\n\n    # Fetch the item via Special:EntityData endpoint which returns JSON\n    # This is equivalent to wbgetentities but simpler for single-item fetches\n    json_text = self._fetch_entity_json(qid)\n\n    # Parse the JSON response from Wikidata\n    return self._parse_wikidata_json(json_text, qid)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load_entity_schema","title":"<code>load_entity_schema(eid)</code>","text":"<p>Load a Wikidata EntitySchema and return it as a template.</p> <p>Parameters:</p> Name Type Description Default <code>eid</code> <code>str</code> <p>The Wikidata EntitySchema ID (e.g., 'E502').</p> required <p>Returns:</p> Type Description <code>WikidataEntitySchemaTemplate</code> <p>WikidataEntitySchemaTemplate with the schema content.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the EntitySchema cannot be fetched or parsed.</p> <p>Plain meaning: Retrieve an EntitySchema and return it ready for use.</p> Example <p>loader = WikidataLoader() schema = loader.load_entity_schema(\"E502\") print(schema.summary())</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_entity_schema(self, eid: str) -&gt; WikidataEntitySchemaTemplate:\n    \"\"\"Load a Wikidata EntitySchema and return it as a template.\n\n    Args:\n        eid: The Wikidata EntitySchema ID (e.g., 'E502').\n\n    Returns:\n        WikidataEntitySchemaTemplate with the schema content.\n\n    Raises:\n        RuntimeError: If the EntitySchema cannot be fetched or parsed.\n\n    Plain meaning: Retrieve an EntitySchema and return it ready for use.\n\n    Example:\n        &gt;&gt;&gt; loader = WikidataLoader()\n        &gt;&gt;&gt; schema = loader.load_entity_schema(\"E502\")\n        &gt;&gt;&gt; print(schema.summary())\n    \"\"\"\n    from gkc.cooperage import fetch_entity_schema_json\n\n    entity_data = fetch_entity_schema_json(eid, user_agent=self.user_agent)\n    return self._build_entity_schema_template(eid, entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load_item","title":"<code>load_item(qid)</code>","text":"<p>Load a Wikidata item and return it as a template.</p> <p>Parameters:</p> Name Type Description Default <code>qid</code> <code>str</code> <p>The Wikidata item ID (e.g., 'Q42').</p> required <p>Returns:</p> Type Description <code>WikidataTemplate</code> <p>WikidataTemplate with the item's structure.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the item cannot be fetched or parsed.</p> <p>Plain meaning: Retrieve the item and return it ready for use.</p> Example <p>loader = WikidataLoader() template = loader.load_item(\"Q42\") print(template.summary())</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_item(self, qid: str) -&gt; WikidataTemplate:\n    \"\"\"Load a Wikidata item and return it as a template.\n\n    Args:\n        qid: The Wikidata item ID (e.g., 'Q42').\n\n    Returns:\n        WikidataTemplate with the item's structure.\n\n    Raises:\n        RuntimeError: If the item cannot be fetched or parsed.\n\n    Plain meaning: Retrieve the item and return it ready for use.\n\n    Example:\n        &gt;&gt;&gt; loader = WikidataLoader()\n        &gt;&gt;&gt; template = loader.load_item(\"Q42\")\n        &gt;&gt;&gt; print(template.summary())\n    \"\"\"\n\n    entity_data = self.load_entity_data(qid)\n\n    # Convert to MashTemplate\n    template = self._build_template(qid, entity_data)\n\n    return template\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load_items","title":"<code>load_items(qids)</code>","text":"<p>Load multiple Wikidata items in batch and return them as templates.</p> <p>Uses the wbgetentities API to efficiently fetch multiple items in batches of 50. Handles partial failures gracefully.</p> <p>Parameters:</p> Name Type Description Default <code>qids</code> <code>list[str]</code> <p>List of Wikidata item IDs (e.g., ['Q42', 'Q5']).</p> required <p>Returns:</p> Type Description <code>dict[str, WikidataTemplate]</code> <p>Dict mapping QIDs to WikidataTemplates. Only successfully loaded</p> <code>dict[str, WikidataTemplate]</code> <p>items are included in the result.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the API request fails completely.</p> <p>Plain meaning: Load multiple items efficiently in batch.</p> Example <p>loader = WikidataLoader() templates = loader.load_items([\"Q42\", \"Q5\", \"Q30\"]) print(len(templates)) 3</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_items(self, qids: list[str]) -&gt; dict[str, WikidataTemplate]:\n    \"\"\"Load multiple Wikidata items in batch and return them as templates.\n\n    Uses the wbgetentities API to efficiently fetch multiple items in batches\n    of 50. Handles partial failures gracefully.\n\n    Args:\n        qids: List of Wikidata item IDs (e.g., ['Q42', 'Q5']).\n\n    Returns:\n        Dict mapping QIDs to WikidataTemplates. Only successfully loaded\n        items are included in the result.\n\n    Raises:\n        RuntimeError: If the API request fails completely.\n\n    Plain meaning: Load multiple items efficiently in batch.\n\n    Example:\n        &gt;&gt;&gt; loader = WikidataLoader()\n        &gt;&gt;&gt; templates = loader.load_items([\"Q42\", \"Q5\", \"Q30\"])\n        &gt;&gt;&gt; print(len(templates))\n        3\n    \"\"\"\n    if not qids:\n        return {}\n\n    result: dict[str, WikidataTemplate] = {}\n\n    # Process in batches of 50 (wbgetentities limit)\n    batch_size = 50\n    for i in range(0, len(qids), batch_size):\n        batch = qids[i : i + batch_size]\n        batch_results = self._fetch_entities_batch(batch)\n\n        # Build templates for each successfully fetched entity\n        for qid, entity_data in batch_results.items():\n            try:\n                template = self._build_template(qid, entity_data)\n                result[qid] = template\n            except Exception:\n                # Skip items that fail to parse\n                continue\n\n    return result\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataLoader.load_property","title":"<code>load_property(pid)</code>","text":"<p>Load a Wikidata property and return it as a template.</p> <p>Parameters:</p> Name Type Description Default <code>pid</code> <code>str</code> <p>The Wikidata property ID (e.g., 'P31').</p> required <p>Returns:</p> Type Description <code>WikidataPropertyTemplate</code> <p>WikidataPropertyTemplate with the property's metadata.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the property cannot be fetched or parsed.</p> <p>Plain meaning: Retrieve a property definition and return it ready for use.</p> Example <p>loader = WikidataLoader() prop = loader.load_property(\"P31\") print(prop.summary())</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_property(self, pid: str) -&gt; WikidataPropertyTemplate:\n    \"\"\"Load a Wikidata property and return it as a template.\n\n    Args:\n        pid: The Wikidata property ID (e.g., 'P31').\n\n    Returns:\n        WikidataPropertyTemplate with the property's metadata.\n\n    Raises:\n        RuntimeError: If the property cannot be fetched or parsed.\n\n    Plain meaning: Retrieve a property definition and return it ready for use.\n\n    Example:\n        &gt;&gt;&gt; loader = WikidataLoader()\n        &gt;&gt;&gt; prop = loader.load_property(\"P31\")\n        &gt;&gt;&gt; print(prop.summary())\n    \"\"\"\n    entity_data = self.load_entity_data(pid)\n    return self._build_property_template(pid, entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#wikidatatemplate","title":"WikidataTemplate","text":"<p>An extracted Wikidata item ready for filtering and export.</p> <p>This is the Wikidata-specific implementation of the DataTemplate protocol.</p> <p>Plain meaning: A loaded Wikidata item template ready for modification.</p> Source code in <code>gkc/mash.py</code> <pre><code>@dataclass\nclass WikidataTemplate:\n    \"\"\"An extracted Wikidata item ready for filtering and export.\n\n    This is the Wikidata-specific implementation of the DataTemplate protocol.\n\n    Plain meaning: A loaded Wikidata item template ready for modification.\n    \"\"\"\n\n    qid: str\n    labels: dict[str, str]\n    descriptions: dict[str, str]\n    aliases: dict[str, list[str]]\n    claims: list[ClaimSummary]\n    entity_data: dict[str, Any]\n\n    def filter_properties(\n        self,\n        include_properties: Optional[list[str]] = None,\n        exclude_properties: Optional[list[str]] = None,\n    ) -&gt; None:\n        \"\"\"Filter properties from the template in-place.\n\n        Plain meaning: Keep only specified properties, then drop excluded ones.\n        \"\"\"\n\n        if include_properties:\n            include_set = set(include_properties)\n            self.claims = [\n                claim for claim in self.claims if claim.property_id in include_set\n            ]\n            claims = self.entity_data.get(\"claims\")\n            if isinstance(claims, dict):\n                self.entity_data[\"claims\"] = {\n                    prop_id: statements\n                    for prop_id, statements in claims.items()\n                    if prop_id in include_set\n                }\n\n        if exclude_properties:\n            exclude_set = set(exclude_properties)\n            self.claims = [\n                claim for claim in self.claims if claim.property_id not in exclude_set\n            ]\n            claims = self.entity_data.get(\"claims\")\n            if isinstance(claims, dict):\n                self.entity_data[\"claims\"] = {\n                    prop_id: statements\n                    for prop_id, statements in claims.items()\n                    if prop_id not in exclude_set\n                }\n\n    def filter_qualifiers(self) -&gt; None:\n        \"\"\"Remove all qualifiers from claims in-place.\n\n        Plain meaning: Strip qualifier detail from claims.\n        \"\"\"\n\n        for claim in self.claims:\n            claim.qualifiers = []\n\n        claims = self.entity_data.get(\"claims\")\n        if isinstance(claims, dict):\n            for statements in claims.values():\n                if not isinstance(statements, list):\n                    continue\n                for statement in statements:\n                    if isinstance(statement, dict):\n                        statement.pop(\"qualifiers\", None)\n                        statement.pop(\"qualifiers-order\", None)\n\n    def filter_references(self) -&gt; None:\n        \"\"\"Remove all references from claims in-place.\n\n        Plain meaning: Strip reference detail from claims.\n        \"\"\"\n\n        for claim in self.claims:\n            claim.references = []\n\n        claims = self.entity_data.get(\"claims\")\n        if isinstance(claims, dict):\n            for statements in claims.values():\n                if not isinstance(statements, list):\n                    continue\n                for statement in statements:\n                    if isinstance(statement, dict):\n                        statement.pop(\"references\", None)\n\n    def filter_languages(\n        self, languages: Optional[Union[str, list[str]]] = None\n    ) -&gt; None:\n        \"\"\"Filter labels, descriptions, and aliases to specified languages.\n\n        Args:\n            languages: Either:\n                - A single language code (e.g., \"en\")\n                - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n                - The string \"all\" to keep all languages\n                - None to use the package-level language configuration\n\n        Plain meaning: Keep only the specified language versions.\n        \"\"\"\n        import gkc\n\n        if languages is None:\n            languages = gkc.get_languages()\n\n        # If \"all\", don't filter anything\n        if languages == \"all\":\n            return\n\n        # Convert single string to list for uniform handling\n        if isinstance(languages, str):\n            languages = [languages]\n\n        # Filter each field\n        self.labels = {k: v for k, v in self.labels.items() if k in languages}\n        self.descriptions = {\n            k: v for k, v in self.descriptions.items() if k in languages\n        }\n        self.aliases = {k: v for k, v in self.aliases.items() if k in languages}\n\n        labels = self.entity_data.get(\"labels\")\n        if isinstance(labels, dict):\n            self.entity_data[\"labels\"] = {\n                lang: value for lang, value in labels.items() if lang in languages\n            }\n\n        descriptions = self.entity_data.get(\"descriptions\")\n        if isinstance(descriptions, dict):\n            self.entity_data[\"descriptions\"] = {\n                lang: value for lang, value in descriptions.items() if lang in languages\n            }\n\n        aliases = self.entity_data.get(\"aliases\")\n        if isinstance(aliases, dict):\n            self.entity_data[\"aliases\"] = {\n                lang: value for lang, value in aliases.items() if lang in languages\n            }\n\n    def summary(self) -&gt; dict[str, Any]:\n        \"\"\"Return a summary of the template for display.\n\n        Plain meaning: Get a quick overview without full details.\n        \"\"\"\n\n        return {\n            \"qid\": self.qid,\n            \"labels\": self.labels,\n            \"descriptions\": self.descriptions,\n            \"total_statements\": len(self.claims),\n            \"aliases\": self.aliases,\n        }\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to a dictionary.\n\n        Plain meaning: Convert to a form suitable for JSON export.\n        \"\"\"\n\n        return copy.deepcopy(self.entity_data)\n\n    def to_simple_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to a simplified dictionary.\n\n        Plain meaning: Convert to a compact summary structure.\n        \"\"\"\n\n        return {\n            \"qid\": self.qid,\n            \"labels\": self.labels,\n            \"descriptions\": self.descriptions,\n            \"aliases\": self.aliases,\n            \"claims\": [\n                {\n                    \"property_id\": c.property_id,\n                    \"value\": c.value,\n                    \"qualifiers\": c.qualifiers,\n                    \"references\": c.references,\n                    \"rank\": c.rank,\n                }\n                for c in self.claims\n            ],\n        }\n\n    def to_shell(self) -&gt; dict[str, Any]:\n        \"\"\"Strip identifiers and metadata to create a shell for new item creation.\n\n        Returns entity data with all system IDs, metadata, and hashes removed,\n        suitable for use as a template for creating new items.\n\n        Returns:\n            Dict with identifiers stripped, ready for new item creation.\n\n        Plain meaning: Prepare this template as a clean shell for a new item.\n        \"\"\"\n        return strip_entity_identifiers(self.entity_data)\n\n    def to_qsv1(\n        self, for_new_item: bool = False, entity_labels: Optional[dict[str, str]] = None\n    ) -&gt; str:\n        \"\"\"Convert to QuickStatements V1 format.\n\n        Args:\n            for_new_item: If True, use CREATE/LAST syntax for new items.\n                         If False, use the item's QID for updates.\n            entity_labels: Optional dict mapping entity IDs to labels for comments.\n\n        Returns:\n            QuickStatements V1 formatted string.\n\n        Plain meaning: Export as QuickStatements commands for bulk operations.\n        \"\"\"\n        from gkc.mash_formatters import QSV1Formatter\n\n        formatter = QSV1Formatter(entity_labels=entity_labels or {})\n        return formatter.format(self, for_new_item=for_new_item)\n\n    def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to GKC Entity Profile format.\n\n        Returns:\n            Dict representing the GKC Entity Profile.\n\n        Raises:\n            NotImplementedError: This transformation is not yet implemented for items.\n\n        Plain meaning: Transform into a GKC Entity Profile (not yet implemented).\n        \"\"\"\n        raise NotImplementedError(\n            \"Item to GKC Entity Profile transformation is not yet implemented. \"\n            \"This will be added in a future version.\"\n        )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.filter_languages","title":"<code>filter_languages(languages=None)</code>","text":"<p>Filter labels, descriptions, and aliases to specified languages.</p> <p>Parameters:</p> Name Type Description Default <code>languages</code> <code>Optional[Union[str, list[str]]]</code> <p>Either: - A single language code (e.g., \"en\") - A list of language codes (e.g., [\"en\", \"es\", \"fr\"]) - The string \"all\" to keep all languages - None to use the package-level language configuration</p> <code>None</code> <p>Plain meaning: Keep only the specified language versions.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_languages(\n    self, languages: Optional[Union[str, list[str]]] = None\n) -&gt; None:\n    \"\"\"Filter labels, descriptions, and aliases to specified languages.\n\n    Args:\n        languages: Either:\n            - A single language code (e.g., \"en\")\n            - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n            - The string \"all\" to keep all languages\n            - None to use the package-level language configuration\n\n    Plain meaning: Keep only the specified language versions.\n    \"\"\"\n    import gkc\n\n    if languages is None:\n        languages = gkc.get_languages()\n\n    # If \"all\", don't filter anything\n    if languages == \"all\":\n        return\n\n    # Convert single string to list for uniform handling\n    if isinstance(languages, str):\n        languages = [languages]\n\n    # Filter each field\n    self.labels = {k: v for k, v in self.labels.items() if k in languages}\n    self.descriptions = {\n        k: v for k, v in self.descriptions.items() if k in languages\n    }\n    self.aliases = {k: v for k, v in self.aliases.items() if k in languages}\n\n    labels = self.entity_data.get(\"labels\")\n    if isinstance(labels, dict):\n        self.entity_data[\"labels\"] = {\n            lang: value for lang, value in labels.items() if lang in languages\n        }\n\n    descriptions = self.entity_data.get(\"descriptions\")\n    if isinstance(descriptions, dict):\n        self.entity_data[\"descriptions\"] = {\n            lang: value for lang, value in descriptions.items() if lang in languages\n        }\n\n    aliases = self.entity_data.get(\"aliases\")\n    if isinstance(aliases, dict):\n        self.entity_data[\"aliases\"] = {\n            lang: value for lang, value in aliases.items() if lang in languages\n        }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.filter_properties","title":"<code>filter_properties(include_properties=None, exclude_properties=None)</code>","text":"<p>Filter properties from the template in-place.</p> <p>Plain meaning: Keep only specified properties, then drop excluded ones.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_properties(\n    self,\n    include_properties: Optional[list[str]] = None,\n    exclude_properties: Optional[list[str]] = None,\n) -&gt; None:\n    \"\"\"Filter properties from the template in-place.\n\n    Plain meaning: Keep only specified properties, then drop excluded ones.\n    \"\"\"\n\n    if include_properties:\n        include_set = set(include_properties)\n        self.claims = [\n            claim for claim in self.claims if claim.property_id in include_set\n        ]\n        claims = self.entity_data.get(\"claims\")\n        if isinstance(claims, dict):\n            self.entity_data[\"claims\"] = {\n                prop_id: statements\n                for prop_id, statements in claims.items()\n                if prop_id in include_set\n            }\n\n    if exclude_properties:\n        exclude_set = set(exclude_properties)\n        self.claims = [\n            claim for claim in self.claims if claim.property_id not in exclude_set\n        ]\n        claims = self.entity_data.get(\"claims\")\n        if isinstance(claims, dict):\n            self.entity_data[\"claims\"] = {\n                prop_id: statements\n                for prop_id, statements in claims.items()\n                if prop_id not in exclude_set\n            }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.filter_qualifiers","title":"<code>filter_qualifiers()</code>","text":"<p>Remove all qualifiers from claims in-place.</p> <p>Plain meaning: Strip qualifier detail from claims.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_qualifiers(self) -&gt; None:\n    \"\"\"Remove all qualifiers from claims in-place.\n\n    Plain meaning: Strip qualifier detail from claims.\n    \"\"\"\n\n    for claim in self.claims:\n        claim.qualifiers = []\n\n    claims = self.entity_data.get(\"claims\")\n    if isinstance(claims, dict):\n        for statements in claims.values():\n            if not isinstance(statements, list):\n                continue\n            for statement in statements:\n                if isinstance(statement, dict):\n                    statement.pop(\"qualifiers\", None)\n                    statement.pop(\"qualifiers-order\", None)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.filter_references","title":"<code>filter_references()</code>","text":"<p>Remove all references from claims in-place.</p> <p>Plain meaning: Strip reference detail from claims.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_references(self) -&gt; None:\n    \"\"\"Remove all references from claims in-place.\n\n    Plain meaning: Strip reference detail from claims.\n    \"\"\"\n\n    for claim in self.claims:\n        claim.references = []\n\n    claims = self.entity_data.get(\"claims\")\n    if isinstance(claims, dict):\n        for statements in claims.values():\n            if not isinstance(statements, list):\n                continue\n            for statement in statements:\n                if isinstance(statement, dict):\n                    statement.pop(\"references\", None)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.summary","title":"<code>summary()</code>","text":"<p>Return a summary of the template for display.</p> <p>Plain meaning: Get a quick overview without full details.</p> Source code in <code>gkc/mash.py</code> <pre><code>def summary(self) -&gt; dict[str, Any]:\n    \"\"\"Return a summary of the template for display.\n\n    Plain meaning: Get a quick overview without full details.\n    \"\"\"\n\n    return {\n        \"qid\": self.qid,\n        \"labels\": self.labels,\n        \"descriptions\": self.descriptions,\n        \"total_statements\": len(self.claims),\n        \"aliases\": self.aliases,\n    }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a dictionary.</p> <p>Plain meaning: Convert to a form suitable for JSON export.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to a dictionary.\n\n    Plain meaning: Convert to a form suitable for JSON export.\n    \"\"\"\n\n    return copy.deepcopy(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.to_gkc_entity_profile","title":"<code>to_gkc_entity_profile()</code>","text":"<p>Convert to GKC Entity Profile format.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict representing the GKC Entity Profile.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This transformation is not yet implemented for items.</p> <p>Plain meaning: Transform into a GKC Entity Profile (not yet implemented).</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to GKC Entity Profile format.\n\n    Returns:\n        Dict representing the GKC Entity Profile.\n\n    Raises:\n        NotImplementedError: This transformation is not yet implemented for items.\n\n    Plain meaning: Transform into a GKC Entity Profile (not yet implemented).\n    \"\"\"\n    raise NotImplementedError(\n        \"Item to GKC Entity Profile transformation is not yet implemented. \"\n        \"This will be added in a future version.\"\n    )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.to_qsv1","title":"<code>to_qsv1(for_new_item=False, entity_labels=None)</code>","text":"<p>Convert to QuickStatements V1 format.</p> <p>Parameters:</p> Name Type Description Default <code>for_new_item</code> <code>bool</code> <p>If True, use CREATE/LAST syntax for new items.          If False, use the item's QID for updates.</p> <code>False</code> <code>entity_labels</code> <code>Optional[dict[str, str]]</code> <p>Optional dict mapping entity IDs to labels for comments.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>QuickStatements V1 formatted string.</p> <p>Plain meaning: Export as QuickStatements commands for bulk operations.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_qsv1(\n    self, for_new_item: bool = False, entity_labels: Optional[dict[str, str]] = None\n) -&gt; str:\n    \"\"\"Convert to QuickStatements V1 format.\n\n    Args:\n        for_new_item: If True, use CREATE/LAST syntax for new items.\n                     If False, use the item's QID for updates.\n        entity_labels: Optional dict mapping entity IDs to labels for comments.\n\n    Returns:\n        QuickStatements V1 formatted string.\n\n    Plain meaning: Export as QuickStatements commands for bulk operations.\n    \"\"\"\n    from gkc.mash_formatters import QSV1Formatter\n\n    formatter = QSV1Formatter(entity_labels=entity_labels or {})\n    return formatter.format(self, for_new_item=for_new_item)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.to_shell","title":"<code>to_shell()</code>","text":"<p>Strip identifiers and metadata to create a shell for new item creation.</p> <p>Returns entity data with all system IDs, metadata, and hashes removed, suitable for use as a template for creating new items.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with identifiers stripped, ready for new item creation.</p> <p>Plain meaning: Prepare this template as a clean shell for a new item.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_shell(self) -&gt; dict[str, Any]:\n    \"\"\"Strip identifiers and metadata to create a shell for new item creation.\n\n    Returns entity data with all system IDs, metadata, and hashes removed,\n    suitable for use as a template for creating new items.\n\n    Returns:\n        Dict with identifiers stripped, ready for new item creation.\n\n    Plain meaning: Prepare this template as a clean shell for a new item.\n    \"\"\"\n    return strip_entity_identifiers(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataTemplate.to_simple_dict","title":"<code>to_simple_dict()</code>","text":"<p>Serialize to a simplified dictionary.</p> <p>Plain meaning: Convert to a compact summary structure.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_simple_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to a simplified dictionary.\n\n    Plain meaning: Convert to a compact summary structure.\n    \"\"\"\n\n    return {\n        \"qid\": self.qid,\n        \"labels\": self.labels,\n        \"descriptions\": self.descriptions,\n        \"aliases\": self.aliases,\n        \"claims\": [\n            {\n                \"property_id\": c.property_id,\n                \"value\": c.value,\n                \"qualifiers\": c.qualifiers,\n                \"references\": c.references,\n                \"rank\": c.rank,\n            }\n            for c in self.claims\n        ],\n    }\n</code></pre>"},{"location":"gkc/api/mash/#wikidatapropertytemplate","title":"WikidataPropertyTemplate","text":"<p>An extracted Wikidata property ready for filtering and export.</p> <p>This is the property-specific implementation of the DataTemplate protocol.</p> <p>Plain meaning: A loaded Wikidata property template ready for modification.</p> Source code in <code>gkc/mash.py</code> <pre><code>@dataclass\nclass WikidataPropertyTemplate:\n    \"\"\"An extracted Wikidata property ready for filtering and export.\n\n    This is the property-specific implementation of the DataTemplate protocol.\n\n    Plain meaning: A loaded Wikidata property template ready for modification.\n    \"\"\"\n\n    pid: str\n    labels: dict[str, str]\n    descriptions: dict[str, str]\n    aliases: dict[str, list[str]]\n    datatype: Optional[str]\n    formatter_url: Optional[str]\n    entity_data: dict[str, Any]\n\n    def filter_languages(\n        self, languages: Optional[Union[str, list[str]]] = None\n    ) -&gt; None:\n        \"\"\"Filter labels, descriptions, and aliases to specified languages.\n\n        Args:\n            languages: Either:\n                - A single language code (e.g., \"en\")\n                - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n                - The string \"all\" to keep all languages\n                - None to use the package-level language configuration\n\n        Plain meaning: Keep only the specified language versions.\n        \"\"\"\n        import gkc\n\n        if languages is None:\n            languages = gkc.get_languages()\n\n        # If \"all\", don't filter anything\n        if languages == \"all\":\n            return\n\n        # Convert single string to list for uniform handling\n        if isinstance(languages, str):\n            languages = [languages]\n\n        # Filter each field\n        self.labels = {k: v for k, v in self.labels.items() if k in languages}\n        self.descriptions = {\n            k: v for k, v in self.descriptions.items() if k in languages\n        }\n        self.aliases = {k: v for k, v in self.aliases.items() if k in languages}\n\n        labels = self.entity_data.get(\"labels\")\n        if isinstance(labels, dict):\n            self.entity_data[\"labels\"] = {\n                lang: value for lang, value in labels.items() if lang in languages\n            }\n\n        descriptions = self.entity_data.get(\"descriptions\")\n        if isinstance(descriptions, dict):\n            self.entity_data[\"descriptions\"] = {\n                lang: value for lang, value in descriptions.items() if lang in languages\n            }\n\n        aliases = self.entity_data.get(\"aliases\")\n        if isinstance(aliases, dict):\n            self.entity_data[\"aliases\"] = {\n                lang: value for lang, value in aliases.items() if lang in languages\n            }\n\n    def summary(self) -&gt; dict[str, Any]:\n        \"\"\"Return a summary of the template for display.\n\n        Plain meaning: Get a quick overview without full details.\n        \"\"\"\n        return {\n            \"pid\": self.pid,\n            \"labels\": self.labels,\n            \"descriptions\": self.descriptions,\n            \"datatype\": self.datatype,\n            \"formatter_url\": self.formatter_url,\n            \"aliases\": self.aliases,\n        }\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to a dictionary.\n\n        Plain meaning: Convert to a form suitable for JSON export.\n        \"\"\"\n        return copy.deepcopy(self.entity_data)\n\n    def to_shell(self) -&gt; dict[str, Any]:\n        \"\"\"Strip identifiers and metadata to create a shell for new property creation.\n\n        Returns entity data with all system IDs, metadata, and hashes removed,\n        suitable for use as a template for creating new properties.\n\n        Returns:\n            Dict with identifiers stripped, ready for new property creation.\n\n        Plain meaning: Prepare this template as a clean shell for a new property.\n        \"\"\"\n        return strip_entity_identifiers(self.entity_data)\n\n    def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to GKC Entity Profile format.\n\n        Returns:\n            Dict representing the GKC Entity Profile.\n\n        Raises:\n            NotImplementedError: This transformation is not yet implemented\n                for properties.\n\n        Plain meaning: Transform into a GKC Entity Profile\n            (not yet implemented).\n        \"\"\"\n        raise NotImplementedError(\n            \"Property to GKC Entity Profile transformation is not yet implemented. \"\n            \"This will be added in a future version.\"\n        )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataPropertyTemplate.filter_languages","title":"<code>filter_languages(languages=None)</code>","text":"<p>Filter labels, descriptions, and aliases to specified languages.</p> <p>Parameters:</p> Name Type Description Default <code>languages</code> <code>Optional[Union[str, list[str]]]</code> <p>Either: - A single language code (e.g., \"en\") - A list of language codes (e.g., [\"en\", \"es\", \"fr\"]) - The string \"all\" to keep all languages - None to use the package-level language configuration</p> <code>None</code> <p>Plain meaning: Keep only the specified language versions.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_languages(\n    self, languages: Optional[Union[str, list[str]]] = None\n) -&gt; None:\n    \"\"\"Filter labels, descriptions, and aliases to specified languages.\n\n    Args:\n        languages: Either:\n            - A single language code (e.g., \"en\")\n            - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n            - The string \"all\" to keep all languages\n            - None to use the package-level language configuration\n\n    Plain meaning: Keep only the specified language versions.\n    \"\"\"\n    import gkc\n\n    if languages is None:\n        languages = gkc.get_languages()\n\n    # If \"all\", don't filter anything\n    if languages == \"all\":\n        return\n\n    # Convert single string to list for uniform handling\n    if isinstance(languages, str):\n        languages = [languages]\n\n    # Filter each field\n    self.labels = {k: v for k, v in self.labels.items() if k in languages}\n    self.descriptions = {\n        k: v for k, v in self.descriptions.items() if k in languages\n    }\n    self.aliases = {k: v for k, v in self.aliases.items() if k in languages}\n\n    labels = self.entity_data.get(\"labels\")\n    if isinstance(labels, dict):\n        self.entity_data[\"labels\"] = {\n            lang: value for lang, value in labels.items() if lang in languages\n        }\n\n    descriptions = self.entity_data.get(\"descriptions\")\n    if isinstance(descriptions, dict):\n        self.entity_data[\"descriptions\"] = {\n            lang: value for lang, value in descriptions.items() if lang in languages\n        }\n\n    aliases = self.entity_data.get(\"aliases\")\n    if isinstance(aliases, dict):\n        self.entity_data[\"aliases\"] = {\n            lang: value for lang, value in aliases.items() if lang in languages\n        }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataPropertyTemplate.summary","title":"<code>summary()</code>","text":"<p>Return a summary of the template for display.</p> <p>Plain meaning: Get a quick overview without full details.</p> Source code in <code>gkc/mash.py</code> <pre><code>def summary(self) -&gt; dict[str, Any]:\n    \"\"\"Return a summary of the template for display.\n\n    Plain meaning: Get a quick overview without full details.\n    \"\"\"\n    return {\n        \"pid\": self.pid,\n        \"labels\": self.labels,\n        \"descriptions\": self.descriptions,\n        \"datatype\": self.datatype,\n        \"formatter_url\": self.formatter_url,\n        \"aliases\": self.aliases,\n    }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataPropertyTemplate.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a dictionary.</p> <p>Plain meaning: Convert to a form suitable for JSON export.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to a dictionary.\n\n    Plain meaning: Convert to a form suitable for JSON export.\n    \"\"\"\n    return copy.deepcopy(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataPropertyTemplate.to_gkc_entity_profile","title":"<code>to_gkc_entity_profile()</code>","text":"<p>Convert to GKC Entity Profile format.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict representing the GKC Entity Profile.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>This transformation is not yet implemented for properties.</p> Transform into a GKC Entity Profile <p>(not yet implemented).</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to GKC Entity Profile format.\n\n    Returns:\n        Dict representing the GKC Entity Profile.\n\n    Raises:\n        NotImplementedError: This transformation is not yet implemented\n            for properties.\n\n    Plain meaning: Transform into a GKC Entity Profile\n        (not yet implemented).\n    \"\"\"\n    raise NotImplementedError(\n        \"Property to GKC Entity Profile transformation is not yet implemented. \"\n        \"This will be added in a future version.\"\n    )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataPropertyTemplate.to_shell","title":"<code>to_shell()</code>","text":"<p>Strip identifiers and metadata to create a shell for new property creation.</p> <p>Returns entity data with all system IDs, metadata, and hashes removed, suitable for use as a template for creating new properties.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with identifiers stripped, ready for new property creation.</p> <p>Plain meaning: Prepare this template as a clean shell for a new property.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_shell(self) -&gt; dict[str, Any]:\n    \"\"\"Strip identifiers and metadata to create a shell for new property creation.\n\n    Returns entity data with all system IDs, metadata, and hashes removed,\n    suitable for use as a template for creating new properties.\n\n    Returns:\n        Dict with identifiers stripped, ready for new property creation.\n\n    Plain meaning: Prepare this template as a clean shell for a new property.\n    \"\"\"\n    return strip_entity_identifiers(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#wikidataentityschematemplate","title":"WikidataEntitySchemaTemplate","text":"<p>An extracted Wikidata EntitySchema ready for filtering and export.</p> <p>This is the EntitySchema-specific implementation of the DataTemplate protocol.</p> <p>Plain meaning: A loaded Wikidata EntitySchema template ready for modification.</p> Source code in <code>gkc/mash.py</code> <pre><code>@dataclass\nclass WikidataEntitySchemaTemplate:\n    \"\"\"An extracted Wikidata EntitySchema ready for filtering and export.\n\n    This is the EntitySchema-specific implementation of the DataTemplate protocol.\n\n    Plain meaning: A loaded Wikidata EntitySchema template ready for modification.\n    \"\"\"\n\n    eid: str\n    labels: dict[str, str]\n    descriptions: dict[str, str]\n    schema_text: str\n    entity_data: dict[str, Any]\n\n    def filter_languages(\n        self, languages: Optional[Union[str, list[str]]] = None\n    ) -&gt; None:\n        \"\"\"Filter labels and descriptions to specified languages.\n\n        Args:\n            languages: Either:\n                - A single language code (e.g., \"en\")\n                - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n                - The string \"all\" to keep all languages\n                - None to use the package-level language configuration\n\n        Plain meaning: Keep only the specified language versions.\n        \"\"\"\n        import gkc\n\n        if languages is None:\n            languages = gkc.get_languages()\n\n        # If \"all\", don't filter anything\n        if languages == \"all\":\n            return\n\n        # Convert single string to list for uniform handling\n        if isinstance(languages, str):\n            languages = [languages]\n\n        # Filter each field\n        self.labels = {k: v for k, v in self.labels.items() if k in languages}\n        self.descriptions = {\n            k: v for k, v in self.descriptions.items() if k in languages\n        }\n\n        labels = self.entity_data.get(\"labels\")\n        if isinstance(labels, dict):\n            self.entity_data[\"labels\"] = {\n                lang: value for lang, value in labels.items() if lang in languages\n            }\n\n        descriptions = self.entity_data.get(\"descriptions\")\n        if isinstance(descriptions, dict):\n            self.entity_data[\"descriptions\"] = {\n                lang: value for lang, value in descriptions.items() if lang in languages\n            }\n\n    def summary(self) -&gt; dict[str, Any]:\n        \"\"\"Return a summary of the template for display.\n\n        Plain meaning: Get a quick overview without full details.\n        \"\"\"\n        return {\n            \"eid\": self.eid,\n            \"labels\": self.labels,\n            \"descriptions\": self.descriptions,\n            \"schema_text_length\": len(self.schema_text),\n        }\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to a dictionary.\n\n        Plain meaning: Convert to a form suitable for JSON export.\n        \"\"\"\n        return copy.deepcopy(self.entity_data)\n\n    def to_shell(self) -&gt; dict[str, Any]:\n        \"\"\"Strip identifiers and metadata for new EntitySchema creation.\n\n        Returns entity data with all system IDs and metadata removed,\n        suitable for use as a template for creating new EntitySchemas.\n\n        Returns:\n            Dict with identifiers stripped, ready for new EntitySchema creation.\n\n        Plain meaning: Prepare this template as a clean shell for a new EntitySchema.\n        \"\"\"\n        return strip_entity_identifiers(self.entity_data)\n\n    def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n        \"\"\"Convert to GKC Entity Profile format.\n\n        Returns:\n            Dict representing the GKC Entity Profile.\n\n        Raises:\n            NotImplementedError: EntitySchema to Entity Profile transformation\n                is not yet supported. This functionality will be restored\n                when the new Entity Profile architecture is finalized.\n\n        Plain meaning: Transform into a GKC Entity Profile (not yet supported).\n        \"\"\"\n        raise NotImplementedError(\n            \"EntitySchema to GKC Entity Profile transformation is not yet supported. \"\n            \"This functionality will be restored when the new Entity Profile \"\n            \"architecture is finalized.\"\n        )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataEntitySchemaTemplate.filter_languages","title":"<code>filter_languages(languages=None)</code>","text":"<p>Filter labels and descriptions to specified languages.</p> <p>Parameters:</p> Name Type Description Default <code>languages</code> <code>Optional[Union[str, list[str]]]</code> <p>Either: - A single language code (e.g., \"en\") - A list of language codes (e.g., [\"en\", \"es\", \"fr\"]) - The string \"all\" to keep all languages - None to use the package-level language configuration</p> <code>None</code> <p>Plain meaning: Keep only the specified language versions.</p> Source code in <code>gkc/mash.py</code> <pre><code>def filter_languages(\n    self, languages: Optional[Union[str, list[str]]] = None\n) -&gt; None:\n    \"\"\"Filter labels and descriptions to specified languages.\n\n    Args:\n        languages: Either:\n            - A single language code (e.g., \"en\")\n            - A list of language codes (e.g., [\"en\", \"es\", \"fr\"])\n            - The string \"all\" to keep all languages\n            - None to use the package-level language configuration\n\n    Plain meaning: Keep only the specified language versions.\n    \"\"\"\n    import gkc\n\n    if languages is None:\n        languages = gkc.get_languages()\n\n    # If \"all\", don't filter anything\n    if languages == \"all\":\n        return\n\n    # Convert single string to list for uniform handling\n    if isinstance(languages, str):\n        languages = [languages]\n\n    # Filter each field\n    self.labels = {k: v for k, v in self.labels.items() if k in languages}\n    self.descriptions = {\n        k: v for k, v in self.descriptions.items() if k in languages\n    }\n\n    labels = self.entity_data.get(\"labels\")\n    if isinstance(labels, dict):\n        self.entity_data[\"labels\"] = {\n            lang: value for lang, value in labels.items() if lang in languages\n        }\n\n    descriptions = self.entity_data.get(\"descriptions\")\n    if isinstance(descriptions, dict):\n        self.entity_data[\"descriptions\"] = {\n            lang: value for lang, value in descriptions.items() if lang in languages\n        }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataEntitySchemaTemplate.summary","title":"<code>summary()</code>","text":"<p>Return a summary of the template for display.</p> <p>Plain meaning: Get a quick overview without full details.</p> Source code in <code>gkc/mash.py</code> <pre><code>def summary(self) -&gt; dict[str, Any]:\n    \"\"\"Return a summary of the template for display.\n\n    Plain meaning: Get a quick overview without full details.\n    \"\"\"\n    return {\n        \"eid\": self.eid,\n        \"labels\": self.labels,\n        \"descriptions\": self.descriptions,\n        \"schema_text_length\": len(self.schema_text),\n    }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataEntitySchemaTemplate.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a dictionary.</p> <p>Plain meaning: Convert to a form suitable for JSON export.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to a dictionary.\n\n    Plain meaning: Convert to a form suitable for JSON export.\n    \"\"\"\n    return copy.deepcopy(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataEntitySchemaTemplate.to_gkc_entity_profile","title":"<code>to_gkc_entity_profile()</code>","text":"<p>Convert to GKC Entity Profile format.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict representing the GKC Entity Profile.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>EntitySchema to Entity Profile transformation is not yet supported. This functionality will be restored when the new Entity Profile architecture is finalized.</p> <p>Plain meaning: Transform into a GKC Entity Profile (not yet supported).</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_gkc_entity_profile(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to GKC Entity Profile format.\n\n    Returns:\n        Dict representing the GKC Entity Profile.\n\n    Raises:\n        NotImplementedError: EntitySchema to Entity Profile transformation\n            is not yet supported. This functionality will be restored\n            when the new Entity Profile architecture is finalized.\n\n    Plain meaning: Transform into a GKC Entity Profile (not yet supported).\n    \"\"\"\n    raise NotImplementedError(\n        \"EntitySchema to GKC Entity Profile transformation is not yet supported. \"\n        \"This functionality will be restored when the new Entity Profile \"\n        \"architecture is finalized.\"\n    )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikidataEntitySchemaTemplate.to_shell","title":"<code>to_shell()</code>","text":"<p>Strip identifiers and metadata for new EntitySchema creation.</p> <p>Returns entity data with all system IDs and metadata removed, suitable for use as a template for creating new EntitySchemas.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with identifiers stripped, ready for new EntitySchema creation.</p> <p>Plain meaning: Prepare this template as a clean shell for a new EntitySchema.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_shell(self) -&gt; dict[str, Any]:\n    \"\"\"Strip identifiers and metadata for new EntitySchema creation.\n\n    Returns entity data with all system IDs and metadata removed,\n    suitable for use as a template for creating new EntitySchemas.\n\n    Returns:\n        Dict with identifiers stripped, ready for new EntitySchema creation.\n\n    Plain meaning: Prepare this template as a clean shell for a new EntitySchema.\n    \"\"\"\n    return strip_entity_identifiers(self.entity_data)\n</code></pre>"},{"location":"gkc/api/mash/#wikipedialoader","title":"WikipediaLoader","text":"<p>Load Wikipedia templates from Wikimedia API as templates for editing workflows.</p> <p>This is the Wikipedia-specific implementation of a data loader.</p> <p>Plain meaning: Fetch and parse a Wikipedia template into a usable format.</p> Source code in <code>gkc/mash.py</code> <pre><code>class WikipediaLoader:\n    \"\"\"Load Wikipedia templates from Wikimedia API as templates for editing workflows.\n\n    This is the Wikipedia-specific implementation of a data loader.\n\n    Plain meaning: Fetch and parse a Wikipedia template into a usable format.\n    \"\"\"\n\n    def __init__(self, user_agent: Optional[str] = None):\n        \"\"\"Initialize the loader.\n\n        Args:\n            user_agent: Custom user agent for Wikimedia API requests.\n                       If not provided, a default GKC user agent is used.\n\n        Plain meaning: Set up the loader with optional custom user agent.\n        \"\"\"\n        if user_agent is None:\n            user_agent = \"GKC/1.0 (https://github.com/skybristol/gkc; data integration)\"\n\n        self.user_agent = user_agent\n        self.base_url = \"https://en.wikipedia.org/w/api.php\"\n\n    def load_template(self, template_name: str) -&gt; WikipediaTemplate:\n        \"\"\"Load a Wikipedia template and return it as a template.\n\n        Args:\n            template_name: The Wikipedia template name (e.g., 'Infobox settlement').\n\n        Returns:\n            WikipediaTemplate with the template's structure.\n\n        Raises:\n            RuntimeError: If the template cannot be fetched or parsed.\n\n        Plain meaning: Retrieve the template and return it ready for use.\n\n        Example:\n            &gt;&gt;&gt; loader = WikipediaLoader()\n            &gt;&gt;&gt; template = loader.load_template(\"Infobox settlement\")\n            &gt;&gt;&gt; print(template.summary())\n        \"\"\"\n        # Fetch template data from Wikimedia API\n        params: dict[str, Any] = {\n            \"action\": \"templatedata\",\n            \"format\": \"json\",\n            \"titles\": f\"Template:{template_name}\",\n        }\n\n        try:\n            response = requests.get(\n                self.base_url,\n                params=params,\n                headers={\"User-Agent\": self.user_agent},\n                timeout=10,\n            )\n            response.raise_for_status()\n        except requests.RequestException as exc:\n            raise RuntimeError(\n                f\"Failed to fetch template '{template_name}' from Wikimedia API: {exc}\"\n            ) from exc\n\n        try:\n            data = response.json()\n        except ValueError as exc:\n            raise RuntimeError(\n                f\"Failed to parse JSON response for template '{template_name}': {exc}\"\n            ) from exc\n\n        # Extract pages from response. The templatedata API returns pages directly,\n        # not nested under a \"query\" key like other Mediawiki APIs.\n        pages = data.get(\"pages\", {})\n        if not pages:\n            raise RuntimeError(\n                f\"Template '{template_name}' not found in Wikimedia API response\"\n            )\n\n        # Get the first (and only) page\n        page_data = next(iter(pages.values()))\n\n        # Check if this page has template data\n        if \"notabledescriptions\" in page_data or \"missing\" in page_data:\n            raise RuntimeError(\n                f\"Template '{template_name}' not found or has no template data\"\n            )\n\n        # Extract required fields\n        title = page_data.get(\"title\", template_name)\n\n        # Get description in English, or empty string if not available\n        descriptions = page_data.get(\"description\", {})\n        if isinstance(descriptions, dict):\n            description = descriptions.get(\"en\", \"\")\n        else:\n            description = str(descriptions) if descriptions else \"\"\n\n        params_data = page_data.get(\"params\", {})\n        param_order = page_data.get(\"paramOrder\", [])\n\n        # Build and return the template\n        return WikipediaTemplate(\n            title=title,\n            description=description,\n            params=params_data,\n            param_order=param_order,\n            raw_data=page_data,\n        )\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikipediaLoader.__init__","title":"<code>__init__(user_agent=None)</code>","text":"<p>Initialize the loader.</p> <p>Parameters:</p> Name Type Description Default <code>user_agent</code> <code>Optional[str]</code> <p>Custom user agent for Wikimedia API requests.        If not provided, a default GKC user agent is used.</p> <code>None</code> <p>Plain meaning: Set up the loader with optional custom user agent.</p> Source code in <code>gkc/mash.py</code> <pre><code>def __init__(self, user_agent: Optional[str] = None):\n    \"\"\"Initialize the loader.\n\n    Args:\n        user_agent: Custom user agent for Wikimedia API requests.\n                   If not provided, a default GKC user agent is used.\n\n    Plain meaning: Set up the loader with optional custom user agent.\n    \"\"\"\n    if user_agent is None:\n        user_agent = \"GKC/1.0 (https://github.com/skybristol/gkc; data integration)\"\n\n    self.user_agent = user_agent\n    self.base_url = \"https://en.wikipedia.org/w/api.php\"\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikipediaLoader.load_template","title":"<code>load_template(template_name)</code>","text":"<p>Load a Wikipedia template and return it as a template.</p> <p>Parameters:</p> Name Type Description Default <code>template_name</code> <code>str</code> <p>The Wikipedia template name (e.g., 'Infobox settlement').</p> required <p>Returns:</p> Type Description <code>WikipediaTemplate</code> <p>WikipediaTemplate with the template's structure.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the template cannot be fetched or parsed.</p> <p>Plain meaning: Retrieve the template and return it ready for use.</p> Example <p>loader = WikipediaLoader() template = loader.load_template(\"Infobox settlement\") print(template.summary())</p> Source code in <code>gkc/mash.py</code> <pre><code>def load_template(self, template_name: str) -&gt; WikipediaTemplate:\n    \"\"\"Load a Wikipedia template and return it as a template.\n\n    Args:\n        template_name: The Wikipedia template name (e.g., 'Infobox settlement').\n\n    Returns:\n        WikipediaTemplate with the template's structure.\n\n    Raises:\n        RuntimeError: If the template cannot be fetched or parsed.\n\n    Plain meaning: Retrieve the template and return it ready for use.\n\n    Example:\n        &gt;&gt;&gt; loader = WikipediaLoader()\n        &gt;&gt;&gt; template = loader.load_template(\"Infobox settlement\")\n        &gt;&gt;&gt; print(template.summary())\n    \"\"\"\n    # Fetch template data from Wikimedia API\n    params: dict[str, Any] = {\n        \"action\": \"templatedata\",\n        \"format\": \"json\",\n        \"titles\": f\"Template:{template_name}\",\n    }\n\n    try:\n        response = requests.get(\n            self.base_url,\n            params=params,\n            headers={\"User-Agent\": self.user_agent},\n            timeout=10,\n        )\n        response.raise_for_status()\n    except requests.RequestException as exc:\n        raise RuntimeError(\n            f\"Failed to fetch template '{template_name}' from Wikimedia API: {exc}\"\n        ) from exc\n\n    try:\n        data = response.json()\n    except ValueError as exc:\n        raise RuntimeError(\n            f\"Failed to parse JSON response for template '{template_name}': {exc}\"\n        ) from exc\n\n    # Extract pages from response. The templatedata API returns pages directly,\n    # not nested under a \"query\" key like other Mediawiki APIs.\n    pages = data.get(\"pages\", {})\n    if not pages:\n        raise RuntimeError(\n            f\"Template '{template_name}' not found in Wikimedia API response\"\n        )\n\n    # Get the first (and only) page\n    page_data = next(iter(pages.values()))\n\n    # Check if this page has template data\n    if \"notabledescriptions\" in page_data or \"missing\" in page_data:\n        raise RuntimeError(\n            f\"Template '{template_name}' not found or has no template data\"\n        )\n\n    # Extract required fields\n    title = page_data.get(\"title\", template_name)\n\n    # Get description in English, or empty string if not available\n    descriptions = page_data.get(\"description\", {})\n    if isinstance(descriptions, dict):\n        description = descriptions.get(\"en\", \"\")\n    else:\n        description = str(descriptions) if descriptions else \"\"\n\n    params_data = page_data.get(\"params\", {})\n    param_order = page_data.get(\"paramOrder\", [])\n\n    # Build and return the template\n    return WikipediaTemplate(\n        title=title,\n        description=description,\n        params=params_data,\n        param_order=param_order,\n        raw_data=page_data,\n    )\n</code></pre>"},{"location":"gkc/api/mash/#wikipediatemplate","title":"WikipediaTemplate","text":"<p>A Wikipedia template loaded from Wikimedia API for use in Wikipedia editing.</p> <p>This is the Wikipedia-specific implementation of the DataTemplate protocol.</p> <p>Plain meaning: A loaded Wikipedia template ready for display and use in editing workflows.</p> Source code in <code>gkc/mash.py</code> <pre><code>@dataclass\nclass WikipediaTemplate:\n    \"\"\"A Wikipedia template loaded from Wikimedia API for use in Wikipedia editing.\n\n    This is the Wikipedia-specific implementation of the DataTemplate protocol.\n\n    Plain meaning: A loaded Wikipedia template ready for display and use\n    in editing workflows.\n    \"\"\"\n\n    title: str\n    description: str\n    params: dict[str, Any]\n    param_order: list[str]\n    raw_data: dict[str, Any]\n\n    def summary(self) -&gt; dict[str, Any]:\n        \"\"\"Return a summary of the template for display.\n\n        Returns:\n            Dict with title, description, and number of parameters.\n\n        Plain meaning: Get a quick overview without full details.\n        \"\"\"\n        return {\n            \"title\": self.title,\n            \"description\": self.description,\n            \"param_count\": len(self.params),\n        }\n\n    def to_dict(self) -&gt; dict[str, Any]:\n        \"\"\"Serialize to a dictionary.\n\n        Returns:\n            Dict containing title, description, params, and paramOrder.\n\n        Plain meaning: Convert to a form suitable for JSON export.\n        \"\"\"\n        return {\n            \"title\": self.title,\n            \"description\": self.description,\n            \"params\": self.params,\n            \"paramOrder\": self.param_order,\n        }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikipediaTemplate.summary","title":"<code>summary()</code>","text":"<p>Return a summary of the template for display.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict with title, description, and number of parameters.</p> <p>Plain meaning: Get a quick overview without full details.</p> Source code in <code>gkc/mash.py</code> <pre><code>def summary(self) -&gt; dict[str, Any]:\n    \"\"\"Return a summary of the template for display.\n\n    Returns:\n        Dict with title, description, and number of parameters.\n\n    Plain meaning: Get a quick overview without full details.\n    \"\"\"\n    return {\n        \"title\": self.title,\n        \"description\": self.description,\n        \"param_count\": len(self.params),\n    }\n</code></pre>"},{"location":"gkc/api/mash/#gkc.mash.WikipediaTemplate.to_dict","title":"<code>to_dict()</code>","text":"<p>Serialize to a dictionary.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dict containing title, description, params, and paramOrder.</p> <p>Plain meaning: Convert to a form suitable for JSON export.</p> Source code in <code>gkc/mash.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Serialize to a dictionary.\n\n    Returns:\n        Dict containing title, description, params, and paramOrder.\n\n    Plain meaning: Convert to a form suitable for JSON export.\n    \"\"\"\n    return {\n        \"title\": self.title,\n        \"description\": self.description,\n        \"params\": self.params,\n        \"paramOrder\": self.param_order,\n    }\n</code></pre>"},{"location":"gkc/api/mash/#utility-functions","title":"Utility Functions","text":""},{"location":"gkc/api/mash/#strip_entity_identifiers","title":"strip_entity_identifiers()","text":"<p>Return a copy of entity data with identifiers stripped for new-item use.</p> <p>Removes fields that prevent using the JSON as a new item template: - Item-level: id, pageid, lastrevid, modified, ns, title - Statement-level: id (statement GUID) - Snak-level: hash (in mainsnak, qualifiers, and references)</p> <p>Plain meaning: Remove IDs that prevent using the JSON as a new item template.</p> Source code in <code>gkc/mash.py</code> <pre><code>def strip_entity_identifiers(entity_data: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Return a copy of entity data with identifiers stripped for new-item use.\n\n    Removes fields that prevent using the JSON as a new item template:\n    - Item-level: id, pageid, lastrevid, modified, ns, title\n    - Statement-level: id (statement GUID)\n    - Snak-level: hash (in mainsnak, qualifiers, and references)\n\n    Plain meaning: Remove IDs that prevent using the JSON as a new item template.\n    \"\"\"\n\n    cleaned = copy.deepcopy(entity_data)\n\n    # Remove item-level identifiers and metadata\n    cleaned.pop(\"id\", None)\n    cleaned.pop(\"pageid\", None)\n    cleaned.pop(\"lastrevid\", None)\n    cleaned.pop(\"modified\", None)\n    cleaned.pop(\"ns\", None)\n    cleaned.pop(\"title\", None)\n\n    # Remove statement-level identifiers and hashes\n    claims = cleaned.get(\"claims\")\n    if isinstance(claims, dict):\n        for statements in claims.values():\n            if not isinstance(statements, list):\n                continue\n            for statement in statements:\n                if isinstance(statement, dict):\n                    statement.pop(\"id\", None)\n\n                    # Remove hash from mainsnak\n                    mainsnak = statement.get(\"mainsnak\")\n                    if isinstance(mainsnak, dict):\n                        mainsnak.pop(\"hash\", None)\n\n                    # Remove hash from qualifiers\n                    qualifiers = statement.get(\"qualifiers\")\n                    if isinstance(qualifiers, dict):\n                        for qualifier_snaks in qualifiers.values():\n                            if isinstance(qualifier_snaks, list):\n                                for snak in qualifier_snaks:\n                                    if isinstance(snak, dict):\n                                        snak.pop(\"hash\", None)\n\n                    # Remove hash from references\n                    references = statement.get(\"references\")\n                    if isinstance(references, list):\n                        for reference in references:\n                            if isinstance(reference, dict):\n                                reference.pop(\"hash\", None)\n                                ref_snaks = reference.get(\"snaks\")\n                                if isinstance(ref_snaks, dict):\n                                    for ref_snak_list in ref_snaks.values():\n                                        if isinstance(ref_snak_list, list):\n                                            for snak in ref_snak_list:\n                                                if isinstance(snak, dict):\n                                                    snak.pop(\"hash\", None)\n\n    return cleaned\n</code></pre>"},{"location":"gkc/api/mash/#fetch_property_labels","title":"fetch_property_labels()","text":"<p>Fetch human-readable labels for Wikidata properties using SPARQL.</p> <p>Parameters:</p> Name Type Description Default <code>property_ids</code> <code>list[str]</code> <p>List of property IDs (e.g., ['P31', 'P21']).</p> required <code>language</code> <code>Optional[str]</code> <p>Language code for labels (defaults to package configuration).</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dict mapping property IDs to their labels (e.g., {'P31': 'instance of'}).</p> <p>Plain meaning: Look up property names efficiently to make QS output more readable.</p> Source code in <code>gkc/mash.py</code> <pre><code>def fetch_property_labels(\n    property_ids: list[str], language: Optional[str] = None\n) -&gt; dict[str, str]:\n    \"\"\"Fetch human-readable labels for Wikidata properties using SPARQL.\n\n    Args:\n        property_ids: List of property IDs (e.g., ['P31', 'P21']).\n        language: Language code for labels (defaults to package configuration).\n\n    Returns:\n        Dict mapping property IDs to their labels (e.g., {'P31': 'instance of'}).\n\n    Plain meaning: Look up property names efficiently to make QS output more readable.\n    \"\"\"\n    if not property_ids:\n        return {}\n    if language is None:\n        import gkc\n\n        languages = gkc.get_languages()\n        if languages == \"all\":\n            language = \"en\"\n        elif isinstance(languages, str):\n            language = languages\n        else:\n            language = languages[0] if languages else \"en\"\n    return fetch_entity_labels(property_ids, languages=[language])\n</code></pre>"},{"location":"gkc/api/mash/#data-classes","title":"Data Classes","text":""},{"location":"gkc/api/mash/#claimsummary","title":"ClaimSummary","text":"<p>Simplified representation of a Wikidata claim for display and export.</p> <p>Plain meaning: A simple view of a claim without requiring RDF knowledge.</p> Source code in <code>gkc/mash.py</code> <pre><code>@dataclass\nclass ClaimSummary:\n    \"\"\"Simplified representation of a Wikidata claim for display and export.\n\n    Plain meaning: A simple view of a claim without requiring RDF knowledge.\n    \"\"\"\n\n    property_id: str\n    value: str\n    qualifiers: list[dict] = field(default_factory=list)\n    references: list[dict] = field(default_factory=list)\n    rank: str = \"normal\"\n    value_metadata: Optional[dict[str, Any]] = None\n</code></pre>"},{"location":"gkc/api/mash/#examples","title":"Examples","text":""},{"location":"gkc/api/mash/#load-and-filter-a-wikidata-item","title":"Load and filter a Wikidata item","text":"<pre><code>from gkc.mash import WikidataLoader\n\n# Initialize the loader\nloader = WikidataLoader()\n\n# Load an item\ntemplate = loader.load_item(\"Q42\")  # Douglas Adams\n\n# Filter to English only\ntemplate.filter_languages(\"en\")\n\n# Exclude certain properties\ntemplate.filter_properties(exclude_properties=[\"P18\", \"P373\"])\n\n# Remove qualifiers and references for simplicity\ntemplate.filter_qualifiers()\ntemplate.filter_references()\n\n# Get a summary\nsummary = template.summary()\nprint(f\"Loaded {summary['qid']}: {summary['labels']}\")\nprint(f\"Total statements: {summary['total_statements']}\")\n</code></pre>"},{"location":"gkc/api/mash/#load-multiple-items-in-batch","title":"Load multiple items in batch","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\n# Load multiple items efficiently\nqids = [\"Q42\", \"Q5\", \"Q30\", \"Q515\"]\ntemplates = loader.load_items(qids)\n\nfor qid, template in templates.items():\n    print(f\"{qid}: {template.labels.get('en', 'No label')}\")\n</code></pre>"},{"location":"gkc/api/mash/#prepare-entity-data-for-new-item-creation","title":"Prepare entity data for new item creation","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\n# Load an item\ntemplate = loader.load_item(\"Q42\")\n\n# Strip identifiers to prepare for creating a new item\nnew_item_data = template.to_shell()\n\n# Now you can modify labels, claims, etc. and use this for a new item\nimport json\nprint(json.dumps(new_item_data, indent=2))\n</code></pre>"},{"location":"gkc/api/mash/#convert-item-to-quickstatements-format","title":"Convert item to QuickStatements format","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\ntemplate = loader.load_item(\"Q42\")\n\n# For updating existing item\nqs_update = template.to_qsv1(for_new_item=False)\nprint(qs_update)\n\n# For creating new item (uses CREATE/LAST syntax)\nqs_new = template.to_qsv1(for_new_item=True)\nprint(qs_new)\n\n# With entity labels as comments\nentity_labels = {\"P31\": \"instance of\", \"Q5\": \"human\"}\nqs_labeled = template.to_qsv1(entity_labels=entity_labels)\n</code></pre>"},{"location":"gkc/api/mash/#load-and-work-with-properties","title":"Load and work with properties","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\n# Load a single property\nprop = loader.load_property(\"P31\")\nprint(f\"Datatype: {prop.datatype}\")\nprint(f\"Labels: {prop.labels}\")\n\n# Load multiple properties in batch\npids = [\"P31\", \"P279\", \"P21\"]\nprops = loader.load_properties(pids)\n\nfor pid, prop in props.items():\n    print(f\"{pid}: {prop.labels.get('en')} ({prop.datatype})\")\n</code></pre>"},{"location":"gkc/api/mash/#load-and-transform-entityschemas","title":"Load and transform EntitySchemas","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\n# Load an EntitySchema\nschema = loader.load_entity_schema(\"E502\")\nprint(f\"Schema: {schema.labels.get('en')}\")\nprint(f\"ShEx text length: {len(schema.schema_text)}\")\n\n# Convert to GKC Entity Profile\nprofile = schema.to_gkc_entity_profile()\nprint(profile)\n</code></pre>"},{"location":"gkc/api/mash/#fetch-descriptors-for-mixed-entities","title":"Fetch descriptors for mixed entities","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\n# Get labels and descriptions for a mix of items and properties\nentity_ids = [\"Q42\", \"P31\", \"Q5\", \"P279\"]\ndescriptors = loader.fetch_descriptors(entity_ids)\n\nfor eid, info in descriptors.items():\n    label = info[\"labels\"].get(\"en\", \"No label\")\n    desc = info[\"descriptions\"].get(\"en\", \"No description\")\n    print(f\"{eid}: {label} - {desc}\")\n</code></pre>"},{"location":"gkc/api/mash/#work-with-multiple-language-versions","title":"Work with multiple language versions","text":"<pre><code>from gkc.mash import WikidataLoader\nimport gkc\n\n# Set package-level language configuration\ngkc.set_languages([\"en\", \"es\", \"fr\"])\n\nloader = WikidataLoader()\ntemplate = loader.load_item(\"Q42\")\n\n# Filter using package configuration\ntemplate.filter_languages()  # Uses package setting\n\n# Or specify explicitly\ntemplate.filter_languages([\"en\", \"de\"])\n\n# Keep all languages\ntemplate.filter_languages(\"all\")\n</code></pre>"},{"location":"gkc/api/mash/#load-with-custom-user-agent","title":"Load with custom user agent","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader(\n    user_agent=\"MyBot/1.0 (https://example.com; user@example.com)\"\n)\n\ntemplate = loader.load_item(\"Q42\")\n</code></pre>"},{"location":"gkc/api/mash/#load-and-examine-a-wikipedia-template","title":"Load and examine a Wikipedia template","text":"<pre><code>from gkc.mash import WikipediaLoader\n\n# Initialize the loader for en.wikipedia.org\nloader = WikipediaLoader()\n\n# Load a Wikipedia template\ntemplate = loader.load_template(\"Infobox settlement\")\n\n# Get a quick summary\nsummary = template.summary()\nprint(f\"Template: {summary['title']}\")\nprint(f\"Description: {summary['description']}\")\nprint(f\"Parameters: {summary['param_count']}\")\n\n# Get the full template structure\nfull_data = template.to_dict()\nfor param_name in template.param_order[:5]:  # First 5 parameters\n    param_info = template.params.get(param_name, {})\n    label = param_info.get(\"label\", {}).get(\"en\", param_name)\n    print(f\"  - {param_name}: {label}\")\n</code></pre>"},{"location":"gkc/api/mash/#transformation-methods","title":"Transformation Methods","text":"<p>All template types support transformation methods for different output formats:</p>"},{"location":"gkc/api/mash/#to_dict","title":"to_dict()","text":"<p>Returns the raw Wikidata JSON structure, preserving all identifiers. Use this for round-trip processing where you need to preserve the exact structure.</p>"},{"location":"gkc/api/mash/#to_shell","title":"to_shell()","text":"<p>Strips all identifiers, hashes, and metadata from the entity data, creating a clean template for new entity creation. Removes: <code>id</code>, <code>pageid</code>, <code>lastrevid</code>, <code>modified</code>, <code>ns</code>, <code>title</code>, statement IDs, and all hashes.</p>"},{"location":"gkc/api/mash/#to_qsv1-items-only","title":"to_qsv1() (Items only)","text":"<p>Converts item templates to QuickStatements V1 format for bulk operations. Supports both update mode (uses QID) and creation mode (uses CREATE/LAST).</p>"},{"location":"gkc/api/mash/#to_gkc_entity_profile-entityschemas-only","title":"to_gkc_entity_profile() (EntitySchemas only)","text":"<p>Converts EntitySchema templates to GKC Entity Profile format. This transformation is implemented for EntitySchemas and will be added for items and properties in future versions.</p>"},{"location":"gkc/api/mash/#error-handling","title":"Error Handling","text":""},{"location":"gkc/api/mash/#entity-not-found","title":"Entity not found","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\ntry:\n    template = loader.load_item(\"Q999999999999\")\nexcept RuntimeError as e:\n    print(f\"Error: {e}\")\n    # Error: no-such-entity: Q999999999999 not found on Wikidata\n</code></pre>"},{"location":"gkc/api/mash/#network-errors","title":"Network errors","text":"<pre><code>from gkc.mash import WikidataLoader\n\nloader = WikidataLoader()\n\ntry:\n    template = loader.load_item(\"Q42\")\nexcept RuntimeError as e:\n    print(f\"Failed to fetch item: {e}\")\n</code></pre>"},{"location":"gkc/api/mash/#migration-from-previous-version","title":"Migration from Previous Version","text":"<p>The mash module has been refactored for consistency across entity types. Key changes:</p> <ul> <li><code>WikidataLoader.load(qid)</code> is now <code>WikidataLoader.load_item(qid)</code> (old method still works but is deprecated)</li> <li><code>strip_entity_identifiers()</code> now also removes <code>ns</code> and <code>title</code> fields</li> <li>New batch loading: <code>load_items()</code>, <code>load_properties()</code></li> <li>New entity types: <code>load_property()</code>, <code>load_entity_schema()</code></li> <li>Transformation methods moved to template objects: <code>template.to_shell()</code>, <code>template.to_qsv1()</code></li> </ul>"},{"location":"gkc/api/mash/#see-also","title":"See Also","text":"<ul> <li>Mash CLI - Command-line interface for mash operations</li> <li>Mash Formatters API - Convert templates to output formats</li> <li>Recipe API - Build validation recipes from EntitySchemas</li> </ul>"},{"location":"gkc/api/mash_formatters/","title":"Mash Formatters API","text":""},{"location":"gkc/api/mash_formatters/#overview","title":"Overview","text":"<p>Convert Wikidata templates to different output formats for bulk editing, validation, or export. Currently supports QuickStatements V1 format for creating and updating items on Wikidata.</p>"},{"location":"gkc/api/mash_formatters/#quick-start","title":"Quick Start","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\n# Load a template\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Format for new item creation\nformatter = QSV1Formatter()\nqs_text = formatter.format(template, for_new_item=True)\nprint(qs_text)\n</code></pre>"},{"location":"gkc/api/mash_formatters/#classes","title":"Classes","text":""},{"location":"gkc/api/mash_formatters/#qsv1formatter","title":"QSV1Formatter","text":"<p>Format a WikidataTemplate as QuickStatements V1 syntax.</p> <p>Plain meaning: Convert a template to bulk-edit format for Wikidata.</p> Source code in <code>gkc/mash_formatters.py</code> <pre><code>class QSV1Formatter:\n    \"\"\"Format a WikidataTemplate as QuickStatements V1 syntax.\n\n    Plain meaning: Convert a template to bulk-edit format for Wikidata.\n    \"\"\"\n\n    def __init__(\n        self,\n        exclude_properties: list[str] | None = None,\n        exclude_qualifiers: bool = False,\n        exclude_references: bool = False,\n        entity_labels: dict[str, str] | None = None,\n    ):\n        \"\"\"Initialize the formatter.\n\n        Args:\n            exclude_properties: List of property IDs to skip (e.g., ['P31']).\n            exclude_qualifiers: If True, omit all qualifiers.\n            exclude_references: If True, omit all references.\n            entity_labels: Dict mapping entity IDs (properties and items) to labels\n                          (e.g., {'P31': 'instance of', 'Q5': 'human'}) for comments.\n\n        Plain meaning: Configure what to include or exclude from output.\n        \"\"\"\n\n        self.exclude_properties = exclude_properties or []\n        self.exclude_qualifiers = exclude_qualifiers\n        self.exclude_references = exclude_references\n        self.entity_labels = entity_labels or {}\n\n    def format(self, template: WikidataTemplate, for_new_item: bool = True) -&gt; str:\n        \"\"\"Convert template to QuickStatements V1 format.\n\n        Args:\n            template: The WikidataTemplate to format.\n            for_new_item: If True, use \"CREATE\" and \"LAST\" syntax for new items.\n                         If False, use the QID and \"P\" syntax for updates.\n\n        Returns:\n            QuickStatements V1 text.\n\n        Plain meaning: Generate editable QS text from the template.\n        \"\"\"\n\n        lines: list[str] = []\n\n        if for_new_item:\n            lines.append(\"CREATE\")\n            # Add labels and descriptions\n            for lang, text in template.labels.items():\n                lines.append(f'LAST\\tL{lang}\\t\"{text}\"')\n\n            for lang, text in template.descriptions.items():\n                lines.append(f'LAST\\tD{lang}\\t\"{text}\"')\n\n            # Add aliases\n            for lang, alias_list in template.aliases.items():\n                for alias in alias_list:\n                    lines.append(f'LAST\\tA{lang}\\t\"{alias}\"')\n\n            # Add claims with inline comments\n            for claim in template.claims:\n                if claim.property_id in self.exclude_properties:\n                    continue\n\n                line = self._claim_to_qs_line(\"LAST\", claim)\n                if line:\n                    lines.append(line)\n        else:\n            # For existing items\n            qid = template.qid\n            for lang, text in template.labels.items():\n                lines.append(f'{qid}\\t{lang}\\t\"{text}\"')\n\n            for lang, text in template.descriptions.items():\n                lines.append(f'{qid}\\tDn\\t\"{text}\"')\n\n            for claim in template.claims:\n                if claim.property_id in self.exclude_properties:\n                    continue\n\n                line = self._claim_to_qs_line(qid, claim)\n                if line:\n                    lines.append(line)\n\n        return \"\\n\".join(lines)\n\n    def _claim_to_qs_line(self, subject: str, claim) -&gt; str:\n        \"\"\"Convert a single claim to a QS V1 line with optional comment.\n\n        QuickStatements V1 format for qualifiers and references:\n        - Qualifiers: P1|Q2|P3|Q4 (with pipes separating property-value pairs)\n        - References: S248|Q123 (source), S854|http://... (reference URL)\n        - Comments: /* comment text */ at end of line\n        - Time values with precision: +2001-01-15T00:00:00Z/11\n          (where /11 is day precision)\n\n        Plain meaning: Format one statement with qualifiers/references/comments.\n        \"\"\"\n\n        # Format the main value with metadata (e.g., precision for dates)\n        value_str = claim.value\n        if hasattr(claim, \"value_metadata\") and claim.value_metadata:\n            if \"precision\" in claim.value_metadata:\n                precision = claim.value_metadata[\"precision\"]\n                value_str = f\"{claim.value}/{precision}\"\n\n        parts: list[str] = [subject, claim.property_id, value_str]\n\n        # Build comment parts for main claim\n        comment_parts: list[str] = []\n        if self.entity_labels:\n            prop_label = self.entity_labels.get(claim.property_id)\n            if prop_label:\n                # Check if value is an entity (Q-ID) or other type\n                if claim.value.startswith(\"Q\") and claim.value[1:].isdigit():\n                    value_label = self.entity_labels.get(claim.value, claim.value)\n                    comment_parts.append(f\"{prop_label} is {value_label}\")\n                else:\n                    # For non-entity values (strings, dates, etc.), show the value\n                    comment_parts.append(f\"{prop_label} is {claim.value}\")\n\n        # Add qualifiers on the same line, separated by pipes\n        if not self.exclude_qualifiers and claim.qualifiers:\n            for qual in claim.qualifiers:\n                prop = qual.get(\"property\", \"\")\n                value = qual.get(\"value\", \"\")\n                if prop and value:\n                    # Format qualifier value with metadata if present\n                    qual_value_str = value\n                    if \"metadata\" in qual and qual[\"metadata\"]:\n                        if \"precision\" in qual[\"metadata\"]:\n                            precision = qual[\"metadata\"][\"precision\"]\n                            qual_value_str = f\"{value}/{precision}\"\n\n                    parts.append(prop)\n                    parts.append(qual_value_str)\n\n                    if self.entity_labels:\n                        qual_prop_label = self.entity_labels.get(prop)\n                        if qual_prop_label:\n                            if value.startswith(\"Q\") and value[1:].isdigit():\n                                qual_value_label = self.entity_labels.get(value, value)\n                                comment_parts.append(\n                                    f\"{qual_prop_label} is {qual_value_label}\"\n                                )\n                            else:\n                                comment_parts.append(f\"{qual_prop_label} is {value}\")\n\n        # Add references on the same line, separated by pipes\n        # References in QS V1 use S prefix (e.g., S248 for 'stated in')\n        # For now, we'll skip complex reference formatting\n        # A full implementation would parse and reconstruct reference data\n        if not self.exclude_references and claim.references:\n            pass\n\n        # Build final line with optional comment\n        line = \"\\t\".join(parts)\n        if comment_parts:\n            comment = \"; \".join(comment_parts)\n            line += f\"\\t/* {comment} */\"\n\n        return line\n</code></pre>"},{"location":"gkc/api/mash_formatters/#gkc.mash_formatters.QSV1Formatter.__init__","title":"<code>__init__(exclude_properties=None, exclude_qualifiers=False, exclude_references=False, entity_labels=None)</code>","text":"<p>Initialize the formatter.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_properties</code> <code>list[str] | None</code> <p>List of property IDs to skip (e.g., ['P31']).</p> <code>None</code> <code>exclude_qualifiers</code> <code>bool</code> <p>If True, omit all qualifiers.</p> <code>False</code> <code>exclude_references</code> <code>bool</code> <p>If True, omit all references.</p> <code>False</code> <code>entity_labels</code> <code>dict[str, str] | None</code> <p>Dict mapping entity IDs (properties and items) to labels           (e.g., {'P31': 'instance of', 'Q5': 'human'}) for comments.</p> <code>None</code> <p>Plain meaning: Configure what to include or exclude from output.</p> Source code in <code>gkc/mash_formatters.py</code> <pre><code>def __init__(\n    self,\n    exclude_properties: list[str] | None = None,\n    exclude_qualifiers: bool = False,\n    exclude_references: bool = False,\n    entity_labels: dict[str, str] | None = None,\n):\n    \"\"\"Initialize the formatter.\n\n    Args:\n        exclude_properties: List of property IDs to skip (e.g., ['P31']).\n        exclude_qualifiers: If True, omit all qualifiers.\n        exclude_references: If True, omit all references.\n        entity_labels: Dict mapping entity IDs (properties and items) to labels\n                      (e.g., {'P31': 'instance of', 'Q5': 'human'}) for comments.\n\n    Plain meaning: Configure what to include or exclude from output.\n    \"\"\"\n\n    self.exclude_properties = exclude_properties or []\n    self.exclude_qualifiers = exclude_qualifiers\n    self.exclude_references = exclude_references\n    self.entity_labels = entity_labels or {}\n</code></pre>"},{"location":"gkc/api/mash_formatters/#gkc.mash_formatters.QSV1Formatter.format","title":"<code>format(template, for_new_item=True)</code>","text":"<p>Convert template to QuickStatements V1 format.</p> <p>Parameters:</p> Name Type Description Default <code>template</code> <code>WikidataTemplate</code> <p>The WikidataTemplate to format.</p> required <code>for_new_item</code> <code>bool</code> <p>If True, use \"CREATE\" and \"LAST\" syntax for new items.          If False, use the QID and \"P\" syntax for updates.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>QuickStatements V1 text.</p> <p>Plain meaning: Generate editable QS text from the template.</p> Source code in <code>gkc/mash_formatters.py</code> <pre><code>def format(self, template: WikidataTemplate, for_new_item: bool = True) -&gt; str:\n    \"\"\"Convert template to QuickStatements V1 format.\n\n    Args:\n        template: The WikidataTemplate to format.\n        for_new_item: If True, use \"CREATE\" and \"LAST\" syntax for new items.\n                     If False, use the QID and \"P\" syntax for updates.\n\n    Returns:\n        QuickStatements V1 text.\n\n    Plain meaning: Generate editable QS text from the template.\n    \"\"\"\n\n    lines: list[str] = []\n\n    if for_new_item:\n        lines.append(\"CREATE\")\n        # Add labels and descriptions\n        for lang, text in template.labels.items():\n            lines.append(f'LAST\\tL{lang}\\t\"{text}\"')\n\n        for lang, text in template.descriptions.items():\n            lines.append(f'LAST\\tD{lang}\\t\"{text}\"')\n\n        # Add aliases\n        for lang, alias_list in template.aliases.items():\n            for alias in alias_list:\n                lines.append(f'LAST\\tA{lang}\\t\"{alias}\"')\n\n        # Add claims with inline comments\n        for claim in template.claims:\n            if claim.property_id in self.exclude_properties:\n                continue\n\n            line = self._claim_to_qs_line(\"LAST\", claim)\n            if line:\n                lines.append(line)\n    else:\n        # For existing items\n        qid = template.qid\n        for lang, text in template.labels.items():\n            lines.append(f'{qid}\\t{lang}\\t\"{text}\"')\n\n        for lang, text in template.descriptions.items():\n            lines.append(f'{qid}\\tDn\\t\"{text}\"')\n\n        for claim in template.claims:\n            if claim.property_id in self.exclude_properties:\n                continue\n\n            line = self._claim_to_qs_line(qid, claim)\n            if line:\n                lines.append(line)\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"gkc/api/mash_formatters/#examples","title":"Examples","text":""},{"location":"gkc/api/mash_formatters/#format-for-new-item-creation","title":"Format for new item creation","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Filter to simplify output\ntemplate.filter_languages(\"en\")\ntemplate.filter_properties([\"P18\", \"P373\"])  # Exclude images\n\n# Format with CREATE/LAST syntax\nformatter = QSV1Formatter()\nqs_text = formatter.format(template, for_new_item=True)\n\nprint(qs_text)\n# CREATE\n# LAST  Len \"Douglas Adams\"\n# LAST  Den \"English science fiction writer\"\n# LAST  P31 Q5\n# ...\n</code></pre>"},{"location":"gkc/api/mash_formatters/#format-for-updating-existing-item","title":"Format for updating existing item","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Format with QID syntax for updates\nformatter = QSV1Formatter()\nqs_text = formatter.format(template, for_new_item=False)\n\nprint(qs_text)\n# Q42   en  \"Douglas Adams\"\n# Q42   Dn  \"English science fiction writer\"\n# Q42   P31 Q5\n# ...\n</code></pre>"},{"location":"gkc/api/mash_formatters/#add-human-readable-comments","title":"Add human-readable comments","text":"<pre><code>from gkc.mash import WikidataLoader, fetch_property_labels\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Collect all property and item IDs\nentity_ids = set()\nfor claim in template.claims:\n    entity_ids.add(claim.property_id)\n    if claim.value.startswith(\"Q\"):\n        entity_ids.add(claim.value)\n\n# Fetch labels for comments\nfrom gkc.sparql import fetch_entity_labels\nentity_labels = fetch_entity_labels(list(entity_ids), languages=[\"en\"])\n\n# Format with inline comments\nformatter = QSV1Formatter(entity_labels=entity_labels)\nqs_text = formatter.format(template, for_new_item=True)\n\nprint(qs_text)\n# CREATE\n# LAST  Len \"Douglas Adams\"\n# LAST  Den \"English science fiction writer\"\n# LAST  P31 Q5  /* instance of is human */\n# LAST  P21 Q6581097    /* sex or gender is male */\n# ...\n</code></pre>"},{"location":"gkc/api/mash_formatters/#exclude-qualifiers-and-references","title":"Exclude qualifiers and references","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Create formatter that excludes qualifiers and references\nformatter = QSV1Formatter(\n    exclude_qualifiers=True,\n    exclude_references=True\n)\n\nqs_text = formatter.format(template, for_new_item=True)\n# Output will only include main statements, no qualifiers/references\n</code></pre>"},{"location":"gkc/api/mash_formatters/#exclude-specific-properties","title":"Exclude specific properties","text":"<pre><code>from gkc.mash import WikidataLoader\nfrom gkc.mash_formatters import QSV1Formatter\n\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Exclude properties that aren't relevant\nformatter = QSV1Formatter(\n    exclude_properties=[\"P18\", \"P373\", \"P856\"]  # image, commons cat, website\n)\n\nqs_text = formatter.format(template, for_new_item=True)\n</code></pre>"},{"location":"gkc/api/mash_formatters/#complete-workflow-with-all-options","title":"Complete workflow with all options","text":"<pre><code>from gkc.mash import WikidataLoader, fetch_property_labels\nfrom gkc.mash_formatters import QSV1Formatter\nfrom gkc.sparql import fetch_entity_labels\n\n# Load template\nloader = WikidataLoader()\ntemplate = loader.load(\"Q42\")\n\n# Filter template\ntemplate.filter_languages(\"en\")\ntemplate.filter_properties([\"P18\", \"P373\"])\n\n# Fetch entity labels for comments\nentity_ids = set()\nfor claim in template.claims:\n    entity_ids.add(claim.property_id)\n    if claim.value.startswith(\"Q\"):\n        entity_ids.add(claim.value)\n\nentity_labels = fetch_entity_labels(list(entity_ids), languages=[\"en\"])\n\n# Format with all options\nformatter = QSV1Formatter(\n    exclude_properties=[\"P31\"],  # Skip 'instance of' for this example\n    exclude_qualifiers=False,\n    exclude_references=True,\n    entity_labels=entity_labels\n)\n\nqs_text = formatter.format(template, for_new_item=True)\nprint(qs_text)\n</code></pre>"},{"location":"gkc/api/mash_formatters/#quickstatements-v1-format-notes","title":"QuickStatements V1 Format Notes","text":""},{"location":"gkc/api/mash_formatters/#syntax-overview","title":"Syntax Overview","text":"<ul> <li>CREATE: Start a new item</li> <li>LAST: Refer to the most recently created item</li> <li>Labels: <code>LAST\\tLen\\t\"English label\"</code></li> <li>Descriptions: <code>LAST\\tDen\\t\"English description\"</code></li> <li>Aliases: <code>LAST\\tAen\\t\"English alias\"</code></li> <li>Statements: <code>LAST\\tP31\\tQ5</code> (property, value)</li> <li>Qualifiers: <code>LAST\\tP31\\tQ5\\tP580\\t+1952-03-11T00:00:00Z/11</code> (append with pipes)</li> <li>Comments: <code>/* human-readable note */</code> at end of line</li> </ul>"},{"location":"gkc/api/mash_formatters/#precision-in-time-values","title":"Precision in Time Values","text":"<p>Time values include precision indicators:</p> <ul> <li><code>/9</code> - year precision</li> <li><code>/10</code> - month precision  </li> <li><code>/11</code> - day precision</li> <li><code>/14</code> - second precision</li> </ul> <p>Example: <code>+1952-03-11T00:00:00Z/11</code> (precise to day)</p>"},{"location":"gkc/api/mash_formatters/#entity-references","title":"Entity References","text":"<ul> <li>Items: Q-IDs (e.g., <code>Q42</code>)</li> <li>Properties: P-IDs (e.g., <code>P31</code>)</li> <li>Strings: Quoted values (e.g., <code>\"Douglas Adams\"</code>)</li> <li>Quantities: Numeric values with optional units</li> <li>Coordinates: <code>@lat/lon</code> format</li> </ul>"},{"location":"gkc/api/mash_formatters/#see-also","title":"See Also","text":"<ul> <li>Mash API - Load and manipulate Wikidata templates</li> <li>Mash CLI - Command-line interface with QS output examples</li> <li>QuickStatements Documentation - Official QS reference</li> </ul>"},{"location":"gkc/api/profiles/","title":"Profiles API","text":""},{"location":"gkc/api/profiles/#overview","title":"Overview","text":"<p>The profiles module provides YAML-first entity profiles that drive validation, form schema generation, and profile-aware data workflows.</p> <p>Current implementations: YAML loading, JSON Schema validation, Pydantic model generation, form schema generation, Wikidata validation Future implementations: profile registry, code generation, broader datatype support</p>"},{"location":"gkc/api/profiles/#quick-start","title":"Quick Start","text":"<pre><code>from gkc.profiles import ProfileLoader, ProfileValidator\n\nprofile = ProfileLoader().load_from_file(\n    \"/path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\"\n)\nvalidator = ProfileValidator(profile)\nresult = validator.validate_item(item_json, policy=\"lenient\")\n</code></pre>"},{"location":"gkc/api/profiles/#classes","title":"Classes","text":""},{"location":"gkc/api/profiles/#profileloader","title":"ProfileLoader","text":"<p>Load YAML profile definitions into ProfileDefinition objects.</p> <p>Parameters:</p> Name Type Description Default <code>schema_path</code> <code>Optional[Path]</code> <p>Optional path to the JSON schema used for validation.</p> <code>None</code> Side effects <p>Reads the JSON schema from disk during initialization.</p> Example <p>loader = ProfileLoader() profile = loader.load_from_file(\"profiles/TribalGovernmentUS.yaml\")</p> <p>Plain meaning: Read a YAML profile and validate its structure.</p> Source code in <code>gkc/profiles/loaders/yaml_loader.py</code> <pre><code>class ProfileLoader:\n    \"\"\"Load YAML profile definitions into ProfileDefinition objects.\n\n    Args:\n        schema_path: Optional path to the JSON schema used for validation.\n\n    Side effects:\n        Reads the JSON schema from disk during initialization.\n\n    Example:\n        &gt;&gt;&gt; loader = ProfileLoader()\n        &gt;&gt;&gt; profile = loader.load_from_file(\"profiles/TribalGovernmentUS.yaml\")\n\n    Plain meaning: Read a YAML profile and validate its structure.\n    \"\"\"\n\n    def __init__(self, schema_path: Optional[Path] = None):\n        self._schema_path = schema_path or self._default_schema_path()\n        self._validator = Draft202012Validator(self._load_schema())\n\n    def load_from_file(self, path: Union[str, Path]) -&gt; ProfileDefinition:\n        \"\"\"Load a YAML profile from a file.\n\n        Args:\n            path: Path to the YAML profile file.\n\n        Returns:\n            Parsed ProfileDefinition instance.\n\n        Raises:\n            ValueError: If the profile fails schema validation.\n            FileNotFoundError: If the file does not exist.\n            yaml.YAMLError: If the YAML cannot be parsed.\n\n        Side effects:\n            Reads a YAML file from disk.\n\n        Example:\n            &gt;&gt;&gt; profile = loader.load_from_file(\".dev/TribalGovernmentUS.yaml\")\n\n        Plain meaning: Read and validate a profile file.\n        \"\"\"\n        yaml_text = Path(path).read_text(encoding=\"utf-8\")\n        return self.load_from_text(yaml_text)\n\n    def load_from_text(self, text: str) -&gt; ProfileDefinition:\n        \"\"\"Load a YAML profile from text.\n\n        Args:\n            text: YAML text contents.\n\n        Returns:\n            Parsed ProfileDefinition instance.\n\n        Raises:\n            ValueError: If the profile fails schema validation.\n            yaml.YAMLError: If the YAML cannot be parsed.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; profile = loader.load_from_text(\"name: Example\\nstatements: []\")\n\n        Plain meaning: Parse YAML content into a profile object.\n        \"\"\"\n        data = yaml.safe_load(text) or {}\n        return self.load_from_dict(data)\n\n    def load_from_dict(self, data: Dict[str, Any]) -&gt; ProfileDefinition:\n        \"\"\"Load a profile from a Python dictionary.\n\n        Args:\n            data: Profile data dictionary.\n\n        Returns:\n            Parsed ProfileDefinition instance.\n\n        Raises:\n            ValueError: If the profile fails schema validation.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; profile = loader.load_from_dict({\"name\": \"Demo\", \"statements\": []})\n\n        Plain meaning: Validate and convert profile data to a typed object.\n        \"\"\"\n        errors = list(self.validate_data(data))\n        if errors:\n            message = \"Profile schema validation failed: \" + \"; \".join(errors)\n            raise ValueError(message)\n        return ProfileDefinition.model_validate(data)\n\n    def validate_data(self, data: Dict[str, Any]) -&gt; Iterable[str]:\n        \"\"\"Validate profile data against the JSON schema.\n\n        Args:\n            data: Profile data dictionary.\n\n        Returns:\n            Iterable of error messages (empty if valid).\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; errors = list(loader.validate_data({\"name\": \"Demo\"}))\n\n        Plain meaning: Check if the profile matches the required structure.\n        \"\"\"\n        for error in sorted(self._validator.iter_errors(data), key=str):\n            path = \".\".join([str(item) for item in error.path]) or \"&lt;root&gt;\"\n            yield f\"{path}: {error.message}\"\n\n    def _load_schema(self) -&gt; dict[str, Any]:\n        schema_text = self._schema_path.read_text(encoding=\"utf-8\")\n        return json.loads(schema_text)\n\n    @staticmethod\n    def _default_schema_path() -&gt; Path:\n        return Path(__file__).resolve().parents[1] / \"schemas\" / \"profile.schema.json\"\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.loaders.yaml_loader.ProfileLoader.load_from_dict","title":"<code>load_from_dict(data)</code>","text":"<p>Load a profile from a Python dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Profile data dictionary.</p> required <p>Returns:</p> Type Description <code>ProfileDefinition</code> <p>Parsed ProfileDefinition instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the profile fails schema validation.</p> Side effects <p>None.</p> Example <p>profile = loader.load_from_dict({\"name\": \"Demo\", \"statements\": []})</p> <p>Plain meaning: Validate and convert profile data to a typed object.</p> Source code in <code>gkc/profiles/loaders/yaml_loader.py</code> <pre><code>def load_from_dict(self, data: Dict[str, Any]) -&gt; ProfileDefinition:\n    \"\"\"Load a profile from a Python dictionary.\n\n    Args:\n        data: Profile data dictionary.\n\n    Returns:\n        Parsed ProfileDefinition instance.\n\n    Raises:\n        ValueError: If the profile fails schema validation.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; profile = loader.load_from_dict({\"name\": \"Demo\", \"statements\": []})\n\n    Plain meaning: Validate and convert profile data to a typed object.\n    \"\"\"\n    errors = list(self.validate_data(data))\n    if errors:\n        message = \"Profile schema validation failed: \" + \"; \".join(errors)\n        raise ValueError(message)\n    return ProfileDefinition.model_validate(data)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.loaders.yaml_loader.ProfileLoader.load_from_file","title":"<code>load_from_file(path)</code>","text":"<p>Load a YAML profile from a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Union[str, Path]</code> <p>Path to the YAML profile file.</p> required <p>Returns:</p> Type Description <code>ProfileDefinition</code> <p>Parsed ProfileDefinition instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the profile fails schema validation.</p> <code>FileNotFoundError</code> <p>If the file does not exist.</p> <code>YAMLError</code> <p>If the YAML cannot be parsed.</p> Side effects <p>Reads a YAML file from disk.</p> Example <p>profile = loader.load_from_file(\".dev/TribalGovernmentUS.yaml\")</p> <p>Plain meaning: Read and validate a profile file.</p> Source code in <code>gkc/profiles/loaders/yaml_loader.py</code> <pre><code>def load_from_file(self, path: Union[str, Path]) -&gt; ProfileDefinition:\n    \"\"\"Load a YAML profile from a file.\n\n    Args:\n        path: Path to the YAML profile file.\n\n    Returns:\n        Parsed ProfileDefinition instance.\n\n    Raises:\n        ValueError: If the profile fails schema validation.\n        FileNotFoundError: If the file does not exist.\n        yaml.YAMLError: If the YAML cannot be parsed.\n\n    Side effects:\n        Reads a YAML file from disk.\n\n    Example:\n        &gt;&gt;&gt; profile = loader.load_from_file(\".dev/TribalGovernmentUS.yaml\")\n\n    Plain meaning: Read and validate a profile file.\n    \"\"\"\n    yaml_text = Path(path).read_text(encoding=\"utf-8\")\n    return self.load_from_text(yaml_text)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.loaders.yaml_loader.ProfileLoader.load_from_text","title":"<code>load_from_text(text)</code>","text":"<p>Load a YAML profile from text.</p> <pre><code>    Args:\n        text: YAML text contents.\n\n    Returns:\n        Parsed ProfileDefinition instance.\n\n    Raises:\n        ValueError: If the profile fails schema validation.\n        yaml.YAMLError: If the YAML cannot be parsed.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; profile = loader.load_from_text(\"name: Example\n</code></pre> <p>statements: []\")</p> <pre><code>    Plain meaning: Parse YAML content into a profile object.\n</code></pre> Source code in <code>gkc/profiles/loaders/yaml_loader.py</code> <pre><code>def load_from_text(self, text: str) -&gt; ProfileDefinition:\n    \"\"\"Load a YAML profile from text.\n\n    Args:\n        text: YAML text contents.\n\n    Returns:\n        Parsed ProfileDefinition instance.\n\n    Raises:\n        ValueError: If the profile fails schema validation.\n        yaml.YAMLError: If the YAML cannot be parsed.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; profile = loader.load_from_text(\"name: Example\\nstatements: []\")\n\n    Plain meaning: Parse YAML content into a profile object.\n    \"\"\"\n    data = yaml.safe_load(text) or {}\n    return self.load_from_dict(data)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.loaders.yaml_loader.ProfileLoader.validate_data","title":"<code>validate_data(data)</code>","text":"<p>Validate profile data against the JSON schema.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Dict[str, Any]</code> <p>Profile data dictionary.</p> required <p>Returns:</p> Type Description <code>Iterable[str]</code> <p>Iterable of error messages (empty if valid).</p> Side effects <p>None.</p> Example <p>errors = list(loader.validate_data({\"name\": \"Demo\"}))</p> <p>Plain meaning: Check if the profile matches the required structure.</p> Source code in <code>gkc/profiles/loaders/yaml_loader.py</code> <pre><code>def validate_data(self, data: Dict[str, Any]) -&gt; Iterable[str]:\n    \"\"\"Validate profile data against the JSON schema.\n\n    Args:\n        data: Profile data dictionary.\n\n    Returns:\n        Iterable of error messages (empty if valid).\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; errors = list(loader.validate_data({\"name\": \"Demo\"}))\n\n    Plain meaning: Check if the profile matches the required structure.\n    \"\"\"\n    for error in sorted(self._validator.iter_errors(data), key=str):\n        path = \".\".join([str(item) for item in error.path]) or \"&lt;root&gt;\"\n        yield f\"{path}: {error.message}\"\n</code></pre>"},{"location":"gkc/api/profiles/#profiledefinition","title":"ProfileDefinition","text":"<p>               Bases: <code>BaseModel</code></p> <p>Define a YAML profile and its statements.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Profile name.</p> <code>description</code> <code>str</code> <p>Profile description.</p> <code>labels</code> <code>dict[str, MetadataDefinition]</code> <p>Per-language label definitions.</p> <code>descriptions</code> <code>dict[str, MetadataDefinition]</code> <p>Per-language description definitions.</p> <code>aliases</code> <code>dict[str, MetadataDefinition]</code> <p>Per-language alias definitions.</p> <code>sitelinks</code> <code>Optional[SitelinksDefinition]</code> <p>Sitelink definitions for wiki projects.</p> <code>statements</code> <code>List[ProfileFieldDefinition]</code> <p>List of statement definitions.</p> Example <p>ProfileDefinition(name=\"Example\", description=\"Demo\", statements=[])</p> <p>Plain meaning: The complete YAML profile definition.</p> Source code in <code>gkc/profiles/models.py</code> <pre><code>class ProfileDefinition(BaseModel):\n    \"\"\"Define a YAML profile and its statements.\n\n    Attributes:\n        name: Profile name.\n        description: Profile description.\n        labels: Per-language label definitions.\n        descriptions: Per-language description definitions.\n        aliases: Per-language alias definitions.\n        sitelinks: Sitelink definitions for wiki projects.\n        statements: List of statement definitions.\n\n    Example:\n        &gt;&gt;&gt; ProfileDefinition(name=\"Example\", description=\"Demo\", statements=[])\n\n    Plain meaning: The complete YAML profile definition.\n    \"\"\"\n\n    name: str = Field(..., description=\"Profile name\")\n    description: str = Field(..., description=\"Profile description\")\n    labels: dict[str, MetadataDefinition] = Field(\n        default_factory=dict, description=\"Per-language labels\"\n    )\n    descriptions: dict[str, MetadataDefinition] = Field(\n        default_factory=dict, description=\"Per-language descriptions\"\n    )\n    aliases: dict[str, MetadataDefinition] = Field(\n        default_factory=dict, description=\"Per-language aliases\"\n    )\n    sitelinks: Optional[SitelinksDefinition] = Field(\n        default=None, description=\"Sitelinks configuration\"\n    )\n    statements: List[ProfileFieldDefinition] = Field(\n        default_factory=list,\n        validation_alias=AliasChoices(\"statements\", \"fields\"),\n        serialization_alias=\"statements\",\n        description=\"Profile statements\",\n    )\n\n    @property\n    def fields(self) -&gt; List[ProfileFieldDefinition]:\n        \"\"\"Backward-compatible alias for statements.\"\"\"\n        return self.statements\n\n    def statement_by_id(self, statement_id: str) -&gt; Optional[ProfileFieldDefinition]:\n        \"\"\"Get a statement definition by its identifier.\n\n        Args:\n            statement_id: Statement identifier to locate.\n\n        Returns:\n            Matching ProfileFieldDefinition or None if not found.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; profile.statement_by_id(\"instance_of\")\n\n        Plain meaning: Find a statement configuration by its ID.\n        \"\"\"\n        for statement in self.statements:\n            if statement.id == statement_id:\n                return statement\n        return None\n\n    def statement_by_property(\n        self, property_id: str\n    ) -&gt; Optional[ProfileFieldDefinition]:\n        \"\"\"Get a statement definition by its Wikidata property ID.\n\n        Args:\n            property_id: Wikidata property ID.\n\n        Returns:\n            Matching ProfileFieldDefinition or None if not found.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; profile.statement_by_property(\"P31\")\n\n        Plain meaning: Find the statement that maps to a Wikidata property.\n        \"\"\"\n        for statement in self.statements:\n            if statement.wikidata_property == property_id:\n                return statement\n        return None\n\n    def field_by_id(self, field_id: str) -&gt; Optional[ProfileFieldDefinition]:\n        \"\"\"Backward-compatible alias for statement_by_id.\"\"\"\n        return self.statement_by_id(field_id)\n\n    def field_by_property(self, property_id: str) -&gt; Optional[ProfileFieldDefinition]:\n        \"\"\"Backward-compatible alias for statement_by_property.\"\"\"\n        return self.statement_by_property(property_id)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.models.ProfileDefinition.fields","title":"<code>fields</code>  <code>property</code>","text":"<p>Backward-compatible alias for statements.</p>"},{"location":"gkc/api/profiles/#gkc.profiles.models.ProfileDefinition.field_by_id","title":"<code>field_by_id(field_id)</code>","text":"<p>Backward-compatible alias for statement_by_id.</p> Source code in <code>gkc/profiles/models.py</code> <pre><code>def field_by_id(self, field_id: str) -&gt; Optional[ProfileFieldDefinition]:\n    \"\"\"Backward-compatible alias for statement_by_id.\"\"\"\n    return self.statement_by_id(field_id)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.models.ProfileDefinition.field_by_property","title":"<code>field_by_property(property_id)</code>","text":"<p>Backward-compatible alias for statement_by_property.</p> Source code in <code>gkc/profiles/models.py</code> <pre><code>def field_by_property(self, property_id: str) -&gt; Optional[ProfileFieldDefinition]:\n    \"\"\"Backward-compatible alias for statement_by_property.\"\"\"\n    return self.statement_by_property(property_id)\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.models.ProfileDefinition.statement_by_id","title":"<code>statement_by_id(statement_id)</code>","text":"<p>Get a statement definition by its identifier.</p> <p>Parameters:</p> Name Type Description Default <code>statement_id</code> <code>str</code> <p>Statement identifier to locate.</p> required <p>Returns:</p> Type Description <code>Optional[ProfileFieldDefinition]</code> <p>Matching ProfileFieldDefinition or None if not found.</p> Side effects <p>None.</p> Example <p>profile.statement_by_id(\"instance_of\")</p> <p>Plain meaning: Find a statement configuration by its ID.</p> Source code in <code>gkc/profiles/models.py</code> <pre><code>def statement_by_id(self, statement_id: str) -&gt; Optional[ProfileFieldDefinition]:\n    \"\"\"Get a statement definition by its identifier.\n\n    Args:\n        statement_id: Statement identifier to locate.\n\n    Returns:\n        Matching ProfileFieldDefinition or None if not found.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; profile.statement_by_id(\"instance_of\")\n\n    Plain meaning: Find a statement configuration by its ID.\n    \"\"\"\n    for statement in self.statements:\n        if statement.id == statement_id:\n            return statement\n    return None\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.models.ProfileDefinition.statement_by_property","title":"<code>statement_by_property(property_id)</code>","text":"<p>Get a statement definition by its Wikidata property ID.</p> <p>Parameters:</p> Name Type Description Default <code>property_id</code> <code>str</code> <p>Wikidata property ID.</p> required <p>Returns:</p> Type Description <code>Optional[ProfileFieldDefinition]</code> <p>Matching ProfileFieldDefinition or None if not found.</p> Side effects <p>None.</p> Example <p>profile.statement_by_property(\"P31\")</p> <p>Plain meaning: Find the statement that maps to a Wikidata property.</p> Source code in <code>gkc/profiles/models.py</code> <pre><code>def statement_by_property(\n    self, property_id: str\n) -&gt; Optional[ProfileFieldDefinition]:\n    \"\"\"Get a statement definition by its Wikidata property ID.\n\n    Args:\n        property_id: Wikidata property ID.\n\n    Returns:\n        Matching ProfileFieldDefinition or None if not found.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; profile.statement_by_property(\"P31\")\n\n    Plain meaning: Find the statement that maps to a Wikidata property.\n    \"\"\"\n    for statement in self.statements:\n        if statement.wikidata_property == property_id:\n            return statement\n    return None\n</code></pre>"},{"location":"gkc/api/profiles/#profilevalidator","title":"ProfileValidator","text":"<p>Validate Wikidata item data against a ProfileDefinition.</p> <p>Parameters:</p> Name Type Description Default <code>profile</code> <code>ProfileDefinition</code> <p>Parsed ProfileDefinition instance.</p> required Side effects <p>None.</p> Example <p>validator = ProfileValidator(profile) result = validator.validate_item(entity_data)</p> <p>Plain meaning: Apply profile rules to a Wikidata item.</p> Source code in <code>gkc/profiles/validation/validator.py</code> <pre><code>class ProfileValidator:\n    \"\"\"Validate Wikidata item data against a ProfileDefinition.\n\n    Args:\n        profile: Parsed ProfileDefinition instance.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; validator = ProfileValidator(profile)\n        &gt;&gt;&gt; result = validator.validate_item(entity_data)\n\n    Plain meaning: Apply profile rules to a Wikidata item.\n    \"\"\"\n\n    def __init__(self, profile: ProfileDefinition):\n        self.profile = profile\n        self._generator = ProfilePydanticGenerator(profile)\n        self._normalizer = WikidataNormalizer()\n\n    def validate_item(\n        self, entity_data: dict, policy: ValidationPolicy = \"lenient\"\n    ) -&gt; ValidationResult:\n        \"\"\"Validate a Wikidata item against the profile.\n\n        Args:\n            entity_data: Wikidata JSON entity data.\n            policy: Validation policy (\"strict\" or \"lenient\").\n\n        Returns:\n            ValidationResult with errors, warnings, and normalized data.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; result = validator.validate_item(item, policy=\"lenient\")\n\n        Plain meaning: Check a Wikidata item for profile compliance.\n        \"\"\"\n        normalization = self._normalizer.normalize(entity_data, self.profile)\n        model = self._generator.build_model()\n\n        errors: List[ValidationIssue] = []\n        warnings: List[ValidationIssue] = []\n\n        self._add_normalization_issues(normalization, warnings, errors)\n\n        try:\n            model.model_validate(normalization.data, context={\"policy\": policy})\n        except ValidationError as exc:\n            errors.extend(self._errors_from_validation(exc, model))\n\n        if policy == \"lenient\":\n            warnings.extend(self._collect_lenient_warnings(normalization))\n\n        ok = len(errors) == 0\n        return ValidationResult(\n            ok=ok,\n            errors=errors,\n            warnings=warnings,\n            normalized=normalization.data,\n        )\n\n    def _add_normalization_issues(\n        self,\n        normalization: NormalizationResult,\n        warnings: List[ValidationIssue],\n        errors: List[ValidationIssue],\n    ) -&gt; None:\n        for issue in normalization.issues:\n            target = warnings if issue.severity == \"warning\" else errors\n            target.append(\n                ValidationIssue(\n                    severity=issue.severity,\n                    message=issue.message,\n                    statement_id=issue.statement_id,\n                    property_id=issue.property_id,\n                )\n            )\n\n    def _errors_from_validation(\n        self, exc: ValidationError, model: type[BaseModel]\n    ) -&gt; list[ValidationIssue]:\n        issues: List[ValidationIssue] = []\n        field_aliases = {\n            name: (field.alias or name) for name, field in model.model_fields.items()\n        }\n\n        for err in exc.errors():\n            loc = err.get(\"loc\", [])\n            field_name = loc[0] if loc else None\n            statement_id = field_aliases.get(field_name) if field_name else None\n            issues.append(\n                ValidationIssue(\n                    severity=\"error\",\n                    message=err.get(\"msg\", \"Validation error\"),\n                    statement_id=statement_id,\n                )\n            )\n        return issues\n\n    def _collect_lenient_warnings(\n        self, normalization: NormalizationResult\n    ) -&gt; list[ValidationIssue]:\n        warnings: list[ValidationIssue] = []\n\n        for field in self.profile.statements:\n            statements = normalization.data.get(field.id, [])\n            violations = _evaluate_field(field, statements)\n            for violation, category in violations:\n                if category == \"field\":\n                    if field.validation_policy != \"allow_existing_nonconforming\":\n                        continue\n                if category == \"reference\" and field.references:\n                    if (\n                        field.references.validation_policy\n                        != \"allow_existing_nonconforming\"\n                    ):\n                        continue\n                warnings.append(\n                    ValidationIssue(\n                        severity=\"warning\",\n                        message=f\"{field.id}: {violation}\",\n                        statement_id=field.id,\n                        property_id=field.wikidata_property,\n                    )\n                )\n\n        return warnings\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.validation.validator.ProfileValidator.validate_item","title":"<code>validate_item(entity_data, policy='lenient')</code>","text":"<p>Validate a Wikidata item against the profile.</p> <p>Parameters:</p> Name Type Description Default <code>entity_data</code> <code>dict</code> <p>Wikidata JSON entity data.</p> required <code>policy</code> <code>ValidationPolicy</code> <p>Validation policy (\"strict\" or \"lenient\").</p> <code>'lenient'</code> <p>Returns:</p> Type Description <code>ValidationResult</code> <p>ValidationResult with errors, warnings, and normalized data.</p> Side effects <p>None.</p> Example <p>result = validator.validate_item(item, policy=\"lenient\")</p> <p>Plain meaning: Check a Wikidata item for profile compliance.</p> Source code in <code>gkc/profiles/validation/validator.py</code> <pre><code>def validate_item(\n    self, entity_data: dict, policy: ValidationPolicy = \"lenient\"\n) -&gt; ValidationResult:\n    \"\"\"Validate a Wikidata item against the profile.\n\n    Args:\n        entity_data: Wikidata JSON entity data.\n        policy: Validation policy (\"strict\" or \"lenient\").\n\n    Returns:\n        ValidationResult with errors, warnings, and normalized data.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; result = validator.validate_item(item, policy=\"lenient\")\n\n    Plain meaning: Check a Wikidata item for profile compliance.\n    \"\"\"\n    normalization = self._normalizer.normalize(entity_data, self.profile)\n    model = self._generator.build_model()\n\n    errors: List[ValidationIssue] = []\n    warnings: List[ValidationIssue] = []\n\n    self._add_normalization_issues(normalization, warnings, errors)\n\n    try:\n        model.model_validate(normalization.data, context={\"policy\": policy})\n    except ValidationError as exc:\n        errors.extend(self._errors_from_validation(exc, model))\n\n    if policy == \"lenient\":\n        warnings.extend(self._collect_lenient_warnings(normalization))\n\n    ok = len(errors) == 0\n    return ValidationResult(\n        ok=ok,\n        errors=errors,\n        warnings=warnings,\n        normalized=normalization.data,\n    )\n</code></pre>"},{"location":"gkc/api/profiles/#validationresult","title":"ValidationResult","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of validating an item against a profile.</p> <p>Attributes:</p> Name Type Description <code>ok</code> <code>bool</code> <p>Whether validation passed without errors.</p> <code>errors</code> <code>List[ValidationIssue]</code> <p>Validation errors.</p> <code>warnings</code> <code>List[ValidationIssue]</code> <p>Validation warnings.</p> <code>normalized</code> <code>Dict[str, List[StatementData]]</code> <p>Normalized statement data.</p> <p>Plain meaning: Validation status and issues found.</p> Source code in <code>gkc/profiles/validation/validator.py</code> <pre><code>class ValidationResult(BaseModel):\n    \"\"\"Result of validating an item against a profile.\n\n    Attributes:\n        ok: Whether validation passed without errors.\n        errors: Validation errors.\n        warnings: Validation warnings.\n        normalized: Normalized statement data.\n\n    Plain meaning: Validation status and issues found.\n    \"\"\"\n\n    ok: bool\n    errors: List[ValidationIssue]\n    warnings: List[ValidationIssue]\n    normalized: Dict[str, List[StatementData]]\n\n    def is_valid(self) -&gt; bool:\n        \"\"\"Return True when validation has no errors.\n\n        Returns:\n            True if no errors are present.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; result.is_valid()\n\n        Plain meaning: Check if validation succeeded.\n        \"\"\"\n        return self.ok\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.validation.validator.ValidationResult.is_valid","title":"<code>is_valid()</code>","text":"<p>Return True when validation has no errors.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if no errors are present.</p> Side effects <p>None.</p> Example <p>result.is_valid()</p> <p>Plain meaning: Check if validation succeeded.</p> Source code in <code>gkc/profiles/validation/validator.py</code> <pre><code>def is_valid(self) -&gt; bool:\n    \"\"\"Return True when validation has no errors.\n\n    Returns:\n        True if no errors are present.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; result.is_valid()\n\n    Plain meaning: Check if validation succeeded.\n    \"\"\"\n    return self.ok\n</code></pre>"},{"location":"gkc/api/profiles/#formschemagenerator","title":"FormSchemaGenerator","text":"<p>Generate form/CLI schemas from YAML profiles.</p> <p>Parameters:</p> Name Type Description Default <code>profile</code> <code>ProfileDefinition</code> <p>Parsed ProfileDefinition instance.</p> required Side effects <p>None.</p> Example <p>schema = FormSchemaGenerator(profile).build_schema()</p> <p>Plain meaning: Convert a profile into a form-friendly schema.</p> Source code in <code>gkc/profiles/generators/form_generator.py</code> <pre><code>class FormSchemaGenerator:\n    \"\"\"Generate form/CLI schemas from YAML profiles.\n\n    Args:\n        profile: Parsed ProfileDefinition instance.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; schema = FormSchemaGenerator(profile).build_schema()\n\n    Plain meaning: Convert a profile into a form-friendly schema.\n    \"\"\"\n\n    def __init__(self, profile: ProfileDefinition):\n        self.profile = profile\n\n    def build_schema(self) -&gt; dict[str, Any]:\n        \"\"\"Build a form schema dictionary for the profile.\n\n        Returns:\n            Dictionary describing statements, qualifiers, and references.\n\n        Side effects:\n            None.\n\n        Example:\n            &gt;&gt;&gt; schema = FormSchemaGenerator(profile).build_schema()\n\n        Plain meaning: Export statement definitions for CLI or UI prompts.\n        \"\"\"\n        return {\n            \"name\": self.profile.name,\n            \"description\": self.profile.description,\n            \"statements\": [\n                self._field_schema(field) for field in self.profile.statements\n            ],\n        }\n\n    def _field_schema(self, field) -&gt; dict[str, Any]:\n        value = {\n            \"type\": field.value.type,\n            \"fixed\": field.value.fixed,\n            \"label\": field.value.label,\n            \"constraints\": [c.model_dump() for c in field.value.constraints],\n        }\n\n        qualifiers = []\n        for qualifier in field.qualifiers:\n            qualifiers.append(\n                {\n                    \"id\": qualifier.id,\n                    \"label\": qualifier.label,\n                    \"input_prompt\": qualifier.input_prompt,\n                    \"wikidata_property\": qualifier.wikidata_property,\n                    \"required\": qualifier.required,\n                    \"min_count\": qualifier.min_count,\n                    \"max_count\": qualifier.max_count,\n                    \"value\": {\n                        \"type\": qualifier.value.type,\n                        \"fixed\": qualifier.value.fixed,\n                        \"label\": qualifier.value.label,\n                        \"constraints\": [\n                            c.model_dump() for c in qualifier.value.constraints\n                        ],\n                    },\n                }\n            )\n\n        references = None\n        if field.references:\n            references = {\n                \"required\": field.references.required,\n                \"min_count\": field.references.min_count,\n                \"input_prompt\": field.references.input_prompt,\n                \"validation_policy\": field.references.validation_policy,\n                \"form_policy\": field.references.form_policy,\n                \"allowed\": [\n                    self._reference_target_schema(target)\n                    for target in field.references.allowed\n                ],\n                \"target\": (\n                    self._reference_target_schema(field.references.target)\n                    if field.references.target\n                    else None\n                ),\n            }\n\n        return {\n            \"id\": field.id,\n            \"label\": field.label,\n            \"input_prompt\": field.input_prompt,\n            \"wikidata_property\": field.wikidata_property,\n            \"required\": field.required,\n            \"max_count\": field.max_count,\n            \"validation_policy\": field.validation_policy,\n            \"form_policy\": field.form_policy,\n            \"value\": value,\n            \"qualifiers\": qualifiers,\n            \"references\": references,\n        }\n\n    @staticmethod\n    def _reference_target_schema(target) -&gt; dict[str, Any]:\n        if target is None:\n            return {}\n        return {\n            \"id\": target.id,\n            \"label\": target.label,\n            \"input_prompt\": target.input_prompt,\n            \"wikidata_property\": target.wikidata_property,\n            \"type\": target.type,\n            \"description\": target.description,\n            \"value_source\": target.value_source,\n            \"allowed_items\": (\n                target.allowed_items.model_dump() if target.allowed_items else None\n            ),\n        }\n</code></pre>"},{"location":"gkc/api/profiles/#gkc.profiles.generators.form_generator.FormSchemaGenerator.build_schema","title":"<code>build_schema()</code>","text":"<p>Build a form schema dictionary for the profile.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary describing statements, qualifiers, and references.</p> Side effects <p>None.</p> Example <p>schema = FormSchemaGenerator(profile).build_schema()</p> <p>Plain meaning: Export statement definitions for CLI or UI prompts.</p> Source code in <code>gkc/profiles/generators/form_generator.py</code> <pre><code>def build_schema(self) -&gt; dict[str, Any]:\n    \"\"\"Build a form schema dictionary for the profile.\n\n    Returns:\n        Dictionary describing statements, qualifiers, and references.\n\n    Side effects:\n        None.\n\n    Example:\n        &gt;&gt;&gt; schema = FormSchemaGenerator(profile).build_schema()\n\n    Plain meaning: Export statement definitions for CLI or UI prompts.\n    \"\"\"\n    return {\n        \"name\": self.profile.name,\n        \"description\": self.profile.description,\n        \"statements\": [\n            self._field_schema(field) for field in self.profile.statements\n        ],\n    }\n</code></pre>"},{"location":"gkc/api/profiles/#examples","title":"Examples","text":""},{"location":"gkc/api/profiles/#load-a-yaml-profile","title":"Load a YAML Profile","text":"<pre><code>from gkc.profiles import ProfileLoader\n\nloader = ProfileLoader()\nprofile = loader.load_from_file(\n    \"/path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\"\n)\nprint(profile.name)\n</code></pre>"},{"location":"gkc/api/profiles/#generate-a-form-schema","title":"Generate a Form Schema","text":"<pre><code>from gkc.profiles import FormSchemaGenerator, ProfileLoader\n\nprofile = ProfileLoader().load_from_file(\n    \"/path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\"\n)\nform_schema = FormSchemaGenerator(profile).build_schema()\nprint(form_schema[\"statements\"][0][\"label\"])\n</code></pre>"},{"location":"gkc/api/profiles/#validate-a-wikidata-item-lenient","title":"Validate a Wikidata Item (Lenient)","text":"<pre><code>from gkc.profiles import ProfileLoader, ProfileValidator\n\nprofile = ProfileLoader().load_from_file(\n    \"/path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\"\n)\nvalidator = ProfileValidator(profile)\nresult = validator.validate_item(item_json, policy=\"lenient\")\n\nif result.ok:\n    print(\"Valid (lenient)\")\n    for warning in result.warnings:\n        print(warning.message)\n</code></pre>"},{"location":"gkc/api/profiles/#validate-a-wikidata-item-strict","title":"Validate a Wikidata Item (Strict)","text":"<pre><code>from gkc.profiles import ProfileLoader, ProfileValidator\n\nprofile = ProfileLoader().load_from_file(\n    \"/path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\"\n)\nvalidator = ProfileValidator(profile)\nresult = validator.validate_item(item_json, policy=\"strict\")\n\nif not result.ok:\n    for error in result.errors:\n        print(error.message)\n</code></pre>"},{"location":"gkc/api/profiles/#error-handling","title":"Error Handling","text":""},{"location":"gkc/api/profiles/#profile-schema-validation-errors","title":"Profile Schema Validation Errors","text":"<pre><code>from gkc.profiles import ProfileLoader\n\nloader = ProfileLoader()\ntry:\n    loader.load_from_file(\"bad_profile.yaml\")\nexcept ValueError as exc:\n    print(f\"Schema error: {exc}\")\n</code></pre>"},{"location":"gkc/api/profiles/#see-also","title":"See Also","text":"<ul> <li>Mash - Load Wikidata items for validation</li> <li>ShEx - Schema validation against EntitySchemas</li> <li>CLI Profiles - Profile commands</li> </ul>"},{"location":"gkc/api/shex/","title":"ShEx Validation API","text":""},{"location":"gkc/api/shex/#overview","title":"Overview","text":"<p>The ShEx validation module provides RDF data validation against ShEx (Shape Expression) schemas. It's designed primarily for validating Wikidata entities against EntitySchemas but supports any RDF data and ShEx schema combination.</p> <p>Current implementations: Wikidata EntitySchema validation, local file validation Future implementations: Additional RDF graph sources, streaming validation</p>"},{"location":"gkc/api/shex/#quick-start","title":"Quick Start","text":"<pre><code>from gkc import ShexValidator\n\n# Validate Wikidata item against EntitySchema\nvalidator = ShexValidator(qid='Q14708404', eid='E502')\nresult = validator.check()\n\nif result.is_valid():\n    print(\"\u2713 Validation passed\")\nelse:\n    print(\"\u2717 Validation failed\")\n</code></pre>"},{"location":"gkc/api/shex/#classes","title":"Classes","text":""},{"location":"gkc/api/shex/#shexvalidator","title":"ShexValidator","text":"<p>ShEx Validator: Validate RDF data against ShEx schemas.</p> <p>Validates Wikidata entities or local RDF data against EntitySchemas (ShEx format). Supports multiple input sources: Wikidata entities, local files, or text strings.</p> <p>Plain meaning: Check if data matches schema structure and rules.</p> Example Source code in <code>gkc/shex.py</code> <pre><code>class ShexValidator:\n    \"\"\"\n    ShEx Validator: Validate RDF data against ShEx schemas.\n\n    Validates Wikidata entities or local RDF data against EntitySchemas (ShEx format).\n    Supports multiple input sources: Wikidata entities, local files, or text strings.\n\n    Plain meaning: Check if data matches schema structure and rules.\n\n    Example:\n        &gt;&gt;&gt; # Validate a Wikidata item against an EntitySchema\n        &gt;&gt;&gt; validator = ShexValidator(qid='Q42', eid='E502')\n        &gt;&gt;&gt; result = validator.check()\n        &gt;&gt;&gt; if result.is_valid():\n        ...     print(\"Validation passed!\")\n\n        &gt;&gt;&gt; # Use local schema file\n        &gt;&gt;&gt; validator = ShexValidator(\n        ...     qid='Q42',\n        ...     schema_file='schema.shex'\n        ... )\n        &gt;&gt;&gt; validator.check()\n\n        &gt;&gt;&gt; # Use RDF text directly\n        &gt;&gt;&gt; validator = ShexValidator(\n        ...     rdf_text=my_rdf_data,\n        ...     schema_text=my_schema\n        ... )\n        &gt;&gt;&gt; validator.check()\n    \"\"\"\n\n    def __init__(\n        self,\n        qid: Optional[str] = None,\n        eid: Optional[str] = None,\n        user_agent: Optional[str] = None,\n        schema_text: Optional[str] = None,\n        schema_file: Optional[str] = None,\n        rdf_text: Optional[str] = None,\n        rdf_file: Optional[str] = None,\n    ):\n        \"\"\"\n        Initialize the ShEx validator.\n\n        Args:\n            qid: Wikidata entity ID (e.g., 'Q42'). Optional if rdf_text or\n                rdf_file provided.\n            eid: EntitySchema ID for Wikidata schema (e.g., 'E502').\n                Optional if schema_text or schema_file provided.\n            user_agent: Custom user agent for Wikidata requests.\n            schema_text: ShEx schema as ShExC string (alternative to eid).\n            schema_file: Path to file containing ShEx schema (alternative to eid).\n            rdf_text: RDF data as a string (alternative to qid).\n            rdf_file: Path to file containing RDF data (alternative to qid).\n        \"\"\"\n        self.qid = qid\n        self.eid = eid\n        self.user_agent = user_agent\n        self.schema_text = schema_text\n        self.schema_file = schema_file\n        self.rdf_text = rdf_text\n        self.rdf_file = rdf_file\n\n        self._schema: Optional[str] = None\n        self._rdf: Optional[str] = None\n        self.results = None\n\n    def load_specification(self) -&gt; \"ShexValidator\":\n        \"\"\"\n        Load the ShEx schema specification from configured source.\n\n        Tries sources in order: schema_text, schema_file, eid (fetch from Wikidata).\n\n        Returns:\n            Self for method chaining\n\n        Raises:\n            ShexValidationError: If no valid schema source or loading fails\n        \"\"\"\n        try:\n            if self.schema_text:\n                self._schema = self.schema_text\n            elif self.schema_file:\n                schema_path = Path(self.schema_file)\n                if not schema_path.exists():\n                    raise ShexValidationError(\n                        f\"Schema file not found: {self.schema_file}\"\n                    )\n                self._schema = schema_path.read_text(encoding=\"utf-8\")\n            elif self.eid:\n                self._schema = fetch_schema_specification(self.eid, self.user_agent)\n            else:\n                raise ShexValidationError(\n                    \"No schema source provided. \"\n                    \"Specify eid, schema_text, or schema_file.\"\n                )\n        except CooperageError as e:\n            raise ShexValidationError(f\"Failed to load schema: {str(e)}\") from e\n        except OSError as e:\n            msg = f\"Failed to read schema file: {str(e)}\"\n            raise ShexValidationError(msg) from e\n\n        return self\n\n    def load_rdf(self) -&gt; \"ShexValidator\":\n        \"\"\"\n        Load RDF data from configured source.\n\n        Tries sources in order: rdf_text, rdf_file, qid (from Wikidata).\n\n        Returns:\n            Self for method chaining\n\n        Raises:\n            ShexValidationError: If no valid RDF source or loading fails\n        \"\"\"\n        try:\n            if self.rdf_text:\n                self._rdf = self.rdf_text\n            elif self.rdf_file:\n                rdf_path = Path(self.rdf_file)\n                if not rdf_path.exists():\n                    msg = f\"RDF file not found: {self.rdf_file}\"\n                    raise ShexValidationError(msg)\n                self._rdf = rdf_path.read_text(encoding=\"utf-8\")\n            elif self.qid:\n                self._rdf = fetch_entity_rdf(\n                    self.qid, format=\"ttl\", user_agent=self.user_agent\n                )\n            else:\n                raise ShexValidationError(\n                    \"No RDF source provided. Specify qid, rdf_text, or rdf_file.\"\n                )\n        except CooperageError as e:\n            raise ShexValidationError(f\"Failed to load RDF: {str(e)}\") from e\n        except OSError as e:\n            raise ShexValidationError(f\"Failed to read RDF file: {str(e)}\") from e\n\n        return self\n\n    def passes_inspection(self) -&gt; bool:\n        \"\"\"\n        Check if validation passed (alias for is_valid).\n\n        Returns:\n            True if validation passed, False otherwise\n\n        Raises:\n            ShexValidationError: If check() hasn't been called yet\n        \"\"\"\n        return self.is_valid()\n\n    def evaluate(self) -&gt; \"ShexValidator\":\n        \"\"\"\n        Evaluate RDF data against the ShEx schema specification.\n\n        Must call load_specification() and load_rdf() first, or use check().\n\n        Returns:\n            Self with results populated\n\n        Raises:\n            ShexValidationError: If evaluation fails or data not loaded\n        \"\"\"\n        if self._schema is None:\n            raise ShexValidationError(\n                \"Schema not loaded. Call load_specification() first or use check().\"\n            )\n        if self._rdf is None:\n            raise ShexValidationError(\n                \"RDF data not loaded. Call load_rdf() first or use check().\"\n            )\n\n        # Determine focus node\n        focus = None\n        if self.qid:\n            focus = get_entity_uri(self.qid)\n\n        try:\n            self.results = ShExEvaluator(\n                rdf=self._rdf, schema=self._schema, focus=focus\n            ).evaluate()\n        except Exception as e:\n            msg = f\"ShEx evaluation failed: {str(e)}\"\n            raise ShexValidationError(msg) from e\n\n        return self\n\n    def check(self) -&gt; \"ShexValidator\":\n        \"\"\"\n        Validate: Load schema, load RDF, and evaluate in one call.\n\n        This is the main entry point for validation. It loads schema and data\n        from configured sources, then performs the validation.\n\n        Returns:\n            Self with results populated\n\n        Example:\n            &gt;&gt;&gt; validator = ShexValidator(qid='Q42', eid='E502')\n            &gt;&gt;&gt; validator.check()\n            &gt;&gt;&gt; if validator.is_valid():\n            ...     print(\"Validation passed!\")\n        \"\"\"\n        self.load_specification()\n        self.load_rdf()\n        self.evaluate()\n        return self\n\n    def is_valid(self) -&gt; bool:\n        \"\"\"\n        Check if validation passed.\n\n        Returns:\n            True if validation passed, False otherwise\n\n        Raises:\n            ShexValidationError: If check() hasn't been called yet\n        \"\"\"\n        if self.results is None:\n            msg = \"No validation results. Call check() first.\"\n            raise ShexValidationError(msg)\n\n        # Handle mocked results (for testing)\n        if isinstance(self.results, bool):\n            return self.results\n\n        # PyShEx returns results as a list of EvaluationResult objects\n        # When validation succeeds, reason contains matching triples\n        # When validation fails, reason contains error messages like\n        # \"Node: ... not in value set\"\n        # If no focus is specified, PyShEx tests all nodes;\n        # we need at least one success\n        if not self.results:\n            return False\n\n        # Check if at least one result succeeded (no error indicators)\n        for result in self.results:\n            reason = result.reason or \"\"\n            # Common failure indicators in PyShEx error messages\n            has_error = any(\n                indicator in reason\n                for indicator in [\n                    \"not in value set\",\n                    \"does not match\",\n                    \"Constraint violation\",\n                    \"No matching\",\n                    \"Failed to\",\n                ]\n            )\n            if not has_error:\n                return True\n\n        return False\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of validator.\"\"\"\n        parts = []\n        if self.qid:\n            parts.append(f\"qid={self.qid!r}\")\n        if self.eid:\n            parts.append(f\"eid={self.eid!r}\")\n        if self.rdf_file:\n            parts.append(f\"rdf_file={self.rdf_file!r}\")\n        if self.schema_file:\n            parts.append(f\"schema_file={self.schema_file!r}\")\n\n        params = \", \".join(parts) if parts else \"\"\n        return f\"ShexValidator({params})\"\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator--validate-a-wikidata-item-against-an-entityschema","title":"Validate a Wikidata item against an EntitySchema","text":"<p>validator = ShexValidator(qid='Q42', eid='E502') result = validator.check() if result.is_valid(): ...     print(\"Validation passed!\")</p>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator--use-local-schema-file","title":"Use local schema file","text":"<p>validator = ShexValidator( ...     qid='Q42', ...     schema_file='schema.shex' ... ) validator.check()</p>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator--use-rdf-text-directly","title":"Use RDF text directly","text":"<p>validator = ShexValidator( ...     rdf_text=my_rdf_data, ...     schema_text=my_schema ... ) validator.check()</p>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.__init__","title":"<code>__init__(qid=None, eid=None, user_agent=None, schema_text=None, schema_file=None, rdf_text=None, rdf_file=None)</code>","text":"<p>Initialize the ShEx validator.</p> <p>Parameters:</p> Name Type Description Default <code>qid</code> <code>Optional[str]</code> <p>Wikidata entity ID (e.g., 'Q42'). Optional if rdf_text or rdf_file provided.</p> <code>None</code> <code>eid</code> <code>Optional[str]</code> <p>EntitySchema ID for Wikidata schema (e.g., 'E502'). Optional if schema_text or schema_file provided.</p> <code>None</code> <code>user_agent</code> <code>Optional[str]</code> <p>Custom user agent for Wikidata requests.</p> <code>None</code> <code>schema_text</code> <code>Optional[str]</code> <p>ShEx schema as ShExC string (alternative to eid).</p> <code>None</code> <code>schema_file</code> <code>Optional[str]</code> <p>Path to file containing ShEx schema (alternative to eid).</p> <code>None</code> <code>rdf_text</code> <code>Optional[str]</code> <p>RDF data as a string (alternative to qid).</p> <code>None</code> <code>rdf_file</code> <code>Optional[str]</code> <p>Path to file containing RDF data (alternative to qid).</p> <code>None</code> Source code in <code>gkc/shex.py</code> <pre><code>def __init__(\n    self,\n    qid: Optional[str] = None,\n    eid: Optional[str] = None,\n    user_agent: Optional[str] = None,\n    schema_text: Optional[str] = None,\n    schema_file: Optional[str] = None,\n    rdf_text: Optional[str] = None,\n    rdf_file: Optional[str] = None,\n):\n    \"\"\"\n    Initialize the ShEx validator.\n\n    Args:\n        qid: Wikidata entity ID (e.g., 'Q42'). Optional if rdf_text or\n            rdf_file provided.\n        eid: EntitySchema ID for Wikidata schema (e.g., 'E502').\n            Optional if schema_text or schema_file provided.\n        user_agent: Custom user agent for Wikidata requests.\n        schema_text: ShEx schema as ShExC string (alternative to eid).\n        schema_file: Path to file containing ShEx schema (alternative to eid).\n        rdf_text: RDF data as a string (alternative to qid).\n        rdf_file: Path to file containing RDF data (alternative to qid).\n    \"\"\"\n    self.qid = qid\n    self.eid = eid\n    self.user_agent = user_agent\n    self.schema_text = schema_text\n    self.schema_file = schema_file\n    self.rdf_text = rdf_text\n    self.rdf_file = rdf_file\n\n    self._schema: Optional[str] = None\n    self._rdf: Optional[str] = None\n    self.results = None\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of validator.</p> Source code in <code>gkc/shex.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"String representation of validator.\"\"\"\n    parts = []\n    if self.qid:\n        parts.append(f\"qid={self.qid!r}\")\n    if self.eid:\n        parts.append(f\"eid={self.eid!r}\")\n    if self.rdf_file:\n        parts.append(f\"rdf_file={self.rdf_file!r}\")\n    if self.schema_file:\n        parts.append(f\"schema_file={self.schema_file!r}\")\n\n    params = \", \".join(parts) if parts else \"\"\n    return f\"ShexValidator({params})\"\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.check","title":"<code>check()</code>","text":"<p>Validate: Load schema, load RDF, and evaluate in one call.</p> <p>This is the main entry point for validation. It loads schema and data from configured sources, then performs the validation.</p> <p>Returns:</p> Type Description <code>ShexValidator</code> <p>Self with results populated</p> Example <p>validator = ShexValidator(qid='Q42', eid='E502') validator.check() if validator.is_valid(): ...     print(\"Validation passed!\")</p> Source code in <code>gkc/shex.py</code> <pre><code>def check(self) -&gt; \"ShexValidator\":\n    \"\"\"\n    Validate: Load schema, load RDF, and evaluate in one call.\n\n    This is the main entry point for validation. It loads schema and data\n    from configured sources, then performs the validation.\n\n    Returns:\n        Self with results populated\n\n    Example:\n        &gt;&gt;&gt; validator = ShexValidator(qid='Q42', eid='E502')\n        &gt;&gt;&gt; validator.check()\n        &gt;&gt;&gt; if validator.is_valid():\n        ...     print(\"Validation passed!\")\n    \"\"\"\n    self.load_specification()\n    self.load_rdf()\n    self.evaluate()\n    return self\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.evaluate","title":"<code>evaluate()</code>","text":"<p>Evaluate RDF data against the ShEx schema specification.</p> <p>Must call load_specification() and load_rdf() first, or use check().</p> <p>Returns:</p> Type Description <code>ShexValidator</code> <p>Self with results populated</p> <p>Raises:</p> Type Description <code>ShexValidationError</code> <p>If evaluation fails or data not loaded</p> Source code in <code>gkc/shex.py</code> <pre><code>def evaluate(self) -&gt; \"ShexValidator\":\n    \"\"\"\n    Evaluate RDF data against the ShEx schema specification.\n\n    Must call load_specification() and load_rdf() first, or use check().\n\n    Returns:\n        Self with results populated\n\n    Raises:\n        ShexValidationError: If evaluation fails or data not loaded\n    \"\"\"\n    if self._schema is None:\n        raise ShexValidationError(\n            \"Schema not loaded. Call load_specification() first or use check().\"\n        )\n    if self._rdf is None:\n        raise ShexValidationError(\n            \"RDF data not loaded. Call load_rdf() first or use check().\"\n        )\n\n    # Determine focus node\n    focus = None\n    if self.qid:\n        focus = get_entity_uri(self.qid)\n\n    try:\n        self.results = ShExEvaluator(\n            rdf=self._rdf, schema=self._schema, focus=focus\n        ).evaluate()\n    except Exception as e:\n        msg = f\"ShEx evaluation failed: {str(e)}\"\n        raise ShexValidationError(msg) from e\n\n    return self\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.is_valid","title":"<code>is_valid()</code>","text":"<p>Check if validation passed.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if validation passed, False otherwise</p> <p>Raises:</p> Type Description <code>ShexValidationError</code> <p>If check() hasn't been called yet</p> Source code in <code>gkc/shex.py</code> <pre><code>def is_valid(self) -&gt; bool:\n    \"\"\"\n    Check if validation passed.\n\n    Returns:\n        True if validation passed, False otherwise\n\n    Raises:\n        ShexValidationError: If check() hasn't been called yet\n    \"\"\"\n    if self.results is None:\n        msg = \"No validation results. Call check() first.\"\n        raise ShexValidationError(msg)\n\n    # Handle mocked results (for testing)\n    if isinstance(self.results, bool):\n        return self.results\n\n    # PyShEx returns results as a list of EvaluationResult objects\n    # When validation succeeds, reason contains matching triples\n    # When validation fails, reason contains error messages like\n    # \"Node: ... not in value set\"\n    # If no focus is specified, PyShEx tests all nodes;\n    # we need at least one success\n    if not self.results:\n        return False\n\n    # Check if at least one result succeeded (no error indicators)\n    for result in self.results:\n        reason = result.reason or \"\"\n        # Common failure indicators in PyShEx error messages\n        has_error = any(\n            indicator in reason\n            for indicator in [\n                \"not in value set\",\n                \"does not match\",\n                \"Constraint violation\",\n                \"No matching\",\n                \"Failed to\",\n            ]\n        )\n        if not has_error:\n            return True\n\n    return False\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.load_rdf","title":"<code>load_rdf()</code>","text":"<p>Load RDF data from configured source.</p> <p>Tries sources in order: rdf_text, rdf_file, qid (from Wikidata).</p> <p>Returns:</p> Type Description <code>ShexValidator</code> <p>Self for method chaining</p> <p>Raises:</p> Type Description <code>ShexValidationError</code> <p>If no valid RDF source or loading fails</p> Source code in <code>gkc/shex.py</code> <pre><code>def load_rdf(self) -&gt; \"ShexValidator\":\n    \"\"\"\n    Load RDF data from configured source.\n\n    Tries sources in order: rdf_text, rdf_file, qid (from Wikidata).\n\n    Returns:\n        Self for method chaining\n\n    Raises:\n        ShexValidationError: If no valid RDF source or loading fails\n    \"\"\"\n    try:\n        if self.rdf_text:\n            self._rdf = self.rdf_text\n        elif self.rdf_file:\n            rdf_path = Path(self.rdf_file)\n            if not rdf_path.exists():\n                msg = f\"RDF file not found: {self.rdf_file}\"\n                raise ShexValidationError(msg)\n            self._rdf = rdf_path.read_text(encoding=\"utf-8\")\n        elif self.qid:\n            self._rdf = fetch_entity_rdf(\n                self.qid, format=\"ttl\", user_agent=self.user_agent\n            )\n        else:\n            raise ShexValidationError(\n                \"No RDF source provided. Specify qid, rdf_text, or rdf_file.\"\n            )\n    except CooperageError as e:\n        raise ShexValidationError(f\"Failed to load RDF: {str(e)}\") from e\n    except OSError as e:\n        raise ShexValidationError(f\"Failed to read RDF file: {str(e)}\") from e\n\n    return self\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.load_specification","title":"<code>load_specification()</code>","text":"<p>Load the ShEx schema specification from configured source.</p> <p>Tries sources in order: schema_text, schema_file, eid (fetch from Wikidata).</p> <p>Returns:</p> Type Description <code>ShexValidator</code> <p>Self for method chaining</p> <p>Raises:</p> Type Description <code>ShexValidationError</code> <p>If no valid schema source or loading fails</p> Source code in <code>gkc/shex.py</code> <pre><code>def load_specification(self) -&gt; \"ShexValidator\":\n    \"\"\"\n    Load the ShEx schema specification from configured source.\n\n    Tries sources in order: schema_text, schema_file, eid (fetch from Wikidata).\n\n    Returns:\n        Self for method chaining\n\n    Raises:\n        ShexValidationError: If no valid schema source or loading fails\n    \"\"\"\n    try:\n        if self.schema_text:\n            self._schema = self.schema_text\n        elif self.schema_file:\n            schema_path = Path(self.schema_file)\n            if not schema_path.exists():\n                raise ShexValidationError(\n                    f\"Schema file not found: {self.schema_file}\"\n                )\n            self._schema = schema_path.read_text(encoding=\"utf-8\")\n        elif self.eid:\n            self._schema = fetch_schema_specification(self.eid, self.user_agent)\n        else:\n            raise ShexValidationError(\n                \"No schema source provided. \"\n                \"Specify eid, schema_text, or schema_file.\"\n            )\n    except CooperageError as e:\n        raise ShexValidationError(f\"Failed to load schema: {str(e)}\") from e\n    except OSError as e:\n        msg = f\"Failed to read schema file: {str(e)}\"\n        raise ShexValidationError(msg) from e\n\n    return self\n</code></pre>"},{"location":"gkc/api/shex/#gkc.shex.ShexValidator.passes_inspection","title":"<code>passes_inspection()</code>","text":"<p>Check if validation passed (alias for is_valid).</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if validation passed, False otherwise</p> <p>Raises:</p> Type Description <code>ShexValidationError</code> <p>If check() hasn't been called yet</p> Source code in <code>gkc/shex.py</code> <pre><code>def passes_inspection(self) -&gt; bool:\n    \"\"\"\n    Check if validation passed (alias for is_valid).\n\n    Returns:\n        True if validation passed, False otherwise\n\n    Raises:\n        ShexValidationError: If check() hasn't been called yet\n    \"\"\"\n    return self.is_valid()\n</code></pre>"},{"location":"gkc/api/shex/#exceptions","title":"Exceptions","text":""},{"location":"gkc/api/shex/#shexvalidationerror","title":"ShexValidationError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when ShEx validation encounters an error.</p> Source code in <code>gkc/shex.py</code> <pre><code>class ShexValidationError(Exception):\n    \"\"\"Raised when ShEx validation encounters an error.\"\"\"\n\n    pass\n</code></pre>"},{"location":"gkc/api/shex/#examples","title":"Examples","text":""},{"location":"gkc/api/shex/#validating-wikidata-entities","title":"Validating Wikidata Entities","text":"<p>Validate a Wikidata item against a published EntitySchema:</p> <pre><code>from gkc import ShexValidator\n\n# Validate federally recognized tribe (Q14708404) against tribe schema (E502)\nvalidator = ShexValidator(qid='Q14708404', eid='E502')\nresult = validator.check()\n\nif result.is_valid():\n    print(\"\u2713 Item conforms to EntitySchema E502\")\nelse:\n    print(\"\u2717 Item does not conform:\")\n    for res in result.results:\n        print(f\"  - {res.reason}\")\n</code></pre>"},{"location":"gkc/api/shex/#validating-local-files","title":"Validating Local Files","text":"<p>Validate local RDF data against a local ShEx schema:</p> <pre><code>from gkc import ShexValidator\n\nvalidator = ShexValidator(\n    rdf_file='path/to/entity.ttl',\n    schema_file='path/to/schema.shex'\n)\n\nresult = validator.check()\nprint(f\"Valid: {result.is_valid()}\")\n</code></pre>"},{"location":"gkc/api/shex/#mixed-sources","title":"Mixed Sources","text":"<p>You can mix Wikidata and local sources:</p> <pre><code># Wikidata entity with local schema\nvalidator = ShexValidator(\n    qid='Q42',\n    schema_file='custom_schema.shex'\n)\nresult = validator.check()\n\n# Local RDF data with Wikidata EntitySchema\nvalidator = ShexValidator(\n    rdf_file='new_entity.ttl',\n    eid='E502'\n)\nresult = validator.check()\n</code></pre>"},{"location":"gkc/api/shex/#using-text-strings","title":"Using Text Strings","text":"<p>For programmatically generated RDF or schemas:</p> <pre><code>from gkc import ShexValidator\n\nmy_rdf = \"\"\"\n@prefix wd: &lt;http://www.wikidata.org/entity/&gt; .\n@prefix wdt: &lt;http://www.wikidata.org/prop/direct/&gt; .\n\nwd:Q42 wdt:P31 wd:Q5 .\n\"\"\"\n\nmy_schema = \"\"\"\nPREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\nPREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n\n&lt;Human&gt; {\n  wdt:P31 [ wd:Q5 ]\n}\n\"\"\"\n\nvalidator = ShexValidator(\n    rdf_text=my_rdf,\n    schema_text=my_schema\n)\n\nresult = validator.check()\n</code></pre>"},{"location":"gkc/api/shex/#fluent-api-pattern","title":"Fluent API Pattern","text":"<p>Load and validate step-by-step:</p> <pre><code>from gkc import ShexValidator\n\nvalidator = ShexValidator(qid='Q42', eid='E502')\n\n# Load schema\nvalidator.load_specification()\nprint(f\"Schema loaded: {len(validator._schema)} characters\")\n\n# Load RDF data\nvalidator.load_rdf()\nprint(f\"RDF loaded: {len(validator._rdf)} characters\")\n\n# Perform validation\nvalidator.evaluate()\n\n# Check result\nif validator.passes_inspection():\n    print(\"\u2713 Validation passed!\")\n</code></pre>"},{"location":"gkc/api/shex/#custom-user-agent","title":"Custom User Agent","text":"<p>When fetching from Wikidata, use a custom user agent:</p> <pre><code>from gkc import ShexValidator\n\nvalidator = ShexValidator(\n    qid='Q42',\n    eid='E502',\n    user_agent='MyBot/1.0 (https://example.com; bot@example.com)'\n)\n\nresult = validator.check()\n</code></pre>"},{"location":"gkc/api/shex/#pre-upload-quality-check","title":"Pre-Upload Quality Check","text":"<p>Validate data before uploading to Wikidata:</p> <pre><code>from gkc import ShexValidator, ShexValidationError\n\ndef validate_before_upload(rdf_data: str, target_schema: str) -&gt; bool:\n    \"\"\"Validate RDF data against target EntitySchema.\"\"\"\n    try:\n        validator = ShexValidator(\n            rdf_text=rdf_data,\n            eid=target_schema\n        )\n\n        result = validator.check()\n\n        if result.is_valid():\n            return True\n        else:\n            # Log validation errors\n            for res in result.results:\n                print(f\"Validation error: {res.reason}\")\n            return False\n\n    except ShexValidationError as e:\n        print(f\"Validation failed: {e}\")\n        return False\n\n# Use in upload workflow\nif validate_before_upload(my_data, 'E502'):\n    upload_to_wikidata(my_data)\nelse:\n    print(\"Fix validation errors before uploading\")\n</code></pre>"},{"location":"gkc/api/shex/#batch-validation","title":"Batch Validation","text":"<p>Validate multiple entities:</p> <pre><code>from gkc import ShexValidator\n\nentities_to_validate = [\n    ('Q14708404', 'Wanapum'),\n    ('Q3551781', 'Umatilla'),\n    ('Q1948829', 'Muckleshoot')\n]\n\nschema_id = 'E502'  # Federally recognized tribe schema\n\nresults = {}\nfor qid, name in entities_to_validate:\n    validator = ShexValidator(qid=qid, eid=schema_id)\n    validator.check()\n    results[name] = validator.is_valid()\n\n# Report\nfor name, valid in results.items():\n    status = \"\u2713\" if valid else \"\u2717\"\n    print(f\"{status} {name}\")\n</code></pre>"},{"location":"gkc/api/shex/#error-handling","title":"Error Handling","text":""},{"location":"gkc/api/shex/#common-error-patterns","title":"Common Error Patterns","text":"<pre><code>from gkc.shex import ShexValidationError, ShexValidator\n\ntry:\n    validator = ShexValidator(qid='Q42', eid='E502')\n    result = validator.check()\n\n    if not result.is_valid():\n        # Parse validation errors\n        for res in result.results:\n            reason = res.reason or \"\"\n\n            if \"not in value set\" in reason:\n                print(f\"Value constraint violation: {reason}\")\n            elif \"does not match\" in reason:\n                print(f\"Format/type mismatch: {reason}\")\n            elif \"Constraint violation\" in reason:\n                print(f\"Cardinality or requirement error: {reason}\")\n\nexcept ShexValidationError as e:\n    print(f\"Validation process failed: {e}\")\n</code></pre>"},{"location":"gkc/api/shex/#handling-missing-sources","title":"Handling Missing Sources","text":"<pre><code>from gkc.shex import ShexValidationError, ShexValidator\n\ntry:\n    validator = ShexValidator()  # No sources provided\n    validator.check()\nexcept ShexValidationError as e:\n    print(f\"Error: {e}\")\n    # Output: \"No schema source provided. Specify eid, schema_text, or schema_file.\"\n</code></pre>"},{"location":"gkc/api/shex/#see-also","title":"See Also","text":"<ul> <li>ShEx CLI Documentation - Command-line interface</li> <li>Utilities Guide - General ShEx validation guide</li> <li>Wikidata EntitySchemas - Wikidata's schema namespace</li> <li>ShEx Primer - Learn ShEx syntax</li> </ul>"},{"location":"gkc/api/shipper/","title":"Shipper API","text":""},{"location":"gkc/api/shipper/#overview","title":"Overview","text":"<p>The Shipper module provides write operations for delivering Bottled data to external knowledge systems. Currently it supports Wikidata write operations using the MediaWiki API, with planned support for Wikimedia Commons and OpenStreetMap.</p> <p>Current implementations: Wikidata production and test instance write operations Future implementations: Wikimedia Commons uploads, OpenStreetMap data contribution</p>"},{"location":"gkc/api/shipper/#quick-start","title":"Quick Start","text":"<pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\n# Authenticate to Wikidata\nauth = WikiverseAuth(\n    username=\"MyUsername@MyBot\",\n    password=\"abc123def456ghi789\"\n)\nauth.login()\n\n# Create a shipper with dry-run enabled by default\nshipper = WikidataShipper(auth=auth)\n\n# Write an item (dry-run, no actual submission)\npayload = {\n    \"labels\": {\"en\": {\"language\": \"en\", \"value\": \"Test Item\"}},\n    \"descriptions\": {\"en\": {\"language\": \"en\", \"value\": \"A test item\"}},\n}\n\nresult = shipper.write_item(\n    payload=payload,\n    summary=\"Creating test item via GKC\",\n    dry_run=True\n)\n\nprint(f\"Status: {result.status}\")\nprint(f\"Warnings: {result.warnings}\")\n</code></pre>"},{"location":"gkc/api/shipper/#classes","title":"Classes","text":""},{"location":"gkc/api/shipper/#shippererror","title":"ShipperError","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a shipper operation fails.</p> <p>Plain meaning: A write or validation step failed.</p> Source code in <code>gkc/shipper.py</code> <pre><code>class ShipperError(Exception):\n    \"\"\"Raised when a shipper operation fails.\n\n    Plain meaning: A write or validation step failed.\n    \"\"\"\n</code></pre>"},{"location":"gkc/api/shipper/#writeresult","title":"WriteResult","text":"<p>Result summary for write operations.</p> <p>Plain meaning: A stable summary of what happened during a write.</p> Source code in <code>gkc/shipper.py</code> <pre><code>@dataclass\nclass WriteResult:\n    \"\"\"Result summary for write operations.\n\n    Plain meaning: A stable summary of what happened during a write.\n    \"\"\"\n\n    entity_id: Optional[str]\n    revision_id: Optional[int]\n    status: str\n    warnings: list[str] = field(default_factory=list)\n    api_response: dict = field(default_factory=dict)\n    request_payload: Optional[dict] = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -&gt; dict:\n        \"\"\"Return a JSON-serializable dictionary.\n\n        Plain meaning: Convert the result into a simple dict.\n        \"\"\"\n\n        return {\n            \"entity_id\": self.entity_id,\n            \"revision_id\": self.revision_id,\n            \"status\": self.status,\n            \"warnings\": list(self.warnings),\n            \"api_response\": dict(self.api_response),\n            \"request_payload\": copy.deepcopy(self.request_payload),\n            \"metadata\": dict(self.metadata),\n        }\n\n    def to_json(self) -&gt; str:\n        \"\"\"Serialize the result to JSON.\n\n        Plain meaning: Turn the result into a JSON string.\n        \"\"\"\n\n        return json.dumps(self.to_dict(), sort_keys=True)\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.WriteResult.to_dict","title":"<code>to_dict()</code>","text":"<p>Return a JSON-serializable dictionary.</p> <p>Plain meaning: Convert the result into a simple dict.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Return a JSON-serializable dictionary.\n\n    Plain meaning: Convert the result into a simple dict.\n    \"\"\"\n\n    return {\n        \"entity_id\": self.entity_id,\n        \"revision_id\": self.revision_id,\n        \"status\": self.status,\n        \"warnings\": list(self.warnings),\n        \"api_response\": dict(self.api_response),\n        \"request_payload\": copy.deepcopy(self.request_payload),\n        \"metadata\": dict(self.metadata),\n    }\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.WriteResult.to_json","title":"<code>to_json()</code>","text":"<p>Serialize the result to JSON.</p> <p>Plain meaning: Turn the result into a JSON string.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def to_json(self) -&gt; str:\n    \"\"\"Serialize the result to JSON.\n\n    Plain meaning: Turn the result into a JSON string.\n    \"\"\"\n\n    return json.dumps(self.to_dict(), sort_keys=True)\n</code></pre>"},{"location":"gkc/api/shipper/#shipper","title":"Shipper","text":"<p>Base class for shippers.</p> <p>Plain meaning: A shared interface for writing Bottled output to targets.</p> Source code in <code>gkc/shipper.py</code> <pre><code>class Shipper:\n    \"\"\"Base class for shippers.\n\n    Plain meaning: A shared interface for writing Bottled output to targets.\n    \"\"\"\n\n    def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n        \"\"\"Write the payload to a target system.\n\n        Plain meaning: Deliver Bottled output to an external API.\n        \"\"\"\n\n        raise NotImplementedError(\"Shipper.write must be implemented by subclasses\")\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.Shipper.write","title":"<code>write(payload, **kwargs)</code>","text":"<p>Write the payload to a target system.</p> <p>Plain meaning: Deliver Bottled output to an external API.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n    \"\"\"Write the payload to a target system.\n\n    Plain meaning: Deliver Bottled output to an external API.\n    \"\"\"\n\n    raise NotImplementedError(\"Shipper.write must be implemented by subclasses\")\n</code></pre>"},{"location":"gkc/api/shipper/#wikidatashipper","title":"WikidataShipper","text":"<p>               Bases: <code>Shipper</code></p> <p>Shipper for Wikidata write operations.</p> <p>Plain meaning: Submit Bottled output to the Wikidata API.</p> Source code in <code>gkc/shipper.py</code> <pre><code>class WikidataShipper(Shipper):\n    \"\"\"Shipper for Wikidata write operations.\n\n    Plain meaning: Submit Bottled output to the Wikidata API.\n    \"\"\"\n\n    def __init__(\n        self,\n        auth: WikiverseAuth,\n        api_url: Optional[str] = None,\n        dry_run_default: bool = True,\n    ):\n        \"\"\"Initialize the Wikidata shipper.\n\n        Plain meaning: Store auth details and default write behavior.\n        \"\"\"\n\n        self.auth = auth\n        self.api_url = api_url or auth.api_url\n        self.dry_run_default = dry_run_default\n\n    def write_item(\n        self,\n        payload: dict,\n        summary: str,\n        entity_id: Optional[str] = None,\n        dry_run: Optional[bool] = None,\n        validate_only: bool = False,\n        tags: Optional[list[str]] = None,\n        bot: bool = False,\n        metadata: Optional[dict[str, Any]] = None,\n    ) -&gt; WriteResult:\n        \"\"\"Create or update a Wikidata item.\n\n        Plain meaning: Build a request for wbeditentity, optionally submit it,\n        and return a stable result summary.\n        \"\"\"\n\n        if not summary or not summary.strip():\n            raise ValueError(\"summary is required for Wikidata write operations\")\n\n        effective_dry_run = self.dry_run_default if dry_run is None else dry_run\n        normalized_payload = self._normalize_payload(payload)\n\n        is_valid, warnings = self._validate_payload(normalized_payload)\n        result_metadata = metadata or {}\n\n        if validate_only:\n            status = \"validated\" if is_valid else \"blocked\"\n            return WriteResult(\n                entity_id=entity_id,\n                revision_id=None,\n                status=status,\n                warnings=warnings,\n                api_response={},\n                request_payload=normalized_payload,\n                metadata=result_metadata,\n            )\n\n        if not is_valid:\n            return WriteResult(\n                entity_id=entity_id,\n                revision_id=None,\n                status=\"blocked\",\n                warnings=warnings,\n                api_response={},\n                request_payload=normalized_payload,\n                metadata=result_metadata,\n            )\n\n        if effective_dry_run:\n            return WriteResult(\n                entity_id=entity_id,\n                revision_id=None,\n                status=\"dry_run\",\n                warnings=warnings,\n                api_response={},\n                request_payload=normalized_payload,\n                metadata=result_metadata,\n            )\n\n        self._ensure_authenticated()\n        csrf_token = self.auth.get_csrf_token()\n\n        request_data = self._build_request_data(\n            payload=normalized_payload,\n            summary=summary,\n            entity_id=entity_id,\n            csrf_token=csrf_token,\n            tags=tags,\n            bot=bot,\n        )\n\n        response = self.auth.session.post(self.api_url, data=request_data)\n        response.raise_for_status()\n        response_json = response.json()\n\n        if \"error\" in response_json:\n            warnings.append(self._format_api_error(response_json[\"error\"]))\n            return WriteResult(\n                entity_id=entity_id,\n                revision_id=None,\n                status=\"error\",\n                warnings=warnings,\n                api_response=response_json,\n                request_payload=normalized_payload,\n                metadata=result_metadata,\n            )\n\n        response_entity = response_json.get(\"entity\", {})\n        response_entity_id = response_entity.get(\"id\") or entity_id\n        revision_id = response_entity.get(\"lastrevid\")\n\n        return WriteResult(\n            entity_id=response_entity_id,\n            revision_id=revision_id,\n            status=\"submitted\",\n            warnings=warnings,\n            api_response=response_json,\n            request_payload=normalized_payload,\n            metadata=result_metadata,\n        )\n\n    def _ensure_authenticated(self) -&gt; None:\n        if not self.auth.is_logged_in():\n            self.auth.login()\n\n    def _normalize_payload(self, payload: dict) -&gt; dict:\n        return copy.deepcopy(payload)\n\n    def _validate_payload(self, payload: dict) -&gt; tuple[bool, list[str]]:\n        warnings: list[str] = []\n        is_valid = True\n\n        labels = payload.get(\"labels\")\n        if not labels or not isinstance(labels, dict):\n            warnings.append(\"Missing labels in payload\")\n            is_valid = False\n\n        descriptions = payload.get(\"descriptions\")\n        if not descriptions or not isinstance(descriptions, dict):\n            warnings.append(\"Missing descriptions in payload\")\n            is_valid = False\n\n        return is_valid, warnings\n\n    def _build_request_data(\n        self,\n        payload: dict,\n        summary: str,\n        entity_id: Optional[str],\n        csrf_token: str,\n        tags: Optional[list[str]],\n        bot: bool,\n    ) -&gt; dict:\n        request_data = {\n            \"action\": \"wbeditentity\",\n            \"format\": \"json\",\n            \"token\": csrf_token,\n            \"data\": json.dumps(payload),\n            \"summary\": summary,\n        }\n\n        if entity_id:\n            request_data[\"id\"] = entity_id\n        else:\n            request_data[\"new\"] = \"item\"\n\n        if tags:\n            request_data[\"tags\"] = \"|\".join(tags)\n\n        if bot:\n            request_data[\"bot\"] = \"1\"\n\n        return request_data\n\n    def _format_api_error(self, error: dict) -&gt; str:\n        code = error.get(\"code\", \"unknown\")\n        info = error.get(\"info\", \"Unknown API error\")\n        return f\"API error {code}: {info}\"\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.WikidataShipper.__init__","title":"<code>__init__(auth, api_url=None, dry_run_default=True)</code>","text":"<p>Initialize the Wikidata shipper.</p> <p>Plain meaning: Store auth details and default write behavior.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def __init__(\n    self,\n    auth: WikiverseAuth,\n    api_url: Optional[str] = None,\n    dry_run_default: bool = True,\n):\n    \"\"\"Initialize the Wikidata shipper.\n\n    Plain meaning: Store auth details and default write behavior.\n    \"\"\"\n\n    self.auth = auth\n    self.api_url = api_url or auth.api_url\n    self.dry_run_default = dry_run_default\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.WikidataShipper.write_item","title":"<code>write_item(payload, summary, entity_id=None, dry_run=None, validate_only=False, tags=None, bot=False, metadata=None)</code>","text":"<p>Create or update a Wikidata item.</p> <p>Plain meaning: Build a request for wbeditentity, optionally submit it, and return a stable result summary.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def write_item(\n    self,\n    payload: dict,\n    summary: str,\n    entity_id: Optional[str] = None,\n    dry_run: Optional[bool] = None,\n    validate_only: bool = False,\n    tags: Optional[list[str]] = None,\n    bot: bool = False,\n    metadata: Optional[dict[str, Any]] = None,\n) -&gt; WriteResult:\n    \"\"\"Create or update a Wikidata item.\n\n    Plain meaning: Build a request for wbeditentity, optionally submit it,\n    and return a stable result summary.\n    \"\"\"\n\n    if not summary or not summary.strip():\n        raise ValueError(\"summary is required for Wikidata write operations\")\n\n    effective_dry_run = self.dry_run_default if dry_run is None else dry_run\n    normalized_payload = self._normalize_payload(payload)\n\n    is_valid, warnings = self._validate_payload(normalized_payload)\n    result_metadata = metadata or {}\n\n    if validate_only:\n        status = \"validated\" if is_valid else \"blocked\"\n        return WriteResult(\n            entity_id=entity_id,\n            revision_id=None,\n            status=status,\n            warnings=warnings,\n            api_response={},\n            request_payload=normalized_payload,\n            metadata=result_metadata,\n        )\n\n    if not is_valid:\n        return WriteResult(\n            entity_id=entity_id,\n            revision_id=None,\n            status=\"blocked\",\n            warnings=warnings,\n            api_response={},\n            request_payload=normalized_payload,\n            metadata=result_metadata,\n        )\n\n    if effective_dry_run:\n        return WriteResult(\n            entity_id=entity_id,\n            revision_id=None,\n            status=\"dry_run\",\n            warnings=warnings,\n            api_response={},\n            request_payload=normalized_payload,\n            metadata=result_metadata,\n        )\n\n    self._ensure_authenticated()\n    csrf_token = self.auth.get_csrf_token()\n\n    request_data = self._build_request_data(\n        payload=normalized_payload,\n        summary=summary,\n        entity_id=entity_id,\n        csrf_token=csrf_token,\n        tags=tags,\n        bot=bot,\n    )\n\n    response = self.auth.session.post(self.api_url, data=request_data)\n    response.raise_for_status()\n    response_json = response.json()\n\n    if \"error\" in response_json:\n        warnings.append(self._format_api_error(response_json[\"error\"]))\n        return WriteResult(\n            entity_id=entity_id,\n            revision_id=None,\n            status=\"error\",\n            warnings=warnings,\n            api_response=response_json,\n            request_payload=normalized_payload,\n            metadata=result_metadata,\n        )\n\n    response_entity = response_json.get(\"entity\", {})\n    response_entity_id = response_entity.get(\"id\") or entity_id\n    revision_id = response_entity.get(\"lastrevid\")\n\n    return WriteResult(\n        entity_id=response_entity_id,\n        revision_id=revision_id,\n        status=\"submitted\",\n        warnings=warnings,\n        api_response=response_json,\n        request_payload=normalized_payload,\n        metadata=result_metadata,\n    )\n</code></pre>"},{"location":"gkc/api/shipper/#commonsshipper","title":"CommonsShipper","text":"<p>               Bases: <code>Shipper</code></p> <p>Shipper scaffold for Wikimedia Commons.</p> <p>Plain meaning: Reserved for future Commons write support.</p> Source code in <code>gkc/shipper.py</code> <pre><code>class CommonsShipper(Shipper):\n    \"\"\"Shipper scaffold for Wikimedia Commons.\n\n    Plain meaning: Reserved for future Commons write support.\n    \"\"\"\n\n    def __init__(self, auth: WikiverseAuth, api_url: Optional[str] = None):\n        \"\"\"Initialize the Commons shipper.\n\n        Plain meaning: Store auth details for future Commons writes.\n        \"\"\"\n\n        self.auth = auth\n        self.api_url = api_url or auth.api_url\n\n    def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n        \"\"\"Write payload to Wikimedia Commons.\n\n        Plain meaning: Placeholder for future Commons write support.\n        \"\"\"\n\n        raise NotImplementedError(\"CommonsShipper.write is not implemented yet\")\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.CommonsShipper.__init__","title":"<code>__init__(auth, api_url=None)</code>","text":"<p>Initialize the Commons shipper.</p> <p>Plain meaning: Store auth details for future Commons writes.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def __init__(self, auth: WikiverseAuth, api_url: Optional[str] = None):\n    \"\"\"Initialize the Commons shipper.\n\n    Plain meaning: Store auth details for future Commons writes.\n    \"\"\"\n\n    self.auth = auth\n    self.api_url = api_url or auth.api_url\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.CommonsShipper.write","title":"<code>write(payload, **kwargs)</code>","text":"<p>Write payload to Wikimedia Commons.</p> <p>Plain meaning: Placeholder for future Commons write support.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n    \"\"\"Write payload to Wikimedia Commons.\n\n    Plain meaning: Placeholder for future Commons write support.\n    \"\"\"\n\n    raise NotImplementedError(\"CommonsShipper.write is not implemented yet\")\n</code></pre>"},{"location":"gkc/api/shipper/#openstreetmapshipper","title":"OpenStreetMapShipper","text":"<p>               Bases: <code>Shipper</code></p> <p>Shipper scaffold for OpenStreetMap.</p> <p>Plain meaning: Reserved for future OpenStreetMap write support.</p> Source code in <code>gkc/shipper.py</code> <pre><code>class OpenStreetMapShipper(Shipper):\n    \"\"\"Shipper scaffold for OpenStreetMap.\n\n    Plain meaning: Reserved for future OpenStreetMap write support.\n    \"\"\"\n\n    def __init__(self, auth: OpenStreetMapAuth):\n        \"\"\"Initialize the OpenStreetMap shipper.\n\n        Plain meaning: Store auth details for future OpenStreetMap writes.\n        \"\"\"\n\n        self.auth = auth\n\n    def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n        \"\"\"Write payload to OpenStreetMap.\n\n        Plain meaning: Placeholder for future OpenStreetMap write support.\n        \"\"\"\n\n        raise NotImplementedError(\"OpenStreetMapShipper.write is not implemented yet\")\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.OpenStreetMapShipper.__init__","title":"<code>__init__(auth)</code>","text":"<p>Initialize the OpenStreetMap shipper.</p> <p>Plain meaning: Store auth details for future OpenStreetMap writes.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def __init__(self, auth: OpenStreetMapAuth):\n    \"\"\"Initialize the OpenStreetMap shipper.\n\n    Plain meaning: Store auth details for future OpenStreetMap writes.\n    \"\"\"\n\n    self.auth = auth\n</code></pre>"},{"location":"gkc/api/shipper/#gkc.shipper.OpenStreetMapShipper.write","title":"<code>write(payload, **kwargs)</code>","text":"<p>Write payload to OpenStreetMap.</p> <p>Plain meaning: Placeholder for future OpenStreetMap write support.</p> Source code in <code>gkc/shipper.py</code> <pre><code>def write(self, payload: dict, **kwargs: Any) -&gt; WriteResult:\n    \"\"\"Write payload to OpenStreetMap.\n\n    Plain meaning: Placeholder for future OpenStreetMap write support.\n    \"\"\"\n\n    raise NotImplementedError(\"OpenStreetMapShipper.write is not implemented yet\")\n</code></pre>"},{"location":"gkc/api/shipper/#examples","title":"Examples","text":""},{"location":"gkc/api/shipper/#create-a-new-wikidata-item-with-dry-run","title":"Create a new Wikidata item with dry-run","text":"<p>Test your payload structure without actually submitting to Wikidata:</p> <pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\nauth = WikiverseAuth()\nauth.login()\n\nshipper = WikidataShipper(auth=auth, dry_run_default=True)\n\n# Prepare a minimal item payload\npayload = {\n    \"labels\": {\n        \"en\": {\"language\": \"en\", \"value\": \"Douglas Adams\"},\n        \"de\": {\"language\": \"de\", \"value\": \"Douglas Adams\"}\n    },\n    \"descriptions\": {\n        \"en\": {\"language\": \"en\", \"value\": \"English science fiction writer\"}\n    },\n    \"claims\": {\n        \"P31\": [{  # instance of\n            \"mainsnak\": {\n                \"snaktype\": \"value\",\n                \"property\": \"P31\",\n                \"datavalue\": {\n                    \"value\": {\"entity-type\": \"item\", \"id\": \"Q5\"},\n                    \"type\": \"wikibase-entityid\"\n                }\n            },\n            \"type\": \"statement\",\n            \"rank\": \"normal\"\n        }]\n    }\n}\n\n# Dry-run write (no actual submission)\nresult = shipper.write_item(\n    payload=payload,\n    summary=\"Creating Douglas Adams item\",\n    dry_run=True\n)\n\nprint(f\"Dry-run status: {result.status}\")\nprint(f\"Payload validated: {len(result.warnings) == 0}\")\nif result.warnings:\n    print(f\"Warnings: {result.warnings}\")\n</code></pre>"},{"location":"gkc/api/shipper/#validate-payload-without-submitting","title":"Validate payload without submitting","text":"<p>Use validation-only mode to check payload structure:</p> <pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\nauth = WikiverseAuth()\nshipper = WikidataShipper(auth=auth)\n\n# Missing required fields\nincomplete_payload = {\n    \"labels\": {\"en\": {\"language\": \"en\", \"value\": \"Test\"}}\n    # Missing descriptions\n}\n\nresult = shipper.write_item(\n    payload=incomplete_payload,\n    summary=\"Test validation\",\n    validate_only=True\n)\n\nif result.status == \"blocked\":\n    print(\"Validation failed:\")\n    for warning in result.warnings:\n        print(f\"  - {warning}\")\nelse:\n    print(\"Payload is valid\")\n</code></pre>"},{"location":"gkc/api/shipper/#submit-to-testwikidataorg-for-testing","title":"Submit to test.wikidata.org for testing","text":"<p>Use the test instance before submitting to production:</p> <pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\n# Authenticate to test.wikidata.org\nauth = WikiverseAuth(\n    username=\"TestBot@BotAccount\",\n    password=\"test_password_123\",\n    api_url=\"wikidata_test\"\n)\nauth.login()\n\n# Create shipper with dry-run disabled for actual submission\nshipper = WikidataShipper(auth=auth, dry_run_default=False)\n\npayload = {\n    \"labels\": {\"en\": {\"language\": \"en\", \"value\": \"Test Item\"}},\n    \"descriptions\": {\"en\": {\"language\": \"en\", \"value\": \"Testing item creation\"}},\n}\n\n# Submit to test instance\nresult = shipper.write_item(\n    payload=payload,\n    summary=\"Test item creation via GKC\",\n    dry_run=False,\n    tags=[\"gkc\", \"test\"],\n    bot=True\n)\n\nif result.status == \"submitted\":\n    print(f\"Created item: {result.entity_id}\")\n    print(f\"Revision ID: {result.revision_id}\")\nelif result.status == \"error\":\n    print(f\"Submission failed: {result.warnings}\")\n</code></pre>"},{"location":"gkc/api/shipper/#update-an-existing-wikidata-item","title":"Update an existing Wikidata item","text":"<p>Add claims to an existing item by providing the entity ID:</p> <pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\nauth = WikiverseAuth()\nauth.login()\n\nshipper = WikidataShipper(auth=auth, dry_run_default=False)\n\n# Add a new claim to Q42 (Douglas Adams)\npayload = {\n    \"claims\": {\n        \"P106\": [{  # occupation\n            \"mainsnak\": {\n                \"snaktype\": \"value\",\n                \"property\": \"P106\",\n                \"datavalue\": {\n                    \"value\": {\"entity-type\": \"item\", \"id\": \"Q36180\"},\n                    \"type\": \"wikibase-entityid\"\n                }\n            },\n            \"type\": \"statement\",\n            \"rank\": \"normal\"\n        }]\n    }\n}\n\nresult = shipper.write_item(\n    payload=payload,\n    summary=\"Adding occupation claim\",\n    entity_id=\"Q42\",  # Update existing item\n    dry_run=True,  # Use dry-run for this example\n    bot=True\n)\n\nprint(f\"Update status: {result.status}\")\n</code></pre>"},{"location":"gkc/api/shipper/#batch-operations-with-metadata-tracking","title":"Batch operations with metadata tracking","text":"<p>Track multiple write operations with custom metadata:</p> <pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\nauth = WikiverseAuth()\nauth.login()\n\nshipper = WikidataShipper(auth=auth, dry_run_default=True)\n\nitems_to_create = [\n    {\"name\": \"Item 1\", \"description\": \"First test item\"},\n    {\"name\": \"Item 2\", \"description\": \"Second test item\"},\n    {\"name\": \"Item 3\", \"description\": \"Third test item\"},\n]\n\nresults = []\nfor idx, item_data in enumerate(items_to_create):\n    payload = {\n        \"labels\": {\"en\": {\"language\": \"en\", \"value\": item_data[\"name\"]}},\n        \"descriptions\": {\"en\": {\"language\": \"en\", \"value\": item_data[\"description\"]}},\n    }\n\n    result = shipper.write_item(\n        payload=payload,\n        summary=f\"Batch creation: {item_data['name']}\",\n        dry_run=True,\n        metadata={\n            \"batch_id\": \"batch_001\",\n            \"item_index\": idx,\n            \"source\": \"test_dataset\"\n        }\n    )\n\n    results.append(result)\n\n# Analyze batch results\nsuccessful = [r for r in results if r.status in (\"dry_run\", \"submitted\")]\nblocked = [r for r in results if r.status == \"blocked\"]\n\nprint(f\"Successful: {len(successful)}, Blocked: {len(blocked)}\")\n</code></pre>"},{"location":"gkc/api/shipper/#error-handling","title":"Error Handling","text":""},{"location":"gkc/api/shipper/#handle-validation-errors","title":"Handle validation errors","text":"<pre><code>from gkc import WikiverseAuth\nfrom gkc.shipper import WikidataShipper\n\nauth = WikiverseAuth()\nshipper = WikidataShipper(auth=auth)\n\npayload = {\n    # Missing required labels and descriptions\n}\n\nresult = shipper.write_item(\n    payload=payload,\n    summary=\"Test\",\n    validate_only=True\n)\n\nif result.status == \"blocked\":\n    print(\"Payload validation failed:\")\n    for warning in result.warnings:\n        print(f\"  - {warning}\")\n    # Fix issues before retrying\n</code></pre>"},{"location":"gkc/api/shipper/#handle-api-errors","title":"Handle API errors","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\nfrom gkc.shipper import WikidataShipper\n\ntry:\n    auth = WikiverseAuth()\n    auth.login()\n\n    shipper = WikidataShipper(auth=auth, dry_run_default=False)\n\n    payload = {\n        \"labels\": {\"en\": {\"language\": \"en\", \"value\": \"Test\"}},\n        \"descriptions\": {\"en\": {\"language\": \"en\", \"value\": \"Test item\"}},\n    }\n\n    result = shipper.write_item(\n        payload=payload,\n        summary=\"Test submission\",\n        dry_run=False\n    )\n\n    if result.status == \"error\":\n        print(f\"API error occurred: {result.warnings}\")\n        print(f\"Full API response: {result.api_response}\")\n    elif result.status == \"submitted\":\n        print(f\"Successfully created: {result.entity_id}\")\n\nexcept AuthenticationError as e:\n    print(f\"Authentication failed: {e}\")\nexcept ValueError as e:\n    print(f\"Invalid input: {e}\")\n</code></pre>"},{"location":"gkc/api/shipper/#missing-or-invalid-authentication","title":"Missing or invalid authentication","text":"<pre><code>from gkc import WikiverseAuth, AuthenticationError\nfrom gkc.shipper import WikidataShipper\n\ntry:\n    # Missing credentials\n    auth = WikiverseAuth()\n    auth.login()\n\n    shipper = WikidataShipper(auth=auth, dry_run_default=False)\n\n    # This will fail if not authenticated\n    result = shipper.write_item(\n        payload={\"labels\": {}, \"descriptions\": {}},\n        summary=\"Test\",\n        dry_run=False\n    )\n\nexcept AuthenticationError as e:\n    print(f\"Please set WIKIVERSE_USERNAME and WIKIVERSE_PASSWORD: {e}\")\n</code></pre>"},{"location":"gkc/api/shipper/#see-also","title":"See Also","text":"<ul> <li>Authentication API - Required for all write operations</li> <li>Shipping - Conceptual overview of the shipping stage</li> <li>MediaWiki Wikibase API - Underlying API documentation</li> </ul>"},{"location":"gkc/api/sparql/","title":"SPARQL Query Utilities for GKC","text":"<p>A comprehensive SPARQL query utility module for the Global Knowledge Commons (GKC) project, providing a clean Pythonic interface for querying Wikidata and other SPARQL endpoints.</p>"},{"location":"gkc/api/sparql/#quick-start","title":"Quick Start","text":"<pre><code>from gkc import SPARQLQuery\n\n# Create executor\nexecutor = SPARQLQuery()\n\n# Execute query\nresults = executor.query(\"\"\"\n    SELECT ?item ?itemLabel WHERE {\n      ?item wdt:P31 wd:Q146 .\n      SERVICE wikibase:label {\n        bd:serviceParam wikibase:language \"en\" .\n      }\n    }\n    LIMIT 10\n\"\"\")\n\n# Convert to DataFrame\ndf = executor.to_dataframe(query)\n\n# Export to CSV\nexecutor.to_csv(query, filepath=\"results.csv\")\n</code></pre>"},{"location":"gkc/api/sparql/#features","title":"Features","text":"<ul> <li>Multiple Input Formats: Raw SPARQL or Wikidata Query Service URLs</li> <li>Multiple Output Formats: JSON, DataFrames, CSV, Dictionary lists</li> <li>Flexible Configuration: Custom endpoints, timeouts, user agents</li> <li>Robust Error Handling: Comprehensive error messages and exception handling</li> <li>Optional Pandas Support: Works with or without pandas</li> <li>Type Hints: Full type annotations for IDE support</li> <li>Comprehensive Tests: 24 test cases with 83% coverage</li> <li>Complete Documentation: Full API reference and examples</li> </ul>"},{"location":"gkc/api/sparql/#installation","title":"Installation","text":"<p>The SPARQL module is included in GKC. For optional pandas support:</p> <pre><code>pip install pandas\n</code></pre>"},{"location":"gkc/api/sparql/#usage","title":"Usage","text":""},{"location":"gkc/api/sparql/#basic-query","title":"Basic Query","text":"<pre><code>from gkc import SPARQLQuery\n\nexecutor = SPARQLQuery()\nresults = executor.query(\"SELECT ?item WHERE { ?item wdt:P31 wd:Q5 }\")\n</code></pre>"},{"location":"gkc/api/sparql/#query-from-wikidata-url","title":"Query from Wikidata URL","text":"<pre><code># Share queries as Wikidata URLs\nurl = \"https://query.wikidata.org/#SELECT%20?item%20WHERE%20...\"\nresults = executor.query(url)  # Automatically extracts and executes\n</code></pre>"},{"location":"gkc/api/sparql/#convert-to-dataframe","title":"Convert to DataFrame","text":"<pre><code>df = executor.to_dataframe(query)\nprint(df.head())\n</code></pre>"},{"location":"gkc/api/sparql/#export-to-csv","title":"Export to CSV","text":"<pre><code>executor.to_csv(query, filepath=\"results.csv\")\n</code></pre>"},{"location":"gkc/api/sparql/#custom-endpoints","title":"Custom Endpoints","text":"<pre><code>executor = SPARQLQuery(\n    endpoint=\"https://dbpedia.org/sparql\",\n    timeout=60\n)\n</code></pre>"},{"location":"gkc/api/sparql/#api-reference","title":"API Reference","text":""},{"location":"gkc/api/sparql/#classes","title":"Classes","text":""},{"location":"gkc/api/sparql/#sparqlquery","title":"<code>SPARQLQuery</code>","text":"<p>Main class for executing SPARQL queries.</p> <p>Methods: - <code>query(query, format='json', raw=False)</code> - Execute query - <code>to_dict_list(query)</code> - Convert to list of dicts - <code>to_dataframe(query)</code> - Convert to DataFrame - <code>to_csv(query, filepath=None)</code> - Export to CSV - <code>parse_wikidata_query_url(url)</code> - Extract query from URL (static) - <code>normalize_query(query)</code> - Normalize query string (static)</p>"},{"location":"gkc/api/sparql/#sparqlerror","title":"<code>SPARQLError</code>","text":"<p>Custom exception for SPARQL query errors.</p>"},{"location":"gkc/api/sparql/#functions","title":"Functions","text":""},{"location":"gkc/api/sparql/#execute_sparqlquery-endpoint-formatjson","title":"<code>execute_sparql(query, endpoint=..., format='json')</code>","text":"<p>Quick function to execute a single query.</p>"},{"location":"gkc/api/sparql/#execute_sparql_to_dataframequery-endpoint","title":"<code>execute_sparql_to_dataframe(query, endpoint=...)</code>","text":"<p>Quick function to execute query and return DataFrame.</p>"},{"location":"gkc/api/sparql/#documentation","title":"Documentation","text":"<ul> <li>Utilities Guide - SPARQL usage patterns and examples</li> <li>Examples</li> </ul>"},{"location":"gkc/api/sparql/#examples","title":"Examples","text":""},{"location":"gkc/api/sparql/#example-1-find-cities-with-large-populations","title":"Example 1: Find Cities with Large Populations","text":"<pre><code>from gkc import SPARQLQuery\n\nexecutor = SPARQLQuery()\n\nquery = \"\"\"\nSELECT ?item ?itemLabel ?population WHERE {\n  ?item wdt:P31 wd:Q3624078 .\n  ?item wdt:P1082 ?population .\n  FILTER(?population &gt; 5000000)\n  SERVICE wikibase:label {\n    bd:serviceParam wikibase:language \"en\" .\n  }\n}\nORDER BY DESC(?population)\nLIMIT 10\n\"\"\"\n\nresults = executor.to_dict_list(query)\nfor row in results:\n    print(f\"{row['itemLabel']}: {row['population']}\")\n</code></pre>"},{"location":"gkc/api/sparql/#example-2-data-analysis-with-dataframe","title":"Example 2: Data Analysis with DataFrame","text":"<pre><code>from gkc import execute_sparql_to_dataframe\n\ndf = execute_sparql_to_dataframe(\"\"\"\nSELECT ?item ?itemLabel ?population WHERE {\n  ?item wdt:P31 wd:Q3624078 .\n  ?item wdt:P1082 ?population .\n}\n\"\"\")\n\n# Analyze with pandas\ntop_10 = df.nlargest(10, 'population')\nprint(top_10)\n</code></pre>"},{"location":"gkc/api/sparql/#testing","title":"Testing","text":"<p>Run tests with:</p> <pre><code>pytest tests/test_sparql.py -v\n</code></pre> <p>Results: - 22 tests passed - 2 tests skipped (pandas optional) - 83% code coverage</p>"},{"location":"gkc/api/sparql/#resources","title":"Resources","text":"<ul> <li>Wikidata Query Service</li> <li>SPARQL Tutorial</li> <li>Wikidata Properties</li> </ul>"},{"location":"gkc/api/sparql/#license","title":"License","text":"<p>MIT License - See LICENSE file for details</p>"},{"location":"gkc/api/sparql/#author","title":"Author","text":"<p>GKC Contributors</p>"},{"location":"gkc/api/spirit_safe/","title":"SpiritSafe API","text":""},{"location":"gkc/api/spirit_safe/#overview","title":"Overview","text":"<p>The <code>gkc.spirit_safe</code> module provides profile registry integration, SPARQL lookup hydration, and cache management for SpiritSafe-backed workflows.</p> <p>This module supports two source modes:</p> <ul> <li><code>github</code> (default): fetches profile and query assets from the SpiritSafe repository</li> <li><code>local</code>: uses a local SpiritSafe clone for branch-based development and testing</li> </ul>"},{"location":"gkc/api/spirit_safe/#source-configuration","title":"Source Configuration","text":""},{"location":"gkc/api/spirit_safe/#spiritsafesourceconfig","title":"<code>SpiritSafeSourceConfig</code>","text":"<p>Package-level configuration for SpiritSafe source location.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>SpiritSafeSourceMode</code> <p>Source mode (\"github\" or \"local\")</p> <code>'github'</code> <code>github_repo</code> <code>str</code> <p>GitHub repository slug for SpiritSafe assets</p> <code>DEFAULT_SPIRIT_SAFE_GITHUB_REPO</code> <code>github_ref</code> <code>str</code> <p>Git ref used for GitHub raw file resolution</p> <code>'main'</code> <code>local_root</code> <code>Optional[Path]</code> <p>Local SpiritSafe clone root when mode is \"local\"</p> <code>None</code> <p>Plain meaning: Decide whether SpiritSafe assets come from GitHub or local disk.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>@dataclass(frozen=True)\nclass SpiritSafeSourceConfig:\n    \"\"\"Package-level configuration for SpiritSafe source location.\n\n    Args:\n        mode: Source mode (\"github\" or \"local\")\n        github_repo: GitHub repository slug for SpiritSafe assets\n        github_ref: Git ref used for GitHub raw file resolution\n        local_root: Local SpiritSafe clone root when mode is \"local\"\n\n    Plain meaning: Decide whether SpiritSafe assets come from GitHub or local disk.\n    \"\"\"\n\n    mode: SpiritSafeSourceMode = \"github\"\n    github_repo: str = DEFAULT_SPIRIT_SAFE_GITHUB_REPO\n    github_ref: str = \"main\"\n    local_root: Optional[Path] = None\n\n    def resolve_cache_dir(self) -&gt; Path:\n        \"\"\"Resolve default cache directory for the configured source.\n\n        Returns:\n            Filesystem path to cache directory.\n        \"\"\"\n        if self.mode == \"local\" and self.local_root is not None:\n            return self.local_root / \"cache\"\n\n        repo_slug = self.github_repo.replace(\"/\", \"_\")\n        return Path.home() / \".cache\" / \"gkc\" / \"spiritsafe\" / repo_slug / \"cache\"\n\n    def resolve_relative(self, relative_path: str) -&gt; Union[Path, str]:\n        \"\"\"Resolve a SpiritSafe-relative path to local path or GitHub raw URL.\n\n        Args:\n            relative_path: Relative path inside SpiritSafe repository.\n\n        Returns:\n            Local filesystem path (local mode) or GitHub raw URL (github mode).\n        \"\"\"\n        normalized = relative_path.lstrip(\"/\")\n        if self.mode == \"local\":\n            if self.local_root is None:\n                raise ValueError(\"local_root is required when mode='local'\")\n            return self.local_root / normalized\n\n        return (\n            f\"https://raw.githubusercontent.com/{self.github_repo}/\"\n            f\"{self.github_ref}/{normalized}\"\n        )\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.SpiritSafeSourceConfig.resolve_cache_dir","title":"<code>resolve_cache_dir()</code>","text":"<p>Resolve default cache directory for the configured source.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Filesystem path to cache directory.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def resolve_cache_dir(self) -&gt; Path:\n    \"\"\"Resolve default cache directory for the configured source.\n\n    Returns:\n        Filesystem path to cache directory.\n    \"\"\"\n    if self.mode == \"local\" and self.local_root is not None:\n        return self.local_root / \"cache\"\n\n    repo_slug = self.github_repo.replace(\"/\", \"_\")\n    return Path.home() / \".cache\" / \"gkc\" / \"spiritsafe\" / repo_slug / \"cache\"\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.SpiritSafeSourceConfig.resolve_relative","title":"<code>resolve_relative(relative_path)</code>","text":"<p>Resolve a SpiritSafe-relative path to local path or GitHub raw URL.</p> <p>Parameters:</p> Name Type Description Default <code>relative_path</code> <code>str</code> <p>Relative path inside SpiritSafe repository.</p> required <p>Returns:</p> Type Description <code>Union[Path, str]</code> <p>Local filesystem path (local mode) or GitHub raw URL (github mode).</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def resolve_relative(self, relative_path: str) -&gt; Union[Path, str]:\n    \"\"\"Resolve a SpiritSafe-relative path to local path or GitHub raw URL.\n\n    Args:\n        relative_path: Relative path inside SpiritSafe repository.\n\n    Returns:\n        Local filesystem path (local mode) or GitHub raw URL (github mode).\n    \"\"\"\n    normalized = relative_path.lstrip(\"/\")\n    if self.mode == \"local\":\n        if self.local_root is None:\n            raise ValueError(\"local_root is required when mode='local'\")\n        return self.local_root / normalized\n\n    return (\n        f\"https://raw.githubusercontent.com/{self.github_repo}/\"\n        f\"{self.github_ref}/{normalized}\"\n    )\n</code></pre>"},{"location":"gkc/api/spirit_safe/#set_spirit_safe_source","title":"<code>set_spirit_safe_source</code>","text":"<p>Set package-wide SpiritSafe source location.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>SpiritSafeSourceMode</code> <p>Source mode (\"github\" or \"local\").</p> <code>'github'</code> <code>github_repo</code> <code>str</code> <p>GitHub repository slug for SpiritSafe assets.</p> <code>DEFAULT_SPIRIT_SAFE_GITHUB_REPO</code> <code>github_ref</code> <code>str</code> <p>Git ref used for GitHub raw file resolution.</p> <code>'main'</code> <code>local_root</code> <code>Optional[Union[str, Path]]</code> <p>Local SpiritSafe clone root when mode is \"local\".</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If local mode is requested without local_root.</p> <p>Plain meaning: Configure where SpiritSafe profiles/queries/caches are resolved.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def set_spirit_safe_source(\n    mode: SpiritSafeSourceMode = \"github\",\n    github_repo: str = DEFAULT_SPIRIT_SAFE_GITHUB_REPO,\n    github_ref: str = \"main\",\n    local_root: Optional[Union[str, Path]] = None,\n) -&gt; None:\n    \"\"\"Set package-wide SpiritSafe source location.\n\n    Args:\n        mode: Source mode (\"github\" or \"local\").\n        github_repo: GitHub repository slug for SpiritSafe assets.\n        github_ref: Git ref used for GitHub raw file resolution.\n        local_root: Local SpiritSafe clone root when mode is \"local\".\n\n    Raises:\n        ValueError: If local mode is requested without local_root.\n\n    Plain meaning: Configure where SpiritSafe profiles/queries/caches are resolved.\n    \"\"\"\n    global _SPIRIT_SAFE_SOURCE_CONFIG\n\n    normalized_local_root: Optional[Path] = None\n    if mode == \"local\":\n        if local_root is None:\n            raise ValueError(\"local_root is required when mode='local'\")\n        normalized_local_root = Path(local_root).expanduser().resolve()\n\n    _SPIRIT_SAFE_SOURCE_CONFIG = SpiritSafeSourceConfig(\n        mode=mode,\n        github_repo=github_repo,\n        github_ref=github_ref,\n        local_root=normalized_local_root,\n    )\n</code></pre>"},{"location":"gkc/api/spirit_safe/#get_spirit_safe_source","title":"<code>get_spirit_safe_source</code>","text":"<p>Get current package-wide SpiritSafe source configuration.</p> <p>Returns:</p> Type Description <code>SpiritSafeSourceConfig</code> <p>Active SpiritSafe source configuration.</p> <p>Plain meaning: See where SpiritSafe data is configured to come from.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def get_spirit_safe_source() -&gt; SpiritSafeSourceConfig:\n    \"\"\"Get current package-wide SpiritSafe source configuration.\n\n    Returns:\n        Active SpiritSafe source configuration.\n\n    Plain meaning: See where SpiritSafe data is configured to come from.\n    \"\"\"\n    return _SPIRIT_SAFE_SOURCE_CONFIG\n</code></pre>"},{"location":"gkc/api/spirit_safe/#profile-registry-access","title":"Profile Registry Access","text":""},{"location":"gkc/api/spirit_safe/#profilemetadata","title":"<code>ProfileMetadata</code>","text":"<p>Metadata for a SpiritSafe profile registrant.</p> <p>This dataclass represents the structured metadata from a profile's metadata.yaml file, supporting discovery, versioning, and governance.</p> <p>Attributes:</p> Name Type Description <code>profile_id</code> <code>str</code> <p>Profile identifier (directory name)</p> <code>name</code> <code>str</code> <p>Human-readable profile name</p> <code>description</code> <code>str</code> <p>Profile description</p> <code>version</code> <code>str</code> <p>Semantic version string</p> <code>status</code> <code>str</code> <p>Profile status (e.g., \"stable\", \"draft\", \"deprecated\")</p> <code>published_date</code> <code>Optional[str]</code> <p>Publication date (ISO 8601 string)</p> <code>authors</code> <code>list[dict[str, str]]</code> <p>List of author dicts with 'name' and optional 'email'</p> <code>maintainers</code> <code>list[dict[str, str]]</code> <p>List of maintainer dicts with 'name' and optional 'email'</p> <code>source_references</code> <code>list[dict[str, str]]</code> <p>List of reference dicts with 'name' and 'url'</p> <code>related_profiles</code> <code>list[str]</code> <p>List of related profile IDs</p> <code>community_feedback</code> <code>dict[str, str]</code> <p>Dict with issue tracker and other feedback URLs</p> <code>datatypes_used</code> <code>list[str]</code> <p>List of Wikibase datatypes used in profile</p> <code>statements_count</code> <code>Optional[int]</code> <p>Number of statements defined in profile</p> <code>references_required</code> <code>Optional[bool]</code> <p>Whether references are required</p> <code>qualifiers_used</code> <code>list[str]</code> <p>List of qualifier property IDs used</p> <code>sparql_sources</code> <code>list[str]</code> <p>List of SPARQL query filenames</p> <code>raw_metadata</code> <code>dict[str, Any]</code> <p>Complete raw metadata dict for access to additional fields</p> <p>Plain meaning: Structured information about a profile package.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>@dataclass(frozen=True)\nclass ProfileMetadata:\n    \"\"\"Metadata for a SpiritSafe profile registrant.\n\n    This dataclass represents the structured metadata from a profile's\n    metadata.yaml file, supporting discovery, versioning, and governance.\n\n    Attributes:\n        profile_id: Profile identifier (directory name)\n        name: Human-readable profile name\n        description: Profile description\n        version: Semantic version string\n        status: Profile status (e.g., \"stable\", \"draft\", \"deprecated\")\n        published_date: Publication date (ISO 8601 string)\n        authors: List of author dicts with 'name' and optional 'email'\n        maintainers: List of maintainer dicts with 'name' and optional 'email'\n        source_references: List of reference dicts with 'name' and 'url'\n        related_profiles: List of related profile IDs\n        community_feedback: Dict with issue tracker and other feedback URLs\n        datatypes_used: List of Wikibase datatypes used in profile\n        statements_count: Number of statements defined in profile\n        references_required: Whether references are required\n        qualifiers_used: List of qualifier property IDs used\n        sparql_sources: List of SPARQL query filenames\n        raw_metadata: Complete raw metadata dict for access to additional fields\n\n    Plain meaning: Structured information about a profile package.\n    \"\"\"\n\n    profile_id: str\n    name: str\n    description: str\n    version: str\n    status: str\n    published_date: Optional[str] = None\n    authors: list[dict[str, str]] = field(default_factory=list)\n    maintainers: list[dict[str, str]] = field(default_factory=list)\n    source_references: list[dict[str, str]] = field(default_factory=list)\n    related_profiles: list[str] = field(default_factory=list)\n    community_feedback: dict[str, str] = field(default_factory=dict)\n    datatypes_used: list[str] = field(default_factory=list)\n    statements_count: Optional[int] = None\n    references_required: Optional[bool] = None\n    qualifiers_used: list[str] = field(default_factory=list)\n    sparql_sources: list[str] = field(default_factory=list)\n    raw_metadata: dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#list_profiles","title":"<code>list_profiles</code>","text":"<p>List all available profile IDs in the configured SpiritSafe source.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of profile identifiers (directory names under profiles/)</p> Example <p>profiles = list_profiles() print(profiles) ['TribalGovernmentUS', 'OfficeHeldByHeadOfState']</p> Note <p>For GitHub mode, this requires an API call to list directory contents. For local mode, this scans the local profiles/ directory.</p> <p>Design Question: Should we maintain a central registry.yaml file in SpiritSafe to avoid GitHub API calls and provide additional metadata like profile categories, deprecation warnings, or featured profiles?</p> <p>Plain meaning: See what entity profiles are available.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def list_profiles() -&gt; list[str]:\n    \"\"\"List all available profile IDs in the configured SpiritSafe source.\n\n    Returns:\n        List of profile identifiers (directory names under profiles/)\n\n    Example:\n        &gt;&gt;&gt; profiles = list_profiles()\n        &gt;&gt;&gt; print(profiles)\n        ['TribalGovernmentUS', 'OfficeHeldByHeadOfState']\n\n    Note:\n        For GitHub mode, this requires an API call to list directory contents.\n        For local mode, this scans the local profiles/ directory.\n\n        **Design Question**: Should we maintain a central registry.yaml file\n        in SpiritSafe to avoid GitHub API calls and provide additional metadata\n        like profile categories, deprecation warnings, or featured profiles?\n\n    Plain meaning: See what entity profiles are available.\n    \"\"\"\n    source = get_spirit_safe_source()\n\n    if source.mode == \"local\":\n        if source.local_root is None:\n            raise ValueError(\"local_root required for local mode\")\n        profiles_dir = source.local_root / \"profiles\"\n        if not profiles_dir.exists():\n            return []\n        # List directories only\n        return sorted(\n            [\n                item.name\n                for item in profiles_dir.iterdir()\n                if item.is_dir() and not item.name.startswith(\".\")\n            ]\n        )\n\n    # GitHub mode: use GitHub API to list directory contents\n    api_url = (\n        f\"https://api.github.com/repos/{source.github_repo}/\"\n        f\"contents/profiles?ref={source.github_ref}\"\n    )\n    try:\n        response = requests.get(api_url, timeout=10)\n        response.raise_for_status()\n        contents = response.json()\n        # Filter for directories only\n        return sorted([item[\"name\"] for item in contents if item[\"type\"] == \"dir\"])\n    except requests.RequestException as exc:\n        raise RuntimeError(\n            f\"Failed to list profiles from {source.github_repo}: {exc}\"\n        ) from exc\n</code></pre>"},{"location":"gkc/api/spirit_safe/#profile_exists","title":"<code>profile_exists</code>","text":"<p>Check if a profile exists in the configured SpiritSafe source.</p> <p>Parameters:</p> Name Type Description Default <code>profile_id</code> <code>str</code> <p>Profile identifier to check</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if profile exists, False otherwise</p> Example <p>if profile_exists(\"TribalGovernmentUS\"): ...     print(\"Profile found\")</p> <p>Plain meaning: Check if a specific entity profile is available.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def profile_exists(profile_id: str) -&gt; bool:\n    \"\"\"Check if a profile exists in the configured SpiritSafe source.\n\n    Args:\n        profile_id: Profile identifier to check\n\n    Returns:\n        True if profile exists, False otherwise\n\n    Example:\n        &gt;&gt;&gt; if profile_exists(\"TribalGovernmentUS\"):\n        ...     print(\"Profile found\")\n\n    Plain meaning: Check if a specific entity profile is available.\n    \"\"\"\n    try:\n        # Attempt to resolve the profile path\n        profile_path = f\"profiles/{profile_id}/profile.yaml\"\n        source = get_spirit_safe_source()\n        resolved = source.resolve_relative(profile_path)\n        _read_text_from_resolved_path(resolved)\n        return True\n    except Exception:\n        return False\n</code></pre>"},{"location":"gkc/api/spirit_safe/#get_profile_metadata","title":"<code>get_profile_metadata</code>","text":"<p>Load metadata for a profile from its metadata.yaml file.</p> <p>Parameters:</p> Name Type Description Default <code>profile_id</code> <code>str</code> <p>Profile identifier (directory name)</p> required <p>Returns:</p> Type Description <code>ProfileMetadata</code> <p>Structured profile metadata</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If profile or metadata.yaml doesn't exist</p> <code>ValueError</code> <p>If metadata.yaml is invalid</p> Example <p>metadata = get_profile_metadata(\"TribalGovernmentUS\") print(metadata.name) 'Federally Recognized Tribe' print(metadata.version) '1.0.0'</p> <p>Plain meaning: Get information about a profile without loading its full definition.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def get_profile_metadata(profile_id: str) -&gt; ProfileMetadata:\n    \"\"\"Load metadata for a profile from its metadata.yaml file.\n\n    Args:\n        profile_id: Profile identifier (directory name)\n\n    Returns:\n        Structured profile metadata\n\n    Raises:\n        FileNotFoundError: If profile or metadata.yaml doesn't exist\n        ValueError: If metadata.yaml is invalid\n\n    Example:\n        &gt;&gt;&gt; metadata = get_profile_metadata(\"TribalGovernmentUS\")\n        &gt;&gt;&gt; print(metadata.name)\n        'Federally Recognized Tribe'\n        &gt;&gt;&gt; print(metadata.version)\n        '1.0.0'\n\n    Plain meaning: Get information about a profile without loading its full definition.\n    \"\"\"\n    source = get_spirit_safe_source()\n    metadata_path = f\"profiles/{profile_id}/metadata.yaml\"\n    resolved = source.resolve_relative(metadata_path)\n\n    try:\n        metadata_text = _read_text_from_resolved_path(resolved)\n        raw = yaml.safe_load(metadata_text) or {}\n    except Exception as exc:\n        raise FileNotFoundError(\n            f\"Could not load metadata for profile '{profile_id}'\"\n        ) from exc\n\n    # Validate required fields\n    if \"name\" not in raw:\n        raise ValueError(\n            f\"Profile '{profile_id}' metadata missing required field 'name'\"\n        )\n    if \"version\" not in raw:\n        raise ValueError(\n            f\"Profile '{profile_id}' metadata missing required field 'version'\"\n        )\n    if \"status\" not in raw:\n        raise ValueError(\n            f\"Profile '{profile_id}' metadata missing required field 'status'\"\n        )\n\n    # Normalize published_date to string if it was parsed as date object\n    published_date = raw.get(\"published_date\")\n    if published_date is not None and not isinstance(published_date, str):\n        # YAML may parse ISO dates as date objects\n        published_date = str(published_date)\n\n    return ProfileMetadata(\n        profile_id=profile_id,\n        name=raw[\"name\"],\n        description=raw.get(\"description\", \"\"),\n        version=raw[\"version\"],\n        status=raw[\"status\"],\n        published_date=published_date,\n        authors=raw.get(\"authors\", []),\n        maintainers=raw.get(\"maintainers\", []),\n        source_references=raw.get(\"source_references\", []),\n        related_profiles=raw.get(\"related_profiles\", []),\n        community_feedback=raw.get(\"community_feedback\", {}),\n        datatypes_used=raw.get(\"datatypes_used\", []),\n        statements_count=raw.get(\"statements_count\"),\n        references_required=raw.get(\"references_required\"),\n        qualifiers_used=raw.get(\"qualifiers_used\", []),\n        sparql_sources=raw.get(\"sparql_sources\", []),\n        raw_metadata=raw,\n    )\n</code></pre>"},{"location":"gkc/api/spirit_safe/#path-and-query-resolution","title":"Path and Query Resolution","text":""},{"location":"gkc/api/spirit_safe/#resolve_profile_path","title":"<code>resolve_profile_path</code>","text":"<p>Resolve a profile reference to a path within SpiritSafe structure.</p> <p>Handles profile name resolution (with or without .yaml extension) to the registrant package path (<code>profiles/&lt;ProfileName&gt;/profile.yaml</code>) and preserves explicit paths as-is.</p> <p>Parameters:</p> Name Type Description Default <code>profile_ref</code> <code>Union[str, Path]</code> <p>Profile name (e.g., \"TribalGovernmentUS\",     \"TribalGovernmentUS.yaml\") or explicit path     (e.g., \"profiles/TribalGovernmentUS/profile.yaml\").</p> required <p>Returns:</p> Type Description <code>Union[str, Path]</code> <p>Resolved path suitable for _resolve_profile_text().</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def resolve_profile_path(profile_ref: Union[str, Path]) -&gt; Union[str, Path]:\n    \"\"\"Resolve a profile reference to a path within SpiritSafe structure.\n\n    Handles profile name resolution (with or without .yaml extension) to the\n    registrant package path (`profiles/&lt;ProfileName&gt;/profile.yaml`) and preserves\n    explicit paths as-is.\n\n    Args:\n        profile_ref: Profile name (e.g., \"TribalGovernmentUS\",\n                \"TribalGovernmentUS.yaml\") or explicit path\n                (e.g., \"profiles/TribalGovernmentUS/profile.yaml\").\n\n    Returns:\n        Resolved path suitable for _resolve_profile_text().\n    \"\"\"\n    ref_str = str(profile_ref)\n\n    # If it's already a path with directory separators, use as-is\n    if \"/\" in ref_str or \"\\\\\" in ref_str:\n        return profile_ref\n\n    # If it looks like an absolute path, use as-is\n    path_obj = Path(profile_ref)\n    if path_obj.is_absolute():\n        return profile_ref\n\n    # Simple profile name: resolve to registrant package path\n    # Allow both \"ProfileName\" and \"ProfileName.yaml\" inputs\n    profile_name = ref_str.removesuffix(\".yaml\")\n    return f\"profiles/{profile_name}/profile.yaml\"\n</code></pre>"},{"location":"gkc/api/spirit_safe/#resolve_query_ref","title":"<code>resolve_query_ref</code>","text":"<p>Resolve a query reference relative to profile location with root fallback.</p> <p>Resolution strategy: 1. Try profile-relative first (profiles//queries/file.sparql) 2. Fall back to root-relative (queries/file.sparql) <p>Parameters:</p> Name Type Description Default <code>query_ref</code> <code>str</code> <p>Query reference path from profile (e.g., \"queries/file.sparql\")</p> required <code>profile_path</code> <code>Union[str, Path]</code> <p>Path to the profile file that references the query</p> required <p>Returns:</p> Type Description <code>Union[Path, str]</code> <p>Resolved path (local Path or GitHub URL depending on source mode)</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If query cannot be found in either location</p> Example <p>Plain meaning: Find query file near profile first, then in global queries directory.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def resolve_query_ref(\n    query_ref: str, profile_path: Union[str, Path]\n) -&gt; Union[Path, str]:\n    \"\"\"Resolve a query reference relative to profile location with root fallback.\n\n    Resolution strategy:\n    1. Try profile-relative first (profiles/&lt;Name&gt;/queries/file.sparql)\n    2. Fall back to root-relative (queries/file.sparql)\n\n    Args:\n        query_ref: Query reference path from profile (e.g., \"queries/file.sparql\")\n        profile_path: Path to the profile file that references the query\n\n    Returns:\n        Resolved path (local Path or GitHub URL depending on source mode)\n\n    Raises:\n        FileNotFoundError: If query cannot be found in either location\n\n    Example:\n        &gt;&gt;&gt; # For profile \"profiles/TribalGovernmentUS/profile.yaml\"\n        &gt;&gt;&gt; # and query_ref \"queries/file.sparql\"\n        &gt;&gt;&gt; resolve_query_ref(\n        ...     \"queries/file.sparql\",\n        ...     \"profiles/TribalGovernmentUS/profile.yaml\",\n        ... )\n        # tries: profiles/TribalGovernmentUS/queries/file.sparql\n        # then:  queries/file.sparql\n\n    Plain meaning: Find query file near profile first, then in global queries directory.\n    \"\"\"\n    source = get_spirit_safe_source()\n    profile_path_str = str(profile_path)\n\n    # Extract profile directory for registrant-style profiles\n    # profiles/Foo/profile.yaml -&gt; profiles/Foo/\n    profile_dir: Optional[str] = None\n    if \"/\" in profile_path_str or \"\\\\\" in profile_path_str:\n        profile_parent = str(Path(profile_path_str).parent)\n        # Only treat as profile directory if it looks like a registrant path\n        if profile_parent.startswith(\"profiles/\") and profile_parent != \"profiles\":\n            profile_dir = profile_parent\n\n    candidates: list[str] = []\n\n    # Strategy 1: profile-relative (only if we have a profile directory)\n    if profile_dir:\n        profile_relative = f\"{profile_dir}/{query_ref}\".replace(\"//\", \"/\")\n        candidates.append(profile_relative)\n\n    # Strategy 2: root-relative fallback\n    candidates.append(query_ref)\n\n    last_error: Optional[Exception] = None\n    for candidate in candidates:\n        try:\n            resolved = source.resolve_relative(candidate)\n            # Verify the path exists before returning it\n            _read_text_from_resolved_path(resolved)\n            return resolved\n        except Exception as exc:\n            last_error = exc\n\n    # Build helpful error message\n    tried_paths = \", \".join(candidates)\n    if last_error is not None:\n        raise FileNotFoundError(\n            f\"Query not found: {query_ref} (tried: {tried_paths})\"\n        ) from last_error\n\n    raise FileNotFoundError(f\"Query not found: {query_ref} (tried: {tried_paths})\")\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.resolve_query_ref--for-profile-profilestribalgovernmentusprofileyaml","title":"For profile \"profiles/TribalGovernmentUS/profile.yaml\"","text":""},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.resolve_query_ref--and-query_ref-queriesfilesparql","title":"and query_ref \"queries/file.sparql\"","text":"<p>resolve_query_ref( ...     \"queries/file.sparql\", ...     \"profiles/TribalGovernmentUS/profile.yaml\", ... )</p>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.resolve_query_ref--tries-profilestribalgovernmentusqueriesfilesparql","title":"tries: profiles/TribalGovernmentUS/queries/file.sparql","text":""},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.resolve_query_ref--then-queriesfilesparql","title":"then:  queries/file.sparql","text":""},{"location":"gkc/api/spirit_safe/#lookup-hydration-and-caching","title":"Lookup Hydration and Caching","text":""},{"location":"gkc/api/spirit_safe/#hydrate_profile_lookups","title":"<code>hydrate_profile_lookups</code>","text":"<p>Hydrate SPARQL lookup caches for one or more profile files.</p> <p>This performs an explicit lookup hydration workflow by scanning profile YAML, extracting SPARQL lookup specs, resolving query references/templates, deduplicating identical rendered queries, and optionally executing them through <code>LookupFetcher</code>.</p> <p>Parameters:</p> Name Type Description Default <code>profile_paths</code> <code>list[Union[str, Path]]</code> <p>Paths to profile YAML files.</p> required <code>refresh_policy</code> <code>Optional[RefreshPolicy]</code> <p>Optional global refresh policy override.</p> <code>None</code> <code>force_refresh</code> <code>bool</code> <p>Force refresh even if cache is fresh.</p> <code>False</code> <code>page_size</code> <code>int</code> <p>Page size for paginated query execution.</p> <code>1000</code> <code>max_results</code> <code>Optional[int]</code> <p>Optional maximum total results per query.</p> <code>None</code> <code>endpoint</code> <code>str</code> <p>SPARQL endpoint URL.</p> <code>'https://query.wikidata.org/sparql'</code> <code>dry_run</code> <code>bool</code> <p>If True, do not execute queries; return discovery summary only.</p> <code>False</code> <code>fail_on_query_error</code> <code>bool</code> <p>If True, raise on first query execution failure.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Summary dictionary with discovery/execution stats.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def hydrate_profile_lookups(\n    profile_paths: list[Union[str, Path]],\n    *,\n    refresh_policy: Optional[RefreshPolicy] = None,\n    force_refresh: bool = False,\n    page_size: int = 1000,\n    max_results: Optional[int] = None,\n    endpoint: str = \"https://query.wikidata.org/sparql\",\n    dry_run: bool = False,\n    fail_on_query_error: bool = False,\n) -&gt; dict[str, Any]:\n    \"\"\"Hydrate SPARQL lookup caches for one or more profile files.\n\n    This performs an explicit lookup hydration workflow by scanning profile YAML,\n    extracting SPARQL lookup specs, resolving query references/templates, deduplicating\n    identical rendered queries, and optionally executing them through `LookupFetcher`.\n\n    Args:\n        profile_paths: Paths to profile YAML files.\n        refresh_policy: Optional global refresh policy override.\n        force_refresh: Force refresh even if cache is fresh.\n        page_size: Page size for paginated query execution.\n        max_results: Optional maximum total results per query.\n        endpoint: SPARQL endpoint URL.\n        dry_run: If True, do not execute queries; return discovery summary only.\n        fail_on_query_error: If True, raise on first query execution failure.\n\n    Returns:\n        Summary dictionary with discovery/execution stats.\n    \"\"\"\n    source = get_spirit_safe_source()\n    discovered_specs: list[dict[str, Any]] = []\n\n    for profile_path in profile_paths:\n        yaml_text = _resolve_profile_text(profile_path)\n        profile_data = yaml.safe_load(yaml_text) or {}\n        profile_specs = _extract_sparql_specs(profile_data)\n        for spec in profile_specs:\n            spec[\"profile\"] = str(profile_path)\n            discovered_specs.append(spec)\n\n    unique_queries: dict[tuple[str, str], dict[str, Any]] = {}\n    failures: list[dict[str, Any]] = []\n\n    for spec in discovered_specs:\n        try:\n            if spec.get(\"query\"):\n                rendered_query = str(spec[\"query\"])\n            else:\n                query_ref = spec.get(\"query_ref\")\n                if not query_ref:\n                    raise ValueError(\"Missing both 'query' and 'query_ref'\")\n                resolved_query_ref = resolve_query_ref(\n                    str(query_ref), spec.get(\"profile\", \"\")\n                )\n                query_template = _read_text_from_resolved_path(resolved_query_ref)\n                rendered_query = _render_query_template(\n                    query_template, spec.get(\"query_params\", {})\n                )\n\n            key = (endpoint, rendered_query.strip())\n            if key not in unique_queries:\n                unique_queries[key] = {\n                    \"endpoint\": endpoint,\n                    \"query\": rendered_query,\n                    \"refresh\": refresh_policy or spec.get(\"refresh\", \"manual\"),\n                    \"sources\": [],\n                }\n            unique_queries[key][\"sources\"].append(\n                {\n                    \"profile\": spec.get(\"profile\"),\n                    \"location\": spec.get(\"location\"),\n                    \"query_ref\": spec.get(\"query_ref\"),\n                }\n            )\n        except Exception as exc:\n            failure = {\n                \"profile\": spec.get(\"profile\"),\n                \"location\": spec.get(\"location\"),\n                \"query_ref\": spec.get(\"query_ref\"),\n                \"error\": str(exc),\n            }\n            failures.append(failure)\n            if fail_on_query_error:\n                profile_loc = f\"{failure['profile']}:{failure['location']}\"\n                raise RuntimeError(\n                    f\"Failed to prepare query for {profile_loc}\"\n                ) from exc\n\n    hydrated: list[dict[str, Any]] = []\n    if not dry_run:\n        fetcher = LookupFetcher(endpoint=endpoint)\n        for entry in unique_queries.values():\n            try:\n                results = fetcher.fetch(\n                    entry[\"query\"],\n                    refresh_policy=entry[\"refresh\"],\n                    force_refresh=force_refresh,\n                    page_size=page_size,\n                    max_results=max_results,\n                )\n                hydrated.append(\n                    {\n                        \"endpoint\": endpoint,\n                        \"refresh\": entry[\"refresh\"],\n                        \"source_count\": len(entry[\"sources\"]),\n                        \"result_count\": len(results),\n                        \"sources\": entry[\"sources\"],\n                    }\n                )\n            except Exception as exc:\n                failure = {\n                    \"endpoint\": endpoint,\n                    \"sources\": entry[\"sources\"],\n                    \"error\": str(exc),\n                }\n                failures.append(failure)\n                if fail_on_query_error:\n                    raise RuntimeError(\n                        \"Failed to execute hydrated lookup query\"\n                    ) from exc\n\n    cache_dir = source.resolve_cache_dir()\n    cache_file_count = len(list(cache_dir.glob(\"*.json\"))) if cache_dir.exists() else 0\n\n    return {\n        \"source_mode\": source.mode,\n        \"profiles_scanned\": len(profile_paths),\n        \"lookup_specs_found\": len(discovered_specs),\n        \"unique_queries\": len(unique_queries),\n        \"unique_queries_executed\": 0 if dry_run else len(hydrated),\n        \"dry_run\": dry_run,\n        \"cache_dir\": str(cache_dir),\n        \"cache_file_count\": cache_file_count,\n        \"hydrated\": hydrated,\n        \"failures\": failures,\n    }\n</code></pre>"},{"location":"gkc/api/spirit_safe/#lookupcache","title":"<code>LookupCache</code>","text":"<p>Manage cached SPARQL lookup results.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>Optional[Path]</code> <p>Directory for cache storage (default from active SpiritSafe source)</p> <code>None</code> Example <p>cache = LookupCache() cache.get(\"query_hash\")</p> <p>Plain meaning: Store and retrieve SPARQL query results from disk.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>class LookupCache:\n    \"\"\"Manage cached SPARQL lookup results.\n\n    Args:\n        cache_dir: Directory for cache storage (default from active SpiritSafe source)\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; cache.get(\"query_hash\")\n\n    Plain meaning: Store and retrieve SPARQL query results from disk.\n    \"\"\"\n\n    def __init__(self, cache_dir: Optional[Path] = None):\n        \"\"\"Initialize cache manager.\n\n        Args:\n            cache_dir: Cache storage directory (default from active SpiritSafe source)\n        \"\"\"\n        if cache_dir is None:\n            cache_dir = get_spirit_safe_source().resolve_cache_dir()\n\n        self.cache_dir = Path(cache_dir)\n        self.cache_dir.mkdir(parents=True, exist_ok=True)\n\n    def _query_hash(self, query: str) -&gt; str:\n        \"\"\"Generate a hash for a query string.\n\n        Args:\n            query: SPARQL query string\n\n        Returns:\n            SHA256 hash of the query\n        \"\"\"\n        return hashlib.sha256(query.encode(\"utf-8\")).hexdigest()[:16]\n\n    def _cache_path(self, query: str) -&gt; Path:\n        \"\"\"Get cache file path for a query.\n\n        Args:\n            query: SPARQL query string\n\n        Returns:\n            Path to cache file\n        \"\"\"\n        query_hash = self._query_hash(query)\n        return self.cache_dir / f\"{query_hash}.json\"\n\n    def get(self, query: str) -&gt; Optional[dict[str, Any]]:\n        \"\"\"Retrieve cached results for a query.\n\n        Args:\n            query: SPARQL query string\n\n        Returns:\n            Cached data dict or None if not found\n\n        Example:\n            &gt;&gt;&gt; cache = LookupCache()\n            &gt;&gt;&gt; data = cache.get(\"SELECT ?item WHERE { ... }\")\n        \"\"\"\n        cache_path = self._cache_path(query)\n        if not cache_path.exists():\n            return None\n\n        try:\n            with open(cache_path, \"r\") as f:\n                return json.load(f)\n        except (json.JSONDecodeError, IOError):\n            return None\n\n    def set(\n        self,\n        query: str,\n        results: list[dict[str, Any]],\n        metadata: Optional[dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"Cache results for a query.\n\n        Args:\n            query: SPARQL query string\n            results: Query results to cache\n            metadata: Optional metadata to store with results\n\n        Example:\n            &gt;&gt;&gt; cache = LookupCache()\n            &gt;&gt;&gt; cache.set(\"SELECT ...\", [{\"item\": \"Q123\"}])\n        \"\"\"\n        cache_path = self._cache_path(query)\n\n        cache_data = {\n            \"query\": query,\n            \"timestamp\": datetime.now().isoformat(),\n            \"results\": results,\n            \"metadata\": metadata or {},\n        }\n\n        with open(cache_path, \"w\") as f:\n            json.dump(cache_data, f, indent=2)\n\n    def is_fresh(self, query: str, refresh_policy: RefreshPolicy = \"manual\") -&gt; bool:\n        \"\"\"Check if cached results are still fresh.\n\n        Args:\n            query: SPARQL query string\n            refresh_policy: Refresh policy to check against\n\n        Returns:\n            True if cache is fresh, False otherwise\n\n        Example:\n            &gt;&gt;&gt; cache = LookupCache()\n            &gt;&gt;&gt; if not cache.is_fresh(query, \"daily\"):\n            ...     # Refresh cache\n        \"\"\"\n        if refresh_policy == \"manual\":\n            # Manual refresh: always consider fresh if exists\n            return self.get(query) is not None\n\n        cached = self.get(query)\n        if cached is None:\n            return False\n\n        # Parse timestamp\n        try:\n            cached_time = datetime.fromisoformat(cached[\"timestamp\"])\n        except (KeyError, ValueError):\n            return False\n\n        # Check freshness based on policy\n        now = datetime.now()\n        if refresh_policy == \"daily\":\n            return (now - cached_time) &lt; timedelta(days=1)\n        elif refresh_policy == \"weekly\":\n            return (now - cached_time) &lt; timedelta(weeks=1)\n        # on_release would need version comparison (not implemented yet)\n        return False\n\n    def invalidate(self, query: str) -&gt; bool:\n        \"\"\"Invalidate cache for a specific query.\n\n        Args:\n            query: SPARQL query string\n\n        Returns:\n            True if cache was invalidated, False if not found\n\n        Example:\n            &gt;&gt;&gt; cache = LookupCache()\n            &gt;&gt;&gt; cache.invalidate(\"SELECT ...\")\n        \"\"\"\n        cache_path = self._cache_path(query)\n        if cache_path.exists():\n            cache_path.unlink()\n            return True\n        return False\n\n    def clear_all(self) -&gt; int:\n        \"\"\"Clear all cached queries.\n\n        Returns:\n            Number of cache files deleted\n\n        Example:\n            &gt;&gt;&gt; cache = LookupCache()\n            &gt;&gt;&gt; count = cache.clear_all()\n        \"\"\"\n        count = 0\n        for cache_file in self.cache_dir.glob(\"*.json\"):\n            cache_file.unlink()\n            count += 1\n        return count\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.__init__","title":"<code>__init__(cache_dir=None)</code>","text":"<p>Initialize cache manager.</p> <p>Parameters:</p> Name Type Description Default <code>cache_dir</code> <code>Optional[Path]</code> <p>Cache storage directory (default from active SpiritSafe source)</p> <code>None</code> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def __init__(self, cache_dir: Optional[Path] = None):\n    \"\"\"Initialize cache manager.\n\n    Args:\n        cache_dir: Cache storage directory (default from active SpiritSafe source)\n    \"\"\"\n    if cache_dir is None:\n        cache_dir = get_spirit_safe_source().resolve_cache_dir()\n\n    self.cache_dir = Path(cache_dir)\n    self.cache_dir.mkdir(parents=True, exist_ok=True)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.clear_all","title":"<code>clear_all()</code>","text":"<p>Clear all cached queries.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of cache files deleted</p> Example <p>cache = LookupCache() count = cache.clear_all()</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def clear_all(self) -&gt; int:\n    \"\"\"Clear all cached queries.\n\n    Returns:\n        Number of cache files deleted\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; count = cache.clear_all()\n    \"\"\"\n    count = 0\n    for cache_file in self.cache_dir.glob(\"*.json\"):\n        cache_file.unlink()\n        count += 1\n    return count\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.get","title":"<code>get(query)</code>","text":"<p>Retrieve cached results for a query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <p>Returns:</p> Type Description <code>Optional[dict[str, Any]]</code> <p>Cached data dict or None if not found</p> Example <p>cache = LookupCache() data = cache.get(\"SELECT ?item WHERE { ... }\")</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def get(self, query: str) -&gt; Optional[dict[str, Any]]:\n    \"\"\"Retrieve cached results for a query.\n\n    Args:\n        query: SPARQL query string\n\n    Returns:\n        Cached data dict or None if not found\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; data = cache.get(\"SELECT ?item WHERE { ... }\")\n    \"\"\"\n    cache_path = self._cache_path(query)\n    if not cache_path.exists():\n        return None\n\n    try:\n        with open(cache_path, \"r\") as f:\n            return json.load(f)\n    except (json.JSONDecodeError, IOError):\n        return None\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.invalidate","title":"<code>invalidate(query)</code>","text":"<p>Invalidate cache for a specific query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if cache was invalidated, False if not found</p> Example <p>cache = LookupCache() cache.invalidate(\"SELECT ...\")</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def invalidate(self, query: str) -&gt; bool:\n    \"\"\"Invalidate cache for a specific query.\n\n    Args:\n        query: SPARQL query string\n\n    Returns:\n        True if cache was invalidated, False if not found\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; cache.invalidate(\"SELECT ...\")\n    \"\"\"\n    cache_path = self._cache_path(query)\n    if cache_path.exists():\n        cache_path.unlink()\n        return True\n    return False\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.is_fresh","title":"<code>is_fresh(query, refresh_policy='manual')</code>","text":"<p>Check if cached results are still fresh.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <code>refresh_policy</code> <code>RefreshPolicy</code> <p>Refresh policy to check against</p> <code>'manual'</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if cache is fresh, False otherwise</p> Example <p>cache = LookupCache() if not cache.is_fresh(query, \"daily\"): ...     # Refresh cache</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def is_fresh(self, query: str, refresh_policy: RefreshPolicy = \"manual\") -&gt; bool:\n    \"\"\"Check if cached results are still fresh.\n\n    Args:\n        query: SPARQL query string\n        refresh_policy: Refresh policy to check against\n\n    Returns:\n        True if cache is fresh, False otherwise\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; if not cache.is_fresh(query, \"daily\"):\n        ...     # Refresh cache\n    \"\"\"\n    if refresh_policy == \"manual\":\n        # Manual refresh: always consider fresh if exists\n        return self.get(query) is not None\n\n    cached = self.get(query)\n    if cached is None:\n        return False\n\n    # Parse timestamp\n    try:\n        cached_time = datetime.fromisoformat(cached[\"timestamp\"])\n    except (KeyError, ValueError):\n        return False\n\n    # Check freshness based on policy\n    now = datetime.now()\n    if refresh_policy == \"daily\":\n        return (now - cached_time) &lt; timedelta(days=1)\n    elif refresh_policy == \"weekly\":\n        return (now - cached_time) &lt; timedelta(weeks=1)\n    # on_release would need version comparison (not implemented yet)\n    return False\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupCache.set","title":"<code>set(query, results, metadata=None)</code>","text":"<p>Cache results for a query.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <code>results</code> <code>list[dict[str, Any]]</code> <p>Query results to cache</p> required <code>metadata</code> <code>Optional[dict[str, Any]]</code> <p>Optional metadata to store with results</p> <code>None</code> Example <p>cache = LookupCache() cache.set(\"SELECT ...\", [{\"item\": \"Q123\"}])</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def set(\n    self,\n    query: str,\n    results: list[dict[str, Any]],\n    metadata: Optional[dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"Cache results for a query.\n\n    Args:\n        query: SPARQL query string\n        results: Query results to cache\n        metadata: Optional metadata to store with results\n\n    Example:\n        &gt;&gt;&gt; cache = LookupCache()\n        &gt;&gt;&gt; cache.set(\"SELECT ...\", [{\"item\": \"Q123\"}])\n    \"\"\"\n    cache_path = self._cache_path(query)\n\n    cache_data = {\n        \"query\": query,\n        \"timestamp\": datetime.now().isoformat(),\n        \"results\": results,\n        \"metadata\": metadata or {},\n    }\n\n    with open(cache_path, \"w\") as f:\n        json.dump(cache_data, f, indent=2)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#lookupfetcher","title":"<code>LookupFetcher</code>","text":"<p>Fetch and cache SPARQL-backed choice lists.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Optional[LookupCache]</code> <p>Optional LookupCache instance</p> <code>None</code> <code>endpoint</code> <code>str</code> <p>SPARQL endpoint URL</p> <code>'https://query.wikidata.org/sparql'</code> Example <p>fetcher = LookupFetcher() results = fetcher.fetch(query, refresh_policy=\"daily\")</p> <p>Plain meaning: Execute SPARQL queries for choice lists with caching.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>class LookupFetcher:\n    \"\"\"Fetch and cache SPARQL-backed choice lists.\n\n    Args:\n        cache: Optional LookupCache instance\n        endpoint: SPARQL endpoint URL\n\n    Example:\n        &gt;&gt;&gt; fetcher = LookupFetcher()\n        &gt;&gt;&gt; results = fetcher.fetch(query, refresh_policy=\"daily\")\n\n    Plain meaning: Execute SPARQL queries for choice lists with caching.\n    \"\"\"\n\n    def __init__(\n        self,\n        cache: Optional[LookupCache] = None,\n        endpoint: str = \"https://query.wikidata.org/sparql\",\n    ):\n        \"\"\"Initialize lookup fetcher.\n\n        Args:\n            cache: LookupCache instance (creates default if None)\n            endpoint: SPARQL endpoint URL\n        \"\"\"\n        self.cache = cache or LookupCache()\n        self.endpoint = endpoint\n        self.sparql = SPARQLQuery(endpoint=endpoint)\n\n    def _dedupe_results(self, results: list[dict[str, Any]]) -&gt; list[dict[str, Any]]:\n        \"\"\"Remove duplicate results based on unique identifier.\n\n        Handles query result redundancy from SPARQL endpoints or pagination\n        artifacts by tracking seen items and keeping only first occurrence.\n        Uses the \"item\" field as the unique identifier (standard for Wikidata).\n\n        Args:\n            results: Raw results from SPARQL query execution.\n\n        Returns:\n            Deduplicated results list preserving order of first occurrence.\n\n        Plain meaning: Remove duplicate rows from query results.\n        \"\"\"\n        seen_items: set[str] = set()\n        deduplicated: list[dict[str, Any]] = []\n\n        for result in results:\n            # Use \"item\" field as unique identifier (Wikidata convention)\n            # If no item field, use entire result as dict key (as string)\n            if \"item\" in result:\n                item_key = result[\"item\"]\n            else:\n                # Fallback: use string representation of the entire row\n                # This handles cases with multiple identifier fields\n                item_key = tuple(sorted(result.items())).__str__()\n\n            if item_key not in seen_items:\n                seen_items.add(item_key)\n                deduplicated.append(result)\n\n        return deduplicated\n\n    def fetch(\n        self,\n        query: str,\n        refresh_policy: RefreshPolicy = \"manual\",\n        force_refresh: bool = False,\n        page_size: int = 1000,\n        max_results: Optional[int] = None,\n    ) -&gt; list[dict[str, str]]:\n        \"\"\"Fetch lookup results with caching.\n\n        Args:\n            query: SPARQL query string\n            refresh_policy: Cache refresh policy\n            force_refresh: Force cache refresh even if fresh\n            page_size: Results per page for pagination\n            max_results: Maximum total results to fetch\n\n        Returns:\n            List of result dictionaries\n\n        Raises:\n            SPARQLError: If query execution fails\n\n        Example:\n            &gt;&gt;&gt; fetcher = LookupFetcher()\n            &gt;&gt;&gt; results = fetcher.fetch(\n            ...     \"SELECT ?item ?itemLabel WHERE { ... }\",\n            ...     refresh_policy=\"daily\"\n            ... )\n\n        Plain meaning: Get lookup data from cache or query endpoint.\n        \"\"\"\n        # Check cache first\n        if not force_refresh and self.cache.is_fresh(query, refresh_policy):\n            cached = self.cache.get(query)\n            if cached is not None:\n                return cached[\"results\"]\n\n        # Execute query with pagination\n        results = paginate_query(\n            query,\n            page_size=page_size,\n            endpoint=self.endpoint,\n            max_results=max_results,\n        )\n\n        # Deduplicate results to handle redundant query results\n        # (can occur with certain SPARQL patterns or pagination artifacts)\n        results = self._dedupe_results(results)\n\n        # Cache results\n        self.cache.set(\n            query,\n            results,\n            metadata={\n                \"refresh_policy\": refresh_policy,\n                \"result_count\": len(results),\n            },\n        )\n\n        return results\n\n    def fetch_choice_list(\n        self,\n        query: str,\n        id_var: str = \"item\",\n        label_var: str = \"itemLabel\",\n        extra_vars: Optional[list[str]] = None,\n        refresh_policy: RefreshPolicy = \"manual\",\n        force_refresh: bool = False,\n    ) -&gt; list[dict[str, str]]:\n        \"\"\"Fetch a choice list with normalized structure.\n\n        Normalizes SPARQL results to a consistent choice list format\n        with id, label, and optional extra fields.\n\n        Args:\n            query: SPARQL query string\n            id_var: Variable name for item ID (default: \"item\")\n            label_var: Variable name for label (default: \"itemLabel\")\n            extra_vars: Optional list of extra variable names to include\n            refresh_policy: Cache refresh policy\n            force_refresh: Force cache refresh\n\n        Returns:\n            List of choice items with normalized structure\n\n        Example:\n            &gt;&gt;&gt; fetcher = LookupFetcher()\n            &gt;&gt;&gt; choices = fetcher.fetch_choice_list(\n            ...     query,\n            ...     id_var=\"item\",\n            ...     label_var=\"itemLabel\",\n            ...     extra_vars=[\"languageCode\"]\n            ... )\n            &gt;&gt;&gt; # Returns: [{\"id\": \"Q123\", \"label\": \"Example\", \"languageCode\": \"en\"}]\n\n        Plain meaning: Get normalized choice data for forms and validation.\n        \"\"\"\n        raw_results = self.fetch(query, refresh_policy, force_refresh)\n\n        # Normalize to choice list format\n        choices = []\n        for row in raw_results:\n            choice: dict[str, str] = {}\n\n            # Extract ID (handle URLs with entity IDs)\n            id_value = row.get(id_var, \"\")\n            if \"/\" in id_value:\n                # Extract QID from URL\n                # (e.g., http://www.wikidata.org/entity/Q123 -&gt; Q123)\n                id_value = id_value.split(\"/\")[-1]\n            choice[\"id\"] = id_value\n\n            # Extract label\n            choice[\"label\"] = row.get(label_var, \"\")\n\n            # Extract extra fields if specified\n            if extra_vars:\n                for var in extra_vars:\n                    if var in row:\n                        choice[var] = row[var]\n\n            choices.append(choice)\n\n        return choices\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupFetcher.__init__","title":"<code>__init__(cache=None, endpoint='https://query.wikidata.org/sparql')</code>","text":"<p>Initialize lookup fetcher.</p> <p>Parameters:</p> Name Type Description Default <code>cache</code> <code>Optional[LookupCache]</code> <p>LookupCache instance (creates default if None)</p> <code>None</code> <code>endpoint</code> <code>str</code> <p>SPARQL endpoint URL</p> <code>'https://query.wikidata.org/sparql'</code> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def __init__(\n    self,\n    cache: Optional[LookupCache] = None,\n    endpoint: str = \"https://query.wikidata.org/sparql\",\n):\n    \"\"\"Initialize lookup fetcher.\n\n    Args:\n        cache: LookupCache instance (creates default if None)\n        endpoint: SPARQL endpoint URL\n    \"\"\"\n    self.cache = cache or LookupCache()\n    self.endpoint = endpoint\n    self.sparql = SPARQLQuery(endpoint=endpoint)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupFetcher.fetch","title":"<code>fetch(query, refresh_policy='manual', force_refresh=False, page_size=1000, max_results=None)</code>","text":"<p>Fetch lookup results with caching.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <code>refresh_policy</code> <code>RefreshPolicy</code> <p>Cache refresh policy</p> <code>'manual'</code> <code>force_refresh</code> <code>bool</code> <p>Force cache refresh even if fresh</p> <code>False</code> <code>page_size</code> <code>int</code> <p>Results per page for pagination</p> <code>1000</code> <code>max_results</code> <code>Optional[int]</code> <p>Maximum total results to fetch</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of result dictionaries</p> <p>Raises:</p> Type Description <code>SPARQLError</code> <p>If query execution fails</p> Example <p>fetcher = LookupFetcher() results = fetcher.fetch( ...     \"SELECT ?item ?itemLabel WHERE { ... }\", ...     refresh_policy=\"daily\" ... )</p> <p>Plain meaning: Get lookup data from cache or query endpoint.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def fetch(\n    self,\n    query: str,\n    refresh_policy: RefreshPolicy = \"manual\",\n    force_refresh: bool = False,\n    page_size: int = 1000,\n    max_results: Optional[int] = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Fetch lookup results with caching.\n\n    Args:\n        query: SPARQL query string\n        refresh_policy: Cache refresh policy\n        force_refresh: Force cache refresh even if fresh\n        page_size: Results per page for pagination\n        max_results: Maximum total results to fetch\n\n    Returns:\n        List of result dictionaries\n\n    Raises:\n        SPARQLError: If query execution fails\n\n    Example:\n        &gt;&gt;&gt; fetcher = LookupFetcher()\n        &gt;&gt;&gt; results = fetcher.fetch(\n        ...     \"SELECT ?item ?itemLabel WHERE { ... }\",\n        ...     refresh_policy=\"daily\"\n        ... )\n\n    Plain meaning: Get lookup data from cache or query endpoint.\n    \"\"\"\n    # Check cache first\n    if not force_refresh and self.cache.is_fresh(query, refresh_policy):\n        cached = self.cache.get(query)\n        if cached is not None:\n            return cached[\"results\"]\n\n    # Execute query with pagination\n    results = paginate_query(\n        query,\n        page_size=page_size,\n        endpoint=self.endpoint,\n        max_results=max_results,\n    )\n\n    # Deduplicate results to handle redundant query results\n    # (can occur with certain SPARQL patterns or pagination artifacts)\n    results = self._dedupe_results(results)\n\n    # Cache results\n    self.cache.set(\n        query,\n        results,\n        metadata={\n            \"refresh_policy\": refresh_policy,\n            \"result_count\": len(results),\n        },\n    )\n\n    return results\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupFetcher.fetch_choice_list","title":"<code>fetch_choice_list(query, id_var='item', label_var='itemLabel', extra_vars=None, refresh_policy='manual', force_refresh=False)</code>","text":"<p>Fetch a choice list with normalized structure.</p> <p>Normalizes SPARQL results to a consistent choice list format with id, label, and optional extra fields.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL query string</p> required <code>id_var</code> <code>str</code> <p>Variable name for item ID (default: \"item\")</p> <code>'item'</code> <code>label_var</code> <code>str</code> <p>Variable name for label (default: \"itemLabel\")</p> <code>'itemLabel'</code> <code>extra_vars</code> <code>Optional[list[str]]</code> <p>Optional list of extra variable names to include</p> <code>None</code> <code>refresh_policy</code> <code>RefreshPolicy</code> <p>Cache refresh policy</p> <code>'manual'</code> <code>force_refresh</code> <code>bool</code> <p>Force cache refresh</p> <code>False</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of choice items with normalized structure</p> Example <p>fetcher = LookupFetcher() choices = fetcher.fetch_choice_list( ...     query, ...     id_var=\"item\", ...     label_var=\"itemLabel\", ...     extra_vars=[\"languageCode\"] ... )</p> <p>Plain meaning: Get normalized choice data for forms and validation.</p> Source code in <code>gkc/spirit_safe.py</code> <pre><code>def fetch_choice_list(\n    self,\n    query: str,\n    id_var: str = \"item\",\n    label_var: str = \"itemLabel\",\n    extra_vars: Optional[list[str]] = None,\n    refresh_policy: RefreshPolicy = \"manual\",\n    force_refresh: bool = False,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Fetch a choice list with normalized structure.\n\n    Normalizes SPARQL results to a consistent choice list format\n    with id, label, and optional extra fields.\n\n    Args:\n        query: SPARQL query string\n        id_var: Variable name for item ID (default: \"item\")\n        label_var: Variable name for label (default: \"itemLabel\")\n        extra_vars: Optional list of extra variable names to include\n        refresh_policy: Cache refresh policy\n        force_refresh: Force cache refresh\n\n    Returns:\n        List of choice items with normalized structure\n\n    Example:\n        &gt;&gt;&gt; fetcher = LookupFetcher()\n        &gt;&gt;&gt; choices = fetcher.fetch_choice_list(\n        ...     query,\n        ...     id_var=\"item\",\n        ...     label_var=\"itemLabel\",\n        ...     extra_vars=[\"languageCode\"]\n        ... )\n        &gt;&gt;&gt; # Returns: [{\"id\": \"Q123\", \"label\": \"Example\", \"languageCode\": \"en\"}]\n\n    Plain meaning: Get normalized choice data for forms and validation.\n    \"\"\"\n    raw_results = self.fetch(query, refresh_policy, force_refresh)\n\n    # Normalize to choice list format\n    choices = []\n    for row in raw_results:\n        choice: dict[str, str] = {}\n\n        # Extract ID (handle URLs with entity IDs)\n        id_value = row.get(id_var, \"\")\n        if \"/\" in id_value:\n            # Extract QID from URL\n            # (e.g., http://www.wikidata.org/entity/Q123 -&gt; Q123)\n            id_value = id_value.split(\"/\")[-1]\n        choice[\"id\"] = id_value\n\n        # Extract label\n        choice[\"label\"] = row.get(label_var, \"\")\n\n        # Extract extra fields if specified\n        if extra_vars:\n            for var in extra_vars:\n                if var in row:\n                    choice[var] = row[var]\n\n        choices.append(choice)\n\n    return choices\n</code></pre>"},{"location":"gkc/api/spirit_safe/#gkc.spirit_safe.LookupFetcher.fetch_choice_list--returns-id-q123-label-example-languagecode-en","title":"Returns: [{\"id\": \"Q123\", \"label\": \"Example\", \"languageCode\": \"en\"}]","text":""},{"location":"gkc/api/spirit_safe/#usage-examples","title":"Usage Examples","text":""},{"location":"gkc/api/spirit_safe/#use-default-github-source","title":"Use default GitHub source","text":"<pre><code>import gkc\n\nsource = gkc.get_spirit_safe_source()\nprint(source.mode)  # github\nprofiles = gkc.list_profiles()\nprint(profiles)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#use-local-clone-for-branch-testing","title":"Use local clone for branch testing","text":"<pre><code>import gkc\n\ngkc.set_spirit_safe_source(\n    mode=\"local\",\n    local_root=\"/path/to/SpiritSafe\"\n)\n\nmetadata = gkc.get_profile_metadata(\"TribalGovernmentUS\")\nprint(metadata.version)\n</code></pre>"},{"location":"gkc/api/spirit_safe/#hydrate-lookups-from-profile-names","title":"Hydrate lookups from profile names","text":"<pre><code>import gkc\n\nsummary = gkc.hydrate_profile_lookups(\n    [gkc.resolve_profile_path(\"TribalGovernmentUS\")],\n    dry_run=True,\n)\nprint(summary[\"unique_queries\"])\n</code></pre>"},{"location":"gkc/cli/","title":"Command Line Interface (CLI)","text":"<p>Plain meaning: Run GKC tasks from your terminal.</p>"},{"location":"gkc/cli/#overview","title":"Overview","text":"<p>The GKC command line interface provides a lightweight entry point for common workflows including authentication, data loading, and transformation tasks. Commands are organized into logical groups for easy discovery and use.</p>"},{"location":"gkc/cli/#installation","title":"Installation","text":"<p>If you have GKC installed, the <code>gkc</code> command should be available. When developing locally, use Poetry to run the CLI:</p> <pre><code>poetry run gkc --help\n</code></pre>"},{"location":"gkc/cli/#global-flags","title":"Global Flags","text":"<p>These flags work with any command:</p> <ul> <li><code>--json</code>: Emit machine-readable JSON output for all commands</li> <li><code>--verbose</code>: Show additional details and diagnostic information</li> </ul>"},{"location":"gkc/cli/#command-groups","title":"Command Groups","text":""},{"location":"gkc/cli/#authentication","title":"Authentication","text":"<p>Manage credentials and verify authentication for Wikiverse (Wikidata, Wikipedia, Wikimedia Commons) and OpenStreetMap services.</p> <pre><code>gkc auth wikiverse status\ngkc auth osm status\n</code></pre>"},{"location":"gkc/cli/#mash","title":"Mash","text":"<p>Load Wikidata items as templates for viewing, filtering, and exporting in various formats.</p> <pre><code>gkc mash qid Q42\n</code></pre>"},{"location":"gkc/cli/#profiles","title":"Profiles","text":"<p>Validate items against YAML profiles, generate form schemas, and hydrate SPARQL lookups.</p> <pre><code>gkc profile validate --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml --qid Q123\n</code></pre>"},{"location":"gkc/cli/#quick-start-examples","title":"Quick Start Examples","text":"<p>Check authentication status: <pre><code>gkc auth wikiverse status\n</code></pre></p> <p>Load a Wikidata item as a template: <pre><code>gkc mash qid Q42 --output summary\n</code></pre></p> <p>Get raw Wikidata JSON output for scripting: <pre><code>gkc --json mash qid Q42 --output json\n</code></pre></p>"},{"location":"gkc/cli/#getting-help","title":"Getting Help","text":"<p>Use <code>--help</code> with any command or subcommand to see available options:</p> <pre><code>gkc --help\ngkc auth --help\ngkc mash qid --help\n</code></pre>"},{"location":"gkc/cli/#build-and-test-commands","title":"Build and Test Commands","text":"<p>Build documentation: <pre><code>poetry run mkdocs build\n</code></pre></p> <p>Run tests: <pre><code>poetry run pytest\n</code></pre></p>"},{"location":"gkc/cli/auth/","title":"Authentication Commands","text":"<p>Plain meaning: Verify and manage credentials for external services.</p>"},{"location":"gkc/cli/auth/#overview","title":"Overview","text":"<p>The authentication commands help you verify that your credentials are properly configured and can successfully authenticate with Wikiverse (Wikidata, Wikipedia, Wikimedia Commons) and OpenStreetMap services.</p>"},{"location":"gkc/cli/auth/#wikiverse-authentication","title":"Wikiverse Authentication","text":"<p>Wikiverse commands manage authentication for all Wikimedia projects (Wikidata, Wikipedia, Wikimedia Commons) using bot password credentials.</p>"},{"location":"gkc/cli/auth/#login","title":"Login","text":"<pre><code>gkc auth wikiverse login\n</code></pre> <p>Logs into Wikiverse using bot password credentials.</p> <p>Options: - <code>--interactive</code>: Prompt for credentials if environment variables are missing - <code>--api-url</code>: Override the Wikiverse API URL</p> <p>Example: <pre><code>gkc auth wikiverse login --interactive\n</code></pre></p>"},{"location":"gkc/cli/auth/#status","title":"Status","text":"<pre><code>gkc auth wikiverse status\n</code></pre> <p>Checks whether credentials are available and whether a CSRF token can be obtained. This is the recommended way to verify your authentication setup.</p> <p>Options: - <code>--api-url</code>: Override the Wikiverse API URL</p> <p>Example: <pre><code>gkc auth wikiverse status\ngkc --json auth wikiverse status\n</code></pre></p>"},{"location":"gkc/cli/auth/#token","title":"Token","text":"<pre><code>gkc auth wikiverse token\n</code></pre> <p>Retrieves a CSRF token for debugging purposes. Tokens are redacted by default for security.</p> <p>Options: - <code>--interactive</code>: Prompt for credentials if environment variables are missing - <code>--api-url</code>: Override the Wikiverse API URL - <code>--show-token</code>: Display the full token (use with caution)</p> <p>Example: <pre><code>gkc auth wikiverse token\ngkc auth wikiverse token --show-token\n</code></pre></p>"},{"location":"gkc/cli/auth/#openstreetmap-authentication","title":"OpenStreetMap Authentication","text":"<p>OpenStreetMap commands verify that OSM credentials are properly configured.</p>"},{"location":"gkc/cli/auth/#login_1","title":"Login","text":"<pre><code>gkc auth osm login\n</code></pre> <p>Confirms whether OpenStreetMap credentials are present.</p> <p>Options: - <code>--interactive</code>: Prompt for credentials if environment variables are missing</p> <p>Example: <pre><code>gkc auth osm login --interactive\n</code></pre></p>"},{"location":"gkc/cli/auth/#status_1","title":"Status","text":"<pre><code>gkc auth osm status\n</code></pre> <p>Reports whether OpenStreetMap credentials are available.</p> <p>Example: <pre><code>gkc auth osm status\ngkc --json auth osm status\n</code></pre></p>"},{"location":"gkc/cli/auth/#environment-variables","title":"Environment Variables","text":""},{"location":"gkc/cli/auth/#wikiverse","title":"Wikiverse","text":"<p>These environment variables configure Wikiverse authentication:</p> <ul> <li><code>WIKIVERSE_USERNAME</code>: Your bot username (format: <code>YourUsername@BotName</code>)</li> <li><code>WIKIVERSE_PASSWORD</code>: Your bot password</li> <li><code>WIKIVERSE_API_URL</code>: API URL (optional, defaults to Wikidata)</li> </ul> <p>Example: <pre><code>export WIKIVERSE_USERNAME=\"MyUser@MyBot\"\nexport WIKIVERSE_PASSWORD=\"abc123def456\"\n</code></pre></p>"},{"location":"gkc/cli/auth/#openstreetmap","title":"OpenStreetMap","text":"<p>These environment variables configure OSM authentication:</p> <ul> <li><code>OPENSTREETMAP_USERNAME</code>: Your OSM username</li> <li><code>OPENSTREETMAP_PASSWORD</code>: Your OSM password</li> </ul> <p>Example: <pre><code>export OPENSTREETMAP_USERNAME=\"myuser\"\nexport OPENSTREETMAP_PASSWORD=\"secret123\"\n</code></pre></p>"},{"location":"gkc/cli/auth/#output-formats","title":"Output Formats","text":""},{"location":"gkc/cli/auth/#human-readable-output","title":"Human-Readable Output","text":"<p>By default, commands output simple status messages:</p> <pre><code>$ gkc auth wikiverse status\nCredentials and token validated\nauthenticated: True\nlogged_in: True\napi_url: https://www.wikidata.org/w/api.php\ntoken_ok: True\n</code></pre>"},{"location":"gkc/cli/auth/#json-output","title":"JSON Output","text":"<p>Use the <code>--json</code> flag for machine-readable output suitable for scripts:</p> <pre><code>$ gkc --json auth wikiverse status\n{\n  \"command\": \"auth.wikiverse.status\",\n  \"ok\": true,\n  \"message\": \"Credentials and token validated\",\n  \"details\": {\n    \"authenticated\": true,\n    \"logged_in\": true,\n    \"api_url\": \"https://www.wikidata.org/w/api.php\",\n    \"token_ok\": true\n  }\n}\n</code></pre>"},{"location":"gkc/cli/auth/#security-notes","title":"Security Notes","text":"<ul> <li>Tokens are automatically redacted in output unless <code>--show-token</code> is explicitly used</li> <li>Never commit credentials or tokens to version control</li> <li>Use environment variables or interactive prompts instead of command-line arguments for credentials</li> <li>The <code>--json</code> output is safe to log as it redacts sensitive information by default</li> </ul>"},{"location":"gkc/cli/auth/#related-documentation","title":"Related Documentation","text":"<ul> <li>Authentication Guide - Detailed guide for setting up authentication in your code</li> <li>CLI Overview - Main CLI documentation</li> </ul>"},{"location":"gkc/cli/mash/","title":"Mash Commands","text":"<p>Plain meaning: Load source data as ingredients for further actions.</p>"},{"location":"gkc/cli/mash/#overview","title":"Overview","text":"<p>The mash module in GKC handles the input of various data and information content and structure that will be processed through data distillery workflows. The mash CLI provides an interface to load Wikidata entities - items (QID), properties (PID), EntitySchemas (EID) - as well as Wikipedia templates.</p> <p>The name \"mash\" comes from the distillery metaphor\u2014like grain that's been milled and steeped to extract fermentable sugars, mashed entities extract the essential structure and content from source data, readying the ingredients for further processing.</p> <p>Current implementations: - Wikidata items (QID) - Wikidata properties (PID) - Wikidata EntitySchemas (EID) - Wikipedia templates</p> <p>Future implementations: CSV files, JSON APIs, dataframes</p>"},{"location":"gkc/cli/mash/#load-wikidata-items-by-qid","title":"Load Wikidata Items by QID","text":"<pre><code>gkc mash qid &lt;QID&gt; [options]\n</code></pre> <p>Load one or more Wikidata items by QID and output them in various formats.</p>"},{"location":"gkc/cli/mash/#arguments","title":"Arguments","text":"<ul> <li><code>qid</code>: Positional argument for a single item ID (e.g., <code>Q42</code>)</li> <li><code>--qid &lt;QID&gt;</code>: Repeatable flag for multiple items (e.g., <code>--qid Q42 --qid Q5</code>)</li> <li><code>--qid-list &lt;file&gt;</code>: Path to file containing item IDs (one per line)</li> </ul>"},{"location":"gkc/cli/mash/#output-options","title":"Output Options","text":"<ul> <li><code>-o, --output &lt;file&gt;</code>: Write output to file instead of stdout</li> <li><code>--raw</code>: Output raw JSON to stdout (default behavior when no transform specified)</li> <li><code>--summary</code>: Output a summary of the item(s) with labels, descriptions, and statement count</li> <li><code>--transform &lt;type&gt;</code>: Transform the output  </li> <li><code>shell</code>: Strip all identifiers for new item creation</li> <li><code>qsv1</code>: Convert to QuickStatements V1 format</li> <li><code>gkc_entity_profile</code>: Convert to GKC Entity Profile (not yet implemented)</li> </ul>"},{"location":"gkc/cli/mash/#filtering-options","title":"Filtering Options","text":"<ul> <li><code>--include-properties &lt;P1,P2,...&gt;</code>: Comma-separated list of properties to include</li> <li><code>--exclude-properties &lt;P1,P2,...&gt;</code>: Comma-separated list of properties to exclude</li> <li><code>--exclude-qualifiers</code>: Omit all qualifiers from output</li> <li><code>--exclude-references</code>: Omit all references from output</li> <li><code>--no-entity-labels</code>: Skip fetching entity labels for QuickStatements comments (faster)</li> </ul>"},{"location":"gkc/cli/mash/#examples","title":"Examples","text":""},{"location":"gkc/cli/mash/#load-a-single-item-and-display-summary","title":"Load a single item and display summary","text":"<pre><code>gkc mash qid Q42 --summary\n</code></pre> <p>Output: JSON summary with labels, descriptions, and statement count</p>"},{"location":"gkc/cli/mash/#load-a-single-item-raw-json","title":"Load a single item (raw JSON)","text":"<pre><code>gkc mash qid Q42 --raw\n</code></pre> <p>Output: Raw Wikidata JSON for item Q42</p>"},{"location":"gkc/cli/mash/#load-multiple-items","title":"Load multiple items","text":"<pre><code># Using repeatable --qid flags\ngkc mash qid --qid Q42 --qid Q5 --qid Q30\n\n# Using a file list\necho \"Q42\nQ5\nQ30\" &gt; items.txt\ngkc mash qid --qid-list items.txt\n</code></pre>"},{"location":"gkc/cli/mash/#transform-to-shell-for-new-item-creation","title":"Transform to shell for new item creation","text":"<pre><code>gkc mash qid Q42 --transform shell -o new_item_template.json\n</code></pre> <p>Strips all identifiers (id, pageid, ns, title, statement IDs, hashes) to create a clean template for submitting as a new item.</p>"},{"location":"gkc/cli/mash/#transform-to-quickstatements","title":"Transform to QuickStatements","text":"<pre><code># For editing existing item\ngkc mash qid Q42 --transform qsv1\n\n# Extract specific properties only\ngkc mash qid Q42 --transform qsv1 --include-properties P31,P21,P569\n</code></pre>"},{"location":"gkc/cli/mash/#filter-properties-and-save","title":"Filter properties and save","text":"<pre><code>gkc mash qid Q42 \\\n  --exclude-properties P18,P373 \\\n  --exclude-qualifiers \\\n  --exclude-references \\\n  -o filtered_item.json\n</code></pre>"},{"location":"gkc/cli/mash/#load-wikidata-properties-by-pid","title":"Load Wikidata Properties by PID","text":"<pre><code>gkc mash pid &lt;PID&gt; [options]\n</code></pre> <p>Load one or more Wikidata properties by PID and output them in various formats.</p>"},{"location":"gkc/cli/mash/#arguments_1","title":"Arguments","text":"<ul> <li><code>pid</code>: Positional argument for a single property ID (e.g., <code>P31</code>)</li> <li><code>--pid &lt;PID&gt;</code>: Repeatable flag for multiple properties (e.g., <code>--pid P31 --pid P279</code>)</li> <li><code>--pid-list &lt;file&gt;</code>: Path to file containing property IDs (one per line)</li> </ul>"},{"location":"gkc/cli/mash/#output-options_1","title":"Output Options","text":"<ul> <li><code>-o, --output &lt;file&gt;</code>: Write output to file instead of stdout</li> <li><code>--raw</code>: Output raw JSON to stdout (default behavior)</li> <li><code>--summary</code>: Output a summary of the property(ies) with labels, descriptions, and datatype</li> <li><code>--transform &lt;type&gt;</code>: Transform the output</li> <li><code>shell</code>: Strip all identifiers for new property creation</li> <li><code>gkc_entity_profile</code>: Convert to GKC Entity Profile (not yet implemented)</li> </ul>"},{"location":"gkc/cli/mash/#examples_1","title":"Examples","text":""},{"location":"gkc/cli/mash/#load-a-single-property-and-display-summary","title":"Load a single property and display summary","text":"<pre><code>gkc mash pid P31 --summary\n</code></pre> <p>Output: JSON summary with labels, descriptions, datatype, and formatter URL</p>"},{"location":"gkc/cli/mash/#load-a-single-property-raw-json","title":"Load a single property (raw JSON)","text":"<pre><code>gkc mash pid P31 --raw\n</code></pre> <p>Output: Raw Wikidata JSON for property P31</p>"},{"location":"gkc/cli/mash/#load-multiple-properties","title":"Load multiple properties","text":"<pre><code># Using repeatable --pid flags\ngkc mash pid --pid P31 --pid P279 --pid P21\n\n# Using a file list\necho \"P31\nP279\nP21\" &gt; properties.txt\ngkc mash pid --pid-list properties.txt\n</code></pre>"},{"location":"gkc/cli/mash/#transform-to-shell-for-new-property-creation","title":"Transform to shell for new property creation","text":"<pre><code>gkc mash pid P31 --transform shell -o new_property_template.json\n</code></pre>"},{"location":"gkc/cli/mash/#load-wikidata-entityschemas-by-eid","title":"Load Wikidata EntitySchemas by EID","text":"<pre><code>gkc mash eid &lt;EID&gt; [options]\n</code></pre> <p>Load a Wikidata EntitySchema by EID and output it in various formats.</p>"},{"location":"gkc/cli/mash/#arguments_2","title":"Arguments","text":"<ul> <li><code>eid</code>: The EntitySchema ID (e.g., <code>E502</code>)</li> </ul>"},{"location":"gkc/cli/mash/#output-options_2","title":"Output Options","text":"<ul> <li><code>-o, --output &lt;file&gt;</code>: Write output to file instead of stdout</li> <li><code>--raw</code>: Output raw JSON to stdout (default behavior)</li> <li><code>--summary</code>: Output a summary of the EntitySchema with labels and descriptions</li> <li><code>--transform &lt;type&gt;</code>: Transform the output</li> <li><code>shell</code>: Strip all identifiers for new EntitySchema creation</li> <li><code>gkc_entity_profile</code>: Convert to GKC Entity Profile</li> </ul>"},{"location":"gkc/cli/mash/#examples_2","title":"Examples","text":""},{"location":"gkc/cli/mash/#load-an-entityschema-and-display-summary","title":"Load an EntitySchema and display summary","text":"<pre><code>gkc mash eid E502 --summary\n</code></pre> <p>Output: JSON summary with labels, descriptions, and schema text length</p>"},{"location":"gkc/cli/mash/#load-an-entityschema-raw-json","title":"Load an EntitySchema (raw JSON)","text":"<pre><code>gkc mash eid E502 --raw\n</code></pre> <p>Output: Raw EntitySchema JSON including labels, descriptions, and ShEx schema text</p>"},{"location":"gkc/cli/mash/#transform-to-gkc-entity-profile","title":"Transform to GKC Entity Profile","text":"<pre><code>gkc mash eid E502 --transform gkc_entity_profile -o tribe_profile.json\n</code></pre> <p>Converts the EntitySchema's ShEx specification into a GKC Entity Profile that can be used for data validation and transformation.</p>"},{"location":"gkc/cli/mash/#transform-to-shell-for-reuse","title":"Transform to shell for reuse","text":"<pre><code>gkc mash eid E502 --transform shell -o new_schema_template.json\n</code></pre>"},{"location":"gkc/cli/mash/#load-wikipedia-templates","title":"Load Wikipedia Templates","text":"<pre><code>gkc mash wp_template &lt;TEMPLATE_NAME&gt; [options]\n</code></pre> <p>Load a Wikipedia template from en.wikipedia.org and output it in various formats.</p>"},{"location":"gkc/cli/mash/#arguments_3","title":"Arguments","text":"<ul> <li><code>template_name</code>: The Wikipedia template name (e.g., <code>Infobox_settlement</code>)</li> </ul>"},{"location":"gkc/cli/mash/#output-options_3","title":"Output Options","text":"<ul> <li><code>-o, --output &lt;file&gt;</code>: Write output to file instead of stdout</li> <li><code>--raw</code>: Output raw JSON response from the Wikimedia API</li> <li>Default (no flags): Output summary of the template with title, description, and parameter count</li> </ul>"},{"location":"gkc/cli/mash/#examples_3","title":"Examples","text":""},{"location":"gkc/cli/mash/#load-a-wikipedia-template-and-display-summary","title":"Load a Wikipedia template and display summary","text":"<pre><code>gkc mash wp_template Infobox_settlement\n</code></pre> <p>Output: <pre><code>{\n  \"title\": \"Infobox settlement\",\n  \"description\": \"An infobox used to summarize information about places or geographic entities\",\n  \"param_count\": 47\n}\n</code></pre></p>"},{"location":"gkc/cli/mash/#get-the-full-template-structure","title":"Get the full template structure","text":"<pre><code>gkc mash wp_template Infobox_settlement --raw -o settlement_template.json\n</code></pre> <p>Output: Full JSON structure including title, description (multilingual), params, and paramOrder</p>"},{"location":"gkc/cli/mash/#explore-template-parameters","title":"Explore template parameters","text":"<pre><code>gkc mash wp_template Infobox_settlement --raw | jq '.paramOrder[:10]'\n</code></pre> <p>Lists the first 10 parameters in order, useful for understanding template structure.</p>"},{"location":"gkc/cli/mash/#batch-processing-patterns","title":"Batch Processing Patterns","text":""},{"location":"gkc/cli/mash/#load-multiple-items-from-a-file","title":"Load multiple items from a file","text":"<pre><code># Create a file with QIDs\ncat &gt; items.txt &lt;&lt;EOF_MARKER\nQ42\nQ5\nQ30\n# Comments are ignored\nQ515\nEOF_MARKER\n\n# Process all items\ngkc mash qid --qid-list items.txt -o batch_items.json\n</code></pre>"},{"location":"gkc/cli/mash/#transform-multiple-items-to-quickstatements","title":"Transform multiple items to QuickStatements","text":"<pre><code># Load multiple items and convert to QS for batch editing\ngkc mash qid --qid Q42 --qid Q5 --transform qsv1 -o batch_statements.qs\n</code></pre>"},{"location":"gkc/cli/mash/#property-metadata-extraction","title":"Property metadata extraction","text":"<pre><code># Extract metadata for a set of properties\ncat &gt; props.txt &lt;&lt;EOF_MARKER\nP31\nP279\nP21\nP569\nP570\nEOF_MARKER\n\ngkc mash pid --pid-list props.txt -o property_metadata.json\n</code></pre>"},{"location":"gkc/cli/mash/#output-formats","title":"Output Formats","text":""},{"location":"gkc/cli/mash/#raw-json-default","title":"Raw JSON (default)","text":"<p>The raw Wikidata entity JSON as returned by the API. This format preserves all structure and identifiers, suitable for: - Round-trip processing - Integration with other tools - Detailed inspection</p>"},{"location":"gkc/cli/mash/#shell-transform-shell","title":"Shell (--transform shell)","text":"<p>Strips all system identifiers and metadata: - Removes: <code>id</code>, <code>pageid</code>, <code>lastrevid</code>, <code>modified</code>, <code>ns</code>, <code>title</code> - Removes: statement IDs (GUIDs) - Removes: all hashes from snaks, qualifiers, and references</p> <p>Use this when creating templates for new entity creation on Wikidata or Wikibase instances.</p>"},{"location":"gkc/cli/mash/#quickstatements-v1-transform-qsv1-items-only","title":"QuickStatements V1 (--transform qsv1, items only)","text":"<p>Converts item data to QuickStatements V1 format for bulk operations: - Format: <code>QID|property|value</code> - Includes property labels as comments for readability - Use on QuickStatements for batch editing</p>"},{"location":"gkc/cli/mash/#gkc-entity-profile-transform-gkc_entity_profile-entityschemas-only","title":"GKC Entity Profile (--transform gkc_entity_profile, EntitySchemas only)","text":"<p>Converts EntitySchemas to GKC Entity Profiles: - Extracts properties and constraints from ShEx - Creates portable profiles for validation and transformation - Currently only implemented for EntitySchemas</p>"},{"location":"gkc/cli/mash/#common-workflows","title":"Common Workflows","text":""},{"location":"gkc/cli/mash/#creating-similar-items","title":"Creating Similar Items","text":"<ol> <li>Find anexemplar item on Wikidata (e.g., Q42)</li> <li>Load with shell transform: <code>gkc mash qid Q42 --transform shell -o template.json</code></li> <li>Edit the template JSON to modify labels/values</li> <li>Submit to Wikidata using the wbeditentity API or QuickStatements</li> </ol>"},{"location":"gkc/cli/mash/#property-documentation","title":"Property Documentation","text":"<pre><code># Extract metadata for all properties in a domain\ngkc mash pid --pid-list biological_properties.txt -o bio_props.json\n</code></pre>"},{"location":"gkc/cli/mash/#entityschema-development","title":"EntitySchema Development","text":"<pre><code># Load existing schema as starting point\ngkc mash eid E502 --transform shell -o new_schema.json\n\n# Or convert to profile for analysis\ngkc mash eid E502 --transform gkc_entity_profile -o tribe_profile.json\n</code></pre>"},{"location":"gkc/cli/mash/#migration-from-previous-cli","title":"Migration from Previous CLI","text":"<p>The mash CLI has been refactored for consistency. Key changes:</p> <p>Old: <pre><code>gkc mash qid Q42 --output qsv1 --new\ngkc mash qid Q42 --output json\n</code></pre></p> <p>New: <pre><code>gkc mash qid Q42 --transform qsv1\ngkc mash qid Q42  # raw JSON is default\ngkc mash qid Q42 --transform shell  # for new items\n</code></pre></p> <p>Changes: - <code>--output</code> now means output file path, not format - <code>--transform</code> specifies the transformation type - <code>--new</code> flag removed (use <code>--transform shell</code> or <code>--transform qsv1</code> with for_new_item) - <code>--save-profile</code> replaced with <code>-o, --output</code> - Added support for batch loading with <code>--qid-list</code>, <code>--pid-list</code> - Added <code>mash pid</code> command for properties - Simplified <code>mash eid</code> command</p>"},{"location":"gkc/cli/mash/#related-documentation","title":"Related Documentation","text":"<ul> <li>Mash API - Python API for programmatic use</li> <li>QuickStatements Documentation - External tool for batch operations</li> </ul>"},{"location":"gkc/cli/profiles/","title":"Profiles CLI","text":"<p>Plain meaning: Validate data and generate schemas from YAML profiles.</p>"},{"location":"gkc/cli/profiles/#overview","title":"Overview","text":"<p>The <code>profile</code> command group lets you validate Wikidata items against YAML profiles and export form schemas for CLI or UI workflows.</p>"},{"location":"gkc/cli/profiles/#commands","title":"Commands","text":""},{"location":"gkc/cli/profiles/#validate-a-wikidata-item","title":"Validate a Wikidata Item","text":"<pre><code>gkc profile validate --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml --qid Q123\n</code></pre> <p>Validate a local JSON file:</p> <pre><code>gkc profile validate --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml --item-json path/to/item.json\n</code></pre> <p>Use strict validation:</p> <pre><code>gkc profile validate --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml --qid Q123 --policy strict\n</code></pre>"},{"location":"gkc/cli/profiles/#generate-a-form-schema","title":"Generate a Form Schema","text":"<pre><code>gkc profile form-schema --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml\n</code></pre> <p>Write schema to a file:</p> <pre><code>gkc profile form-schema --profile /path/to/SpiritSafe/profiles/TribalGovernmentUS/profile.yaml --output form_schema.json\n</code></pre>"},{"location":"gkc/cli/profiles/#hydrate-sparql-lookups","title":"Hydrate SPARQL Lookups","text":"<p>Use profile names with default GitHub source mode:</p> <pre><code>gkc profile lookups hydrate --profile TribalGovernmentUS --dry-run\n</code></pre> <p>Use a local SpiritSafe clone (recommended for branch development):</p> <pre><code>gkc profile lookups hydrate \\\n  --profile TribalGovernmentUS \\\n  --source local \\\n  --local-root /path/to/SpiritSafe \\\n  --dry-run\n</code></pre> <p>Override GitHub repo/ref for testing:</p> <pre><code>gkc profile lookups hydrate \\\n  --profile TribalGovernmentUS \\\n  --source github \\\n  --repo skybristol/SpiritSafe \\\n  --ref main \\\n  --dry-run\n</code></pre>"},{"location":"gkc/cli/profiles/#flags","title":"Flags","text":"<ul> <li><code>--profile</code>: Profile path or profile name (repeatable for <code>lookups hydrate</code>)</li> <li><code>--qid</code>: Wikidata item ID to fetch and validate</li> <li><code>--item-json</code>: Path to a Wikidata item JSON file</li> <li><code>--policy</code>: Validation policy (<code>strict</code> or <code>lenient</code>)</li> <li><code>--output</code>: Output file path for form schemas</li> <li><code>--source</code>: SpiritSafe source mode override (<code>github</code> or <code>local</code>) for hydration</li> <li><code>--local-root</code>: Local SpiritSafe clone root (required with <code>--source local</code>)</li> <li><code>--repo</code>: GitHub repo slug override for hydration (with <code>--source github</code>)</li> <li><code>--ref</code>: Git reference override for hydration (with <code>--source github</code>)</li> </ul>"},{"location":"gkc/cli/profiles/#see-also","title":"See Also","text":"<ul> <li>Profiles API - Programmatic profile usage</li> <li>Mash CLI - Load Wikidata items for validation</li> </ul>"},{"location":"gkc/cli/shex/","title":"ShEx Commands","text":"<p>Plain meaning: Validate RDF data against ShEx schemas.</p>"},{"location":"gkc/cli/shex/#overview","title":"Overview","text":"<p>The ShEx module in GKC validates RDF data against ShEx (Shape Expression) schemas. It's designed primarily for validating Wikidata entities against EntitySchemas but supports validation of local RDF files as well.</p> <p>ShEx validation helps ensure data quality by checking that entities conform to expected patterns\u2014required properties, value types, cardinality constraints, and more.</p> <p>Current implementations: - Wikidata entity validation (QID + EID) - Local RDF file validation - Mixed source validation (Wikidata entity + local schema, or local RDF + EntitySchema)</p> <p>Future implementations: Batch validation, validation reports, schema coverage analysis</p>"},{"location":"gkc/cli/shex/#validate-rdf-data","title":"Validate RDF Data","text":"<pre><code>gkc shex validate [options]\n</code></pre> <p>Validate RDF data (from Wikidata or local file) against a ShEx schema (from Wikidata EntitySchema or local file).</p>"},{"location":"gkc/cli/shex/#source-options","title":"Source Options","text":"<p>RDF Data Source (choose one): - <code>--qid &lt;QID&gt;</code>: Fetch RDF data for Wikidata item (e.g., <code>Q42</code>) - <code>--rdf-file &lt;path&gt;</code>: Use local RDF file (Turtle format)</p> <p>Schema Source (choose one): - <code>--eid &lt;EID&gt;</code>: Fetch ShEx schema from Wikidata EntitySchema (e.g., <code>E502</code>) - <code>--schema-file &lt;path&gt;</code>: Use local ShEx schema file</p>"},{"location":"gkc/cli/shex/#other-options","title":"Other Options","text":"<ul> <li><code>--user-agent &lt;string&gt;</code>: Custom user agent for Wikidata API requests (recommended for bots)</li> </ul>"},{"location":"gkc/cli/shex/#examples","title":"Examples","text":""},{"location":"gkc/cli/shex/#validate-wikidata-entity-against-entityschema","title":"Validate Wikidata entity against EntitySchema","text":"<pre><code>gkc shex validate --qid Q14708404 --eid E502\n</code></pre> <p>Example output: <pre><code>{\n  \"command\": \"shex.validate\",\n  \"ok\": true,\n  \"message\": \"\u2713 Validation passed\\nEntity: Q14708404\\nSchema: E502\",\n  \"details\": {\n    \"entity\": \"Q14708404\",\n    \"entity_uri\": \"http://www.wikidata.org/entity/Q14708404\",\n    \"schema\": \"E502\",\n    \"valid\": true\n  }\n}\n</code></pre></p>"},{"location":"gkc/cli/shex/#validation-failure","title":"Validation failure","text":"<pre><code>gkc shex validate --qid Q999999 --eid E502\n</code></pre> <p>Example output: <pre><code>{\n  \"command\": \"shex.validate\",\n  \"ok\": false,\n  \"message\": \"\u2717 Validation failed\\nError: wdt:P31 value not in allowed set [wd:Q133346]\\nEntity: Q999999\\nSchema: E502\",\n  \"details\": {\n    \"entity\": \"Q999999\",\n    \"entity_uri\": \"http://www.wikidata.org/entity/Q999999\",\n    \"schema\": \"E502\",\n    \"valid\": false,\n    \"error_summary\": \"wdt:P31 value not in allowed set [wd:Q133346]\"\n  }\n}\n</code></pre></p>"},{"location":"gkc/cli/shex/#validate-local-rdf-file","title":"Validate local RDF file","text":"<pre><code>gkc shex validate --rdf-file entity.ttl --eid E502\n</code></pre> <p>Validates a locally stored Turtle file against Wikidata EntitySchema E502.</p>"},{"location":"gkc/cli/shex/#validate-wikidata-entity-with-local-schema","title":"Validate Wikidata entity with local schema","text":"<pre><code>gkc shex validate --qid Q42 --schema-file custom_schema.shex\n</code></pre> <p>Fetches entity data from Wikidata but uses a custom local ShEx schema.</p>"},{"location":"gkc/cli/shex/#validate-local-files-fully-offline","title":"Validate local files (fully offline)","text":"<pre><code>gkc shex validate --rdf-file entity.ttl --schema-file schema.shex\n</code></pre> <p>Both RDF data and ShEx schema are loaded from local files\u2014no network requests.</p>"},{"location":"gkc/cli/shex/#custom-user-agent-for-bots","title":"Custom user agent (for bots)","text":"<pre><code>gkc shex validate \\\n  --qid Q14708404 \\\n  --eid E502 \\\n  --user-agent \"MyBot/1.0 (https://example.com; bot@example.com)\"\n</code></pre> <p>Use a custom user agent string when fetching data from Wikidata APIs (recommended for automated tools).</p>"},{"location":"gkc/cli/shex/#output-format","title":"Output Format","text":"<p>The <code>gkc shex validate</code> command outputs JSON with the following structure:</p> <pre><code>{\n  \"command\": \"shex.validate\",\n  \"ok\": true|false,\n  \"message\": \"Human-readable summary with status\",\n  \"details\": {\n    \"entity\": \"Q14708404\",\n    \"entity_uri\": \"http://www.wikidata.org/entity/Q14708404\",\n    \"schema\": \"E502\",\n    \"valid\": true|false,\n    \"error_summary\": \"Brief error description (only on failure)\",\n    \"results\": \"Full validation results (available if needed)\"\n  }\n}\n</code></pre> <p>Fields: - <code>ok</code>: Command execution status (true if command succeeded, false on error) - <code>valid</code>: Validation result (true if entity conforms to schema, false if not) - <code>message</code>: Human-readable summary of the validation result with entity/schema info - <code>error_summary</code>: Brief description of validation errors (present only when valid=false) - <code>details</code>: Complete validation details including entity URI, schema reference, and error information</p>"},{"location":"gkc/cli/shex/#validation-workflow-examples","title":"Validation Workflow Examples","text":""},{"location":"gkc/cli/shex/#pre-upload-quality-check","title":"Pre-upload quality check","text":"<p>Before uploading new data to Wikidata, validate it locally:</p> <pre><code># 1. Export new entity as RDF\ncat &gt; new_tribe.ttl &lt;&lt; 'EOF'\n@prefix wd: &lt;http://www.wikidata.org/entity/&gt; .\n@prefix wdt: &lt;http://www.wikidata.org/prop/direct/&gt; .\n\nwd:QNEW wdt:P31 wd:Q133346 ;\n        wdt:P17 wd:Q30 ;\n        wdt:P571 \"1979-01-01\"^^xsd:date .\nEOF\n\n# 2. Validate against tribe schema\ngkc shex validate --rdf-file new_tribe.ttl --eid E502\n\n# 3. If validation passes, proceed with upload\n</code></pre>"},{"location":"gkc/cli/shex/#batch-validation-of-existing-entities","title":"Batch validation of existing entities","text":"<pre><code># Create list of QIDs to validate\ncat &gt; tribes_to_check.txt &lt;&lt; 'EOF'\nQ14708404\nQ3551781\nQ1948829\nQ4675719\nEOF\n\n# Validate each entity\nwhile read qid; do\n  echo \"Checking $qid...\"\n  gkc shex validate --qid \"$qid\" --eid E502 --json &gt;&gt; validation_report.jsonl\ndone &lt; tribes_to_check.txt\n\n# Parse results\njq 'select(.valid == false) | .qid' validation_report.jsonl\n</code></pre>"},{"location":"gkc/cli/shex/#testing-schema-changes","title":"Testing schema changes","text":"<p>When developing new EntitySchemas, test them locally before publishing:</p> <pre><code># 1. Create draft schema\ncat &gt; draft_schema.shex &lt;&lt; 'EOF'\nPREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;\nPREFIX wd: &lt;http://www.wikidata.org/entity/&gt;\n\n&lt;FederallyRecognizedTribe&gt; {\n  wdt:P31 [ wd:Q133346 ] ;\n  wdt:P17 [ wd:Q30 ] ;\n  wdt:P571 xsd:date ? ;\n  wdt:P576 xsd:date ?\n}\nEOF\n\n# 2. Test against known good entity\ngkc shex validate --qid Q14708404 --schema-file draft_schema.shex\n\n# 3. Test against known problematic entity\ngkc shex validate --qid Q999999 --schema-file draft_schema.shex --verbose\n\n# 4. If tests pass, publish schema to Wikidata as new EntitySchema\n</code></pre>"},{"location":"gkc/cli/shex/#comparing-entities-to-multiple-schemas","title":"Comparing entities to multiple schemas","text":"<pre><code># Check if entity conforms to multiple related schemas\nschemas=(\"E502\" \"E503\" \"E504\")\n\nfor eid in \"${schemas[@]}\"; do\n  result=$(gkc shex validate --qid Q14708404 --eid \"$eid\" --json)\n  valid=$(echo \"$result\" | jq -r '.valid')\n  echo \"$eid: $valid\"\ndone\n</code></pre>"},{"location":"gkc/cli/shex/#common-entityschemas","title":"Common EntitySchemas","text":"EID Description Use Case E502 Federally recognized tribe US tribal nations E49 Human Person/biographical items E10 Place Geographic locations E42 Scholarly article Scientific publications <p>Browse all schemas: Wikidata:EntitySchema</p>"},{"location":"gkc/cli/shex/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Validation passed (entity conforms to schema) 1 Validation failed (entity does not conform to schema) 2 Error during validation process (missing files, network error, etc.) <p>Use exit codes in scripts:</p> <pre><code>if gkc shex validate --qid Q42 --eid E49 --json &gt; /dev/null 2&gt;&amp;1; then\n  echo \"Q42 is a valid human entity\"\nelse\n  echo \"Q42 has validation issues\"\nfi\n</code></pre>"},{"location":"gkc/cli/shex/#see-also","title":"See Also","text":"<ul> <li>ShEx API Documentation - Python library usage</li> <li>Utilities Guide - ShEx validation concepts and patterns</li> <li>Wikidata EntitySchemas - Browse published schemas</li> <li>ShEx Primer - Learn ShEx syntax</li> <li>ShEx Test Suite - Additional validation examples</li> </ul>"}]}